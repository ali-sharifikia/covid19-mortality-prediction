{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ceeb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import normalize,StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV,train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, auc, log_loss,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.calibration import calibration_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "949129f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.read_csv(\"Dataset_Final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e194c1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                        0\n",
       "Hospital_Name                     0\n",
       "Age                               0\n",
       "BMI                               0\n",
       "LOS                               0\n",
       "Average_Daily_Use_Cigarettes      0\n",
       "Hookah_Consumption                0\n",
       "SystolicBP                        0\n",
       "DiastolicBP                       0\n",
       "Respiratory_rate                  0\n",
       "Oxygen_Saturation_Percent         0\n",
       "Intubation_Duration_Day           0\n",
       "ICU_LOS                           0\n",
       "Total_Lung_Involvement_Percent    0\n",
       "NIV_Duration_Day                  0\n",
       "Total_Lung_Involvement_Rank       8\n",
       "Sex                               0\n",
       "Current_Smoking                   0\n",
       "History_hookah                    0\n",
       "Drug_history                      0\n",
       "Sweating                          0\n",
       "Fever                             0\n",
       "Dyspnea                           0\n",
       "Chestpain                         0\n",
       "Abnormal_Lung_Signs               0\n",
       "Diabetes                          0\n",
       "Hypertension                      0\n",
       "Cancers                           0\n",
       "Cardiovascular_Disease            0\n",
       "CKD                               0\n",
       "COPD                              0\n",
       "Immunosuppressant_Drugs           0\n",
       "Antihypertensive_drug             0\n",
       "Pantoprazole                      0\n",
       "Hospitalization_14_days_ago       0\n",
       "ICU_admission                     0\n",
       "Death                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424391fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Average_Daily_Use_Cigarettes</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>DiastolicBP</th>\n",
       "      <th>Respiratory_rate</th>\n",
       "      <th>Oxygen_Saturation_Percent</th>\n",
       "      <th>Intubation_Duration_Day</th>\n",
       "      <th>Total_Lung_Involvement_Percent</th>\n",
       "      <th>NIV_Duration_Day</th>\n",
       "      <th>...</th>\n",
       "      <th>Cancers</th>\n",
       "      <th>Cardiovascular_Disease</th>\n",
       "      <th>CKD</th>\n",
       "      <th>COPD</th>\n",
       "      <th>Immunosuppressant_Drugs</th>\n",
       "      <th>Antihypertensive_drug</th>\n",
       "      <th>Pantoprazole</th>\n",
       "      <th>Hospitalization_14_days_ago</th>\n",
       "      <th>ICU_admission</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.422697</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.718638</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.0</td>\n",
       "      <td>26.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.0</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.422697</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19.718638</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>78.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>26.148507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age        BMI  Average_Daily_Use_Cigarettes  SystolicBP  DiastolicBP  \\\n",
       "0  61.0  20.500000                           0.0  122.422697         78.0   \n",
       "1  74.0  26.700000                           0.0   40.000000         75.0   \n",
       "2  51.0  29.100000                           0.0  122.422697         78.0   \n",
       "3  64.0  41.000000                           0.0  136.000000         78.0   \n",
       "4  20.0  26.148507                           0.0  113.000000         76.0   \n",
       "\n",
       "   Respiratory_rate  Oxygen_Saturation_Percent  Intubation_Duration_Day  \\\n",
       "0         19.718638                       91.0                        0   \n",
       "1         16.000000                       75.0                        0   \n",
       "2         19.718638                       91.0                        0   \n",
       "3         20.000000                       95.0                        0   \n",
       "4         19.000000                       92.0                        0   \n",
       "\n",
       "   Total_Lung_Involvement_Percent  NIV_Duration_Day  ...  Cancers  \\\n",
       "0                             0.0                 0  ...        0   \n",
       "1                             0.0                 0  ...        0   \n",
       "2                             0.0                 0  ...        0   \n",
       "3                             0.0                 0  ...        0   \n",
       "4                             0.0                 0  ...        0   \n",
       "\n",
       "   Cardiovascular_Disease  CKD  COPD  Immunosuppressant_Drugs  \\\n",
       "0                       0    0     0                        0   \n",
       "1                       1    1     0                        0   \n",
       "2                       0    0     0                        0   \n",
       "3                       0    0     0                        0   \n",
       "4                       0    0     0                        0   \n",
       "\n",
       "   Antihypertensive_drug  Pantoprazole  Hospitalization_14_days_ago  \\\n",
       "0                      1             0                          0.0   \n",
       "1                      0             1                          1.0   \n",
       "2                      0             0                          1.0   \n",
       "3                      0             0                          0.0   \n",
       "4                      0             0                          0.0   \n",
       "\n",
       "   ICU_admission  Death  \n",
       "0            1.0      1  \n",
       "1            1.0      1  \n",
       "2            1.0      1  \n",
       "3            1.0      0  \n",
       "4            2.0      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.drop(\"Unnamed: 0\", axis = 1 , inplace=True)\n",
    "Dataset.drop(\"Hospital_Name\", axis = 1 , inplace=True)\n",
    "Dataset.drop(\"Total_Lung_Involvement_Rank\", axis = 1 , inplace=True)\n",
    "Dataset.drop(\"Hookah_Consumption\", axis = 1 , inplace=True)\n",
    "Dataset.drop(\"LOS\", axis = 1 , inplace=True)\n",
    "Dataset.drop(\"ICU_LOS\", axis = 1 , inplace=True)\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8894d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Column Identified outliers: 0\n",
      "BMI Column Identified outliers: 8\n",
      "BMI Column Identified outliers: 0\n",
      "Average_Daily_Use_Cigarettes Column Identified outliers: 8\n",
      "Average_Daily_Use_Cigarettes Column Identified outliers: 0\n",
      "SystolicBP Column Identified outliers: 9\n",
      "SystolicBP Column Identified outliers: 0\n",
      "DiastolicBP Column Identified outliers: 9\n",
      "DiastolicBP Column Identified outliers: 0\n",
      "Respiratory_rate Column Identified outliers: 6\n",
      "Respiratory_rate Column Identified outliers: 0\n",
      "Oxygen_Saturation_Percent Column Identified outliers: 14\n",
      "Oxygen_Saturation_Percent Column Identified outliers: 0\n",
      "Intubation_Duration_Day Column Identified outliers: 13\n",
      "Intubation_Duration_Day Column Identified outliers: 0\n",
      "Total_Lung_Involvement_Percent Column Identified outliers: 30\n",
      "Total_Lung_Involvement_Percent Column Identified outliers: 0\n",
      "NIV_Duration_Day Column Identified outliers: 11\n",
      "NIV_Duration_Day Column Identified outliers: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['BMI'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Average_Daily_Use_Cigarettes'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['SystolicBP'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['SystolicBP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['DiastolicBP'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['DiastolicBP'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Respiratory_rate'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Oxygen_Saturation_Percent'][i] = lower\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:136: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Intubation_Duration_Day'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['Total_Lung_Involvement_Percent'][i] = upper\n",
      "C:\\Users\\alish\\AppData\\Local\\Temp\\ipykernel_1220\\1012456011.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Dataset['NIV_Duration_Day'][i] = upper\n"
     ]
    }
   ],
   "source": [
    "#Controlling Outlier data\n",
    "data_mean, data_std = np.mean(Dataset['Age']), np.std(Dataset['Age'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Age'] if x < lower or x > upper]\n",
    "print('Age Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['BMI']), np.std(Dataset['BMI'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "\n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] < lower:\n",
    "        Dataset['BMI'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['BMI'])):\n",
    "    if Dataset['BMI'][i] > upper:\n",
    "        Dataset['BMI'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['BMI'] if x < lower or x > upper]\n",
    "print('BMI Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Average_Daily_Use_Cigarettes']), np.std(Dataset['Average_Daily_Use_Cigarettes'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Average_Daily_Use_Cigarettes'] if x < lower or x > upper]\n",
    "print('Average_Daily_Use_Cigarettes Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Average_Daily_Use_Cigarettes'])):\n",
    "    if Dataset['Average_Daily_Use_Cigarettes'][i] < lower:\n",
    "        Dataset['Average_Daily_Use_Cigarettes'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['Average_Daily_Use_Cigarettes'])):\n",
    "    if Dataset['Average_Daily_Use_Cigarettes'][i] > upper:\n",
    "        Dataset['Average_Daily_Use_Cigarettes'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['Average_Daily_Use_Cigarettes'] if x < lower or x > upper]\n",
    "print('Average_Daily_Use_Cigarettes Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['SystolicBP']), np.std(Dataset['SystolicBP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['SystolicBP'] if x < lower or x > upper]\n",
    "print('SystolicBP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['SystolicBP'])):\n",
    "    if Dataset['SystolicBP'][i] < lower:\n",
    "        Dataset['SystolicBP'][i] = lower\n",
    "        \n",
    "        \n",
    "for i in range(len(Dataset['SystolicBP'])):\n",
    "    if Dataset['SystolicBP'][i] > upper:\n",
    "        Dataset['SystolicBP'][i] = upper\n",
    "        \n",
    "\n",
    "outliers = [x for x in Dataset['SystolicBP'] if x < lower or x > upper]\n",
    "print('SystolicBP Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['DiastolicBP']), np.std(Dataset['DiastolicBP'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['DiastolicBP'] if x < lower or x > upper]\n",
    "print('DiastolicBP Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['DiastolicBP'])):\n",
    "    if Dataset['DiastolicBP'][i] < lower:\n",
    "        Dataset['DiastolicBP'][i] = lower\n",
    "       \n",
    "\n",
    "for i in range(len(Dataset['DiastolicBP'])):\n",
    "    if Dataset['DiastolicBP'][i] > upper:\n",
    "        Dataset['DiastolicBP'][i] = upper\n",
    "    \n",
    "\n",
    "outliers = [x for x in Dataset['DiastolicBP'] if x < lower or x > upper]\n",
    "print('DiastolicBP Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Respiratory_rate']), np.std(Dataset['Respiratory_rate'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Respiratory_rate'] if x < lower or x > upper]\n",
    "print('Respiratory_rate Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Respiratory_rate'])):\n",
    "    if Dataset['Respiratory_rate'][i] < lower:\n",
    "        Dataset['Respiratory_rate'][i] = lower\n",
    " \n",
    "        \n",
    "for i in range(len(Dataset['Respiratory_rate'])):\n",
    "    if Dataset['Respiratory_rate'][i] > upper:\n",
    "        Dataset['Respiratory_rate'][i] = upper\n",
    "   \n",
    "\n",
    "outliers = [x for x in Dataset['Respiratory_rate'] if x < lower or x > upper]\n",
    "print('Respiratory_rate Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Oxygen_Saturation_Percent']), np.std(Dataset['Oxygen_Saturation_Percent'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Oxygen_Saturation_Percent'] if x < lower or x > upper]\n",
    "print('Oxygen_Saturation_Percent Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Oxygen_Saturation_Percent'])):\n",
    "    if Dataset['Oxygen_Saturation_Percent'][i] < lower:\n",
    "        Dataset['Oxygen_Saturation_Percent'][i] = lower\n",
    "\n",
    "        \n",
    "for i in range(len(Dataset['Oxygen_Saturation_Percent'])):\n",
    "    if Dataset['Oxygen_Saturation_Percent'][i] > upper:\n",
    "        Dataset['Oxygen_Saturation_Percent'][i] = upper\n",
    "\n",
    "\n",
    "outliers = [x for x in Dataset['Oxygen_Saturation_Percent'] if x < lower or x > upper]\n",
    "print('Oxygen_Saturation_Percent Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Intubation_Duration_Day']), np.std(Dataset['Intubation_Duration_Day'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Intubation_Duration_Day'] if x < lower or x > upper]\n",
    "print('Intubation_Duration_Day Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Intubation_Duration_Day'])):\n",
    "    if Dataset['Intubation_Duration_Day'][i] < lower:\n",
    "        Dataset['Intubation_Duration_Day'][i] = lower\n",
    "\n",
    "        \n",
    "for i in range(len(Dataset['Intubation_Duration_Day'])):\n",
    "    if Dataset['Intubation_Duration_Day'][i] > upper:\n",
    "        Dataset['Intubation_Duration_Day'][i] = upper\n",
    "\n",
    "\n",
    "outliers = [x for x in Dataset['Intubation_Duration_Day'] if x < lower or x > upper]\n",
    "print('Intubation_Duration_Day Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['Total_Lung_Involvement_Percent']), np.std(Dataset['Total_Lung_Involvement_Percent'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['Total_Lung_Involvement_Percent'] if x < lower or x > upper]\n",
    "print('Total_Lung_Involvement_Percent Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['Total_Lung_Involvement_Percent'])):\n",
    "    if Dataset['Total_Lung_Involvement_Percent'][i] < lower:\n",
    "        Dataset['Total_Lung_Involvement_Percent'][i] = lower\n",
    "\n",
    "        \n",
    "for i in range(len(Dataset['Total_Lung_Involvement_Percent'])):\n",
    "    if Dataset['Total_Lung_Involvement_Percent'][i] > upper:\n",
    "        Dataset['Total_Lung_Involvement_Percent'][i] = upper\n",
    "\n",
    "\n",
    "outliers = [x for x in Dataset['Total_Lung_Involvement_Percent'] if x < lower or x > upper]\n",
    "print('Total_Lung_Involvement_Percent Column Identified outliers: %d' % len(outliers))\n",
    "#############################################################################################\n",
    "data_mean, data_std = np.mean(Dataset['NIV_Duration_Day']), np.std(Dataset['NIV_Duration_Day'])\n",
    "cut_off = data_std * 3\n",
    "lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "outliers = [x for x in Dataset['NIV_Duration_Day'] if x < lower or x > upper]\n",
    "print('NIV_Duration_Day Column Identified outliers: %d' % len(outliers))\n",
    "\n",
    "for i in range(len(Dataset['NIV_Duration_Day'])):\n",
    "    if Dataset['NIV_Duration_Day'][i] < lower:\n",
    "        Dataset['NIV_Duration_Day'][i] = lower\n",
    "\n",
    "        \n",
    "for i in range(len(Dataset['NIV_Duration_Day'])):\n",
    "    if Dataset['NIV_Duration_Day'][i] > upper:\n",
    "        Dataset['NIV_Duration_Day'][i] = upper\n",
    "\n",
    "\n",
    "outliers = [x for x in Dataset['NIV_Duration_Day'] if x < lower or x > upper]\n",
    "print('NIV_Duration_Day Column Identified outliers: %d' % len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b55e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Dataset[Dataset.columns.difference([\"Death\"])] \n",
    "Y = Dataset[\"Death\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7da7533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_balanced, Y_balanced = sm.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1fa19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abnormal_Lung_Signs</th>\n",
       "      <th>Age</th>\n",
       "      <th>Antihypertensive_drug</th>\n",
       "      <th>Average_Daily_Use_Cigarettes</th>\n",
       "      <th>BMI</th>\n",
       "      <th>CKD</th>\n",
       "      <th>COPD</th>\n",
       "      <th>Cancers</th>\n",
       "      <th>Cardiovascular_Disease</th>\n",
       "      <th>Chestpain</th>\n",
       "      <th>...</th>\n",
       "      <th>Immunosuppressant_Drugs</th>\n",
       "      <th>Intubation_Duration_Day</th>\n",
       "      <th>NIV_Duration_Day</th>\n",
       "      <th>Oxygen_Saturation_Percent</th>\n",
       "      <th>Pantoprazole</th>\n",
       "      <th>Respiratory_rate</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sweating</th>\n",
       "      <th>SystolicBP</th>\n",
       "      <th>Total_Lung_Involvement_Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.331393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494373</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.665082</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.504618</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.511437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109106</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.279945</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159734</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.108238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.671994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100635</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.118566</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545404</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669898</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Abnormal_Lung_Signs       Age  Antihypertensive_drug  \\\n",
       "0                    0  0.331393                      1   \n",
       "1                    0  0.504618                      0   \n",
       "2                    0  0.279945                      0   \n",
       "3                    0  0.322031                      0   \n",
       "4                    0  0.118566                      0   \n",
       "\n",
       "   Average_Daily_Use_Cigarettes       BMI  CKD  COPD  Cancers  \\\n",
       "0                           0.0  0.111370    0     0        0   \n",
       "1                           0.0  0.182071    1     0        0   \n",
       "2                           0.0  0.159734    0     0        0   \n",
       "3                           0.0  0.187998    0     0        0   \n",
       "4                           0.0  0.155016    0     0        0   \n",
       "\n",
       "   Cardiovascular_Disease  Chestpain  ...  Immunosuppressant_Drugs  \\\n",
       "0                       0          0  ...                        0   \n",
       "1                       1          0  ...                        0   \n",
       "2                       0          0  ...                        0   \n",
       "3                       0          0  ...                        0   \n",
       "4                       0          0  ...                        0   \n",
       "\n",
       "   Intubation_Duration_Day  NIV_Duration_Day  Oxygen_Saturation_Percent  \\\n",
       "0                      0.0               0.0                   0.494373   \n",
       "1                      0.0               0.0                   0.511437   \n",
       "2                      0.0               0.0                   0.499511   \n",
       "3                      0.0               0.0                   0.478015   \n",
       "4                      0.0               0.0                   0.545404   \n",
       "\n",
       "   Pantoprazole  Respiratory_rate  Sex  Sweating  SystolicBP  \\\n",
       "0             0          0.107125  1.0         0    0.665082   \n",
       "1             1          0.109106  1.0         0    0.420918   \n",
       "2             0          0.108238  1.0         0    0.671994   \n",
       "3             0          0.100635  1.0         0    0.684317   \n",
       "4             0          0.112638  1.0         0    0.669898   \n",
       "\n",
       "   Total_Lung_Involvement_Percent  \n",
       "0                             0.0  \n",
       "1                             0.0  \n",
       "2                             0.0  \n",
       "3                             0.0  \n",
       "4                             0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced[['Age', 'BMI','Average_Daily_Use_Cigarettes',\n",
    "       'SystolicBP', 'DiastolicBP', 'Respiratory_rate',\n",
    "       'Oxygen_Saturation_Percent', 'Intubation_Duration_Day', 'Total_Lung_Involvement_Percent'\n",
    "       ,'NIV_Duration_Day']] = normalize(X_balanced[['Age', 'BMI', 'Average_Daily_Use_Cigarettes',\n",
    "       'SystolicBP', 'DiastolicBP', 'Respiratory_rate',\n",
    "       'Oxygen_Saturation_Percent', 'Intubation_Duration_Day', 'Total_Lung_Involvement_Percent'\n",
    "       ,'NIV_Duration_Day']])\n",
    "X_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "befb066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(f'Best Score is : {results.best_score_} ')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')\n",
    "        \n",
    "def showResults(model, modelType , X, Y):\n",
    "    scores_accuracy = cross_val_score(model, X, Y, cv=10, scoring='accuracy')\n",
    "    scores_log_loss = cross_val_score(model, X, Y, cv=10, scoring='neg_log_loss')\n",
    "    scores_briar = cross_val_score(model, X, Y, cv=10, scoring='neg_brier_score')\n",
    "    scores_auc = cross_val_score(model, X, Y, cv=10, scoring='roc_auc')\n",
    "    scores_recall = cross_val_score(model, X, Y, cv=10, scoring='recall')\n",
    "    scores_precision = cross_val_score(model, X, Y, cv=10, scoring='precision')\n",
    "    scores_f1 = cross_val_score(model, X, Y, cv=10, scoring='f1')\n",
    "    print('K-fold cross-validation results:')\n",
    "    print(modelType ,\" average accuracy is %2.3f\" % scores_accuracy.mean())\n",
    "    print(modelType ,\" average log_loss is %2.3f\" % -scores_log_loss.mean())\n",
    "    print(modelType ,\" average brier score is %2.3f\" % -scores_briar.mean())\n",
    "    print(modelType ,\" average auc is %2.3f\" % scores_auc.mean())\n",
    "    print(modelType ,\" average recall is %2.3f\" % scores_recall.mean())\n",
    "    print(modelType ,\" average precision is %2.3f\" % scores_precision.mean())\n",
    "    print(modelType ,\" average f1 is %2.3f\" % scores_f1.mean())\n",
    "    \n",
    "params_logistic = {\n",
    "    'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'C' : np.logspace(-3,3,7),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "params_bayes = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "225c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Input\n",
    "X = X_balanced[[\"Age\", \"Oxygen_Saturation_Percent\", \"Sweating\", \"Abnormal_Lung_Signs\", \"CKD\",\n",
    "             \"Hospitalization_14_days_ago\", \"BMI\", \"Sex\", \"Current_Smoking\", \"Fever\", \"Chestpain\",\n",
    "               \"Hypertension\", \"Cancers\", \"Cardiovascular_Disease\", \"Immunosuppressant_Drugs\", \n",
    "                \"Antihypertensive_drug\", \"Pantoprazole\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae2529b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.63407238 0.63407238 0.64604145\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.64050289 0.64050289 0.64235474        nan        nan        nan\n",
      "        nan        nan 0.6672613  0.66538396 0.66538396 0.66539246\n",
      "        nan        nan        nan        nan        nan 0.7067788\n",
      " 0.70224261 0.70224261 0.70316854        nan        nan        nan\n",
      "        nan        nan 0.7067703  0.70769623 0.70769623 0.70769623\n",
      "        nan        nan        nan        nan        nan 0.70862215\n",
      " 0.70770472 0.70770472 0.70770472        nan        nan        nan\n",
      "        nan        nan 0.70862215 0.70862215 0.70862215 0.70862215\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf80c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.708622154264356 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.634 + or -0.109 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.634 + or -0.109 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.646 + or -0.098 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.641 + or -0.101 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.641 + or -0.101 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.642 + or -0.106 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.667 + or -0.099 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.665 + or -0.096 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.665 + or -0.096 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.665 + or -0.098 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.707 + or -0.07 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.702 + or -0.081 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.702 + or -0.081 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.703 + or -0.081 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.707 + or -0.066 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.708 + or -0.067 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.708 + or -0.067 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.708 + or -0.067 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.709 + or -0.068 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.708 + or -0.067 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.708 + or -0.067 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.708 + or -0.067 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.709 + or -0.068 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.709 + or -0.068 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.709 + or -0.068 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.709 + or -0.068 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df8da6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.709\n",
      "Logistic Regression  average log_loss is 0.577\n",
      "Logistic Regression  average brier score is 0.191\n",
      "Logistic Regression  average auc is 0.779\n",
      "Logistic Regression  average recall is 0.759\n",
      "Logistic Regression  average precision is 0.690\n",
      "Logistic Regression  average f1 is 0.722\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 100,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f607cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1194856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.0001}\n",
      "Best Score is : 0.6514525993883793 \n",
      "\n",
      "\n",
      "0.637 + or -0.078 for the {'var_smoothing': 1.0}\n",
      "0.635 + or -0.075 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.634 + or -0.077 for the {'var_smoothing': 0.657933224657568}\n",
      "0.64 + or -0.075 for the {'var_smoothing': 0.533669923120631}\n",
      "0.641 + or -0.075 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.645 + or -0.077 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.644 + or -0.077 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.642 + or -0.073 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.639 + or -0.072 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.639 + or -0.068 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.64 + or -0.068 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.64 + or -0.068 for the {'var_smoothing': 0.1}\n",
      "0.64 + or -0.07 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.64 + or -0.07 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.643 + or -0.07 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.643 + or -0.07 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.643 + or -0.07 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.642 + or -0.069 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.643 + or -0.07 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.644 + or -0.071 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.644 + or -0.071 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.644 + or -0.071 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.644 + or -0.071 for the {'var_smoothing': 0.01}\n",
      "0.645 + or -0.072 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.646 + or -0.071 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.647 + or -0.07 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.648 + or -0.071 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.648 + or -0.071 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.649 + or -0.072 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.65 + or -0.072 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.001}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 0.0001}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 1e-05}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1e-06}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.651 + or -0.073 for the {'var_smoothing': 1e-07}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1e-08}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.65 + or -0.074 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6833d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.651\n",
      "Naive Bayes  average log_loss is 1.769\n",
      "Naive Bayes  average brier score is 0.318\n",
      "Naive Bayes  average auc is 0.752\n",
      "Naive Bayes  average recall is 0.949\n",
      "Naive Bayes  average precision is 0.597\n",
      "Naive Bayes  average f1 is 0.732\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.0001)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426b2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Input With Post admission variables\n",
    "X = X_balanced[[\"Age\", \"Oxygen_Saturation_Percent\", \"Sweating\", \"Abnormal_Lung_Signs\", \"CKD\",\n",
    "             \"Hospitalization_14_days_ago\", \"BMI\", \"Sex\", \"Current_Smoking\", \"Fever\", \"Chestpain\",\n",
    "               \"Hypertension\", \"Cancers\", \"Cardiovascular_Disease\", \"Immunosuppressant_Drugs\", \n",
    "                \"Antihypertensive_drug\", \"Pantoprazole\",'Intubation_Duration_Day','NIV_Duration_Day',\n",
    "               \"ICU_admission\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f219c06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.7595141  0.7595141  0.55446823\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.76043153 0.76043153 0.74011213        nan        nan        nan\n",
      "        nan        nan 0.76688753 0.76410975 0.76410975 0.76411825\n",
      "        nan        nan        nan        nan        nan 0.78253483\n",
      " 0.78442066 0.78442066 0.7825773         nan        nan        nan\n",
      "        nan        nan 0.78713897 0.78344376 0.78344376 0.78160041\n",
      "        nan        nan        nan        nan        nan 0.78992525\n",
      " 0.7880649  0.78622154 0.7880649         nan        nan        nan\n",
      "        nan        nan 0.79085117 0.78899932 0.78807339 0.78899932\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b5656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7908511722731906 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.76 + or -0.104 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.76 + or -0.104 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.554 + or -0.036 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.76 + or -0.096 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.76 + or -0.096 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.74 + or -0.093 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.767 + or -0.093 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.764 + or -0.1 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.764 + or -0.1 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.764 + or -0.092 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.783 + or -0.096 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.784 + or -0.098 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.784 + or -0.098 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.783 + or -0.098 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.787 + or -0.096 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.783 + or -0.094 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.783 + or -0.094 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.782 + or -0.094 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.79 + or -0.095 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.788 + or -0.097 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.786 + or -0.094 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788 + or -0.097 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791 + or -0.098 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.789 + or -0.096 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.788 + or -0.094 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.789 + or -0.096 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25a0ce69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.791\n",
      "Logistic Regression  average log_loss is 0.487\n",
      "Logistic Regression  average brier score is 0.153\n",
      "Logistic Regression  average auc is 0.857\n",
      "Logistic Regression  average recall is 0.785\n",
      "Logistic Regression  average precision is 0.801\n",
      "Logistic Regression  average f1 is 0.791\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1000,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60ace70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2518af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.3511191734215131}\n",
      "Best Score is : 0.72353041114509 \n",
      "\n",
      "\n",
      "0.714 + or -0.108 for the {'var_smoothing': 1.0}\n",
      "0.712 + or -0.105 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.715 + or -0.109 for the {'var_smoothing': 0.657933224657568}\n",
      "0.72 + or -0.107 for the {'var_smoothing': 0.533669923120631}\n",
      "0.719 + or -0.096 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.724 + or -0.096 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.714 + or -0.096 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.704 + or -0.097 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.703 + or -0.093 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.699 + or -0.093 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.684 + or -0.093 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.684 + or -0.093 for the {'var_smoothing': 0.1}\n",
      "0.678 + or -0.091 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.667 + or -0.091 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.661 + or -0.087 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.657 + or -0.086 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.655 + or -0.083 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.657 + or -0.081 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.653 + or -0.082 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.653 + or -0.08 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.655 + or -0.08 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.656 + or -0.08 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.656 + or -0.08 for the {'var_smoothing': 0.01}\n",
      "0.657 + or -0.08 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.658 + or -0.079 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.659 + or -0.078 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.66 + or -0.077 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.663 + or -0.077 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.663 + or -0.077 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.663 + or -0.077 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.663 + or -0.077 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.664 + or -0.076 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.665 + or -0.077 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.666 + or -0.077 for the {'var_smoothing': 0.001}\n",
      "0.667 + or -0.078 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.668 + or -0.077 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.668 + or -0.077 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.67 + or -0.074 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.673 + or -0.075 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.671 + or -0.075 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.671 + or -0.075 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.672 + or -0.076 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.672 + or -0.076 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.673 + or -0.077 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.672 + or -0.075 for the {'var_smoothing': 0.0001}\n",
      "0.675 + or -0.075 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.677 + or -0.077 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.678 + or -0.077 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.681 + or -0.078 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.681 + or -0.076 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.681 + or -0.078 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.681 + or -0.078 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.681 + or -0.078 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.683 + or -0.078 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.687 + or -0.079 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.687 + or -0.08 for the {'var_smoothing': 1e-05}\n",
      "0.691 + or -0.08 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.69 + or -0.081 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.69 + or -0.081 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.695 + or -0.082 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.696 + or -0.082 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.697 + or -0.082 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.698 + or -0.082 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.699 + or -0.082 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.699 + or -0.081 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.699 + or -0.081 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 1e-06}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.701 + or -0.081 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 1e-07}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.7 + or -0.081 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1e-08}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.701 + or -0.082 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bfa5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.724\n",
      "Naive Bayes  average log_loss is 0.576\n",
      "Naive Bayes  average brier score is 0.188\n",
      "Naive Bayes  average auc is 0.829\n",
      "Naive Bayes  average recall is 0.899\n",
      "Naive Bayes  average precision is 0.670\n",
      "Naive Bayes  average f1 is 0.767\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.3511191734215131)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea19dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = nb.predict_proba(xtest)[:,1]\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'Naive Bayes Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'Naive Bayes Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d7e7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes Cal  average accuracy is 0.747\n",
      "Naive Bayes Cal  average log_loss is 0.555\n",
      "Naive Bayes Cal  average brier score is 0.184\n",
      "Naive Bayes Cal  average auc is 0.805\n",
      "Naive Bayes Cal  average recall is 0.784\n",
      "Naive Bayes Cal  average precision is 0.744\n",
      "Naive Bayes Cal  average f1 is 0.759\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "showResults(calibrated, \"Naive Bayes Cal\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9858d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance with extratreesclassifier Input\n",
    "X = X_balanced[[\"Age\" , \"Oxygen_Saturation_Percent\", \"CKD\",\"Respiratory_rate\", \"DiastolicBP\", \"SystolicBP\",\n",
    "                \"BMI\",\"Cancers\",\"Average_Daily_Use_Cigarettes\" ,\"Fever\", \"Pantoprazole\", \"Abnormal_Lung_Signs\",\n",
    "                \"Drug_history\", \"Current_Smoking\", \"Diabetes\", \"Cardiovascular_Disease\" , \"Dyspnea\", \"Hospitalization_14_days_ago\",\n",
    "                \"Hypertension\", \"Antihypertensive_drug\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0462ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.6461349  0.6461349  0.58411485\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.65073055 0.65073055 0.64609242        nan        nan        nan\n",
      "        nan        nan 0.67094801 0.65349134 0.65349134 0.6553262\n",
      "        nan        nan        nan        nan        nan 0.70965002\n",
      " 0.68758919 0.68758919 0.69034149        nan        nan        nan\n",
      "        nan        nan 0.70319402 0.70411995 0.70411995 0.70411995\n",
      "        nan        nan        nan        nan        nan 0.7059633\n",
      " 0.70780666 0.70780666 0.70780666        nan        nan        nan\n",
      "        nan        nan 0.70688923 0.70780666 0.70781515 0.70873259\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e76b74c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7096500169894665 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.646 + or -0.115 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.646 + or -0.115 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.584 + or -0.058 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.651 + or -0.111 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.651 + or -0.111 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.646 + or -0.098 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.671 + or -0.09 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.653 + or -0.104 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.653 + or -0.104 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.655 + or -0.102 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.71 + or -0.074 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.688 + or -0.089 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.688 + or -0.089 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.69 + or -0.087 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.703 + or -0.08 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.704 + or -0.081 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.704 + or -0.081 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.704 + or -0.081 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.706 + or -0.081 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.708 + or -0.081 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.708 + or -0.081 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.708 + or -0.081 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.707 + or -0.082 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.708 + or -0.082 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.708 + or -0.082 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.709 + or -0.082 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab109a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.710\n",
      "Logistic Regression  average log_loss is 0.580\n",
      "Logistic Regression  average brier score is 0.197\n",
      "Logistic Regression  average auc is 0.764\n",
      "Logistic Regression  average recall is 0.715\n",
      "Logistic Regression  average precision is 0.703\n",
      "Logistic Regression  average f1 is 0.707\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54137ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ae8b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.002848035868435802}\n",
      "Best Score is : 0.6764101257220523 \n",
      "\n",
      "\n",
      "0.66 + or -0.119 for the {'var_smoothing': 1.0}\n",
      "0.659 + or -0.119 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.66 + or -0.115 for the {'var_smoothing': 0.657933224657568}\n",
      "0.662 + or -0.112 for the {'var_smoothing': 0.533669923120631}\n",
      "0.662 + or -0.113 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.658 + or -0.108 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.659 + or -0.1 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.658 + or -0.101 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.656 + or -0.099 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.657 + or -0.098 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.655 + or -0.097 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.654 + or -0.097 for the {'var_smoothing': 0.1}\n",
      "0.654 + or -0.093 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.657 + or -0.095 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.654 + or -0.095 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.656 + or -0.092 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.658 + or -0.09 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.665 + or -0.09 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.668 + or -0.09 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.671 + or -0.086 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.676 + or -0.088 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.675 + or -0.082 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 0.01}\n",
      "0.674 + or -0.079 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.673 + or -0.079 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.672 + or -0.078 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.676 + or -0.073 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.676 + or -0.074 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.676 + or -0.076 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.675 + or -0.074 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.671 + or -0.072 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.673 + or -0.07 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.671 + or -0.071 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.671 + or -0.071 for the {'var_smoothing': 0.001}\n",
      "0.67 + or -0.068 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.669 + or -0.068 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.669 + or -0.068 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.669 + or -0.068 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.668 + or -0.067 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.669 + or -0.065 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.669 + or -0.065 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.668 + or -0.064 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.668 + or -0.064 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.667 + or -0.064 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.667 + or -0.064 for the {'var_smoothing': 0.0001}\n",
      "0.667 + or -0.064 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.667 + or -0.064 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.667 + or -0.064 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.668 + or -0.064 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.668 + or -0.064 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1e-05}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1e-06}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1e-07}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1e-08}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.668 + or -0.065 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78c23bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.676\n",
      "Naive Bayes  average log_loss is 0.683\n",
      "Naive Bayes  average brier score is 0.224\n",
      "Naive Bayes  average auc is 0.721\n",
      "Naive Bayes  average recall is 0.676\n",
      "Naive Bayes  average precision is 0.673\n",
      "Naive Bayes  average f1 is 0.673\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.002848035868435802)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0882e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance with extratreesclassifier Input + Post admission variables\n",
    "X = X_balanced[[\"ICU_admission\", \"Age\", \"Oxygen_Saturation_Percent\", \"CKD\", \"DiastolicBP\", \"Respiratory_rate\",\n",
    "               \"SystolicBP\", \"Intubation_Duration_Day\", \"BMI\", \"Cancers\", \"Dyspnea\", \"Drug_history\", \"Pantoprazole\",\n",
    "               \"Abnormal_Lung_Signs\", \"Fever\", \"Cardiovascular_Disease\", \"Antihypertensive_drug\", \"Hypertension\",\n",
    "               \"Hospitalization_14_days_ago\", \"Average_Daily_Use_Cigarettes\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "deb69738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.75404349 0.75404349 0.52586646\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.7512827  0.7512827  0.71151886        nan        nan        nan\n",
      "        nan        nan 0.76044852 0.76139144 0.76139144 0.74476724\n",
      "        nan        nan        nan        nan        nan 0.76136595\n",
      " 0.76044852 0.76044852 0.76046551        nan        nan        nan\n",
      "        nan        nan 0.77514441 0.76872239 0.76780496 0.76778797\n",
      "        nan        nan        nan        nan        nan 0.77793068\n",
      " 0.76960584 0.77329256 0.76775399        nan        nan        nan\n",
      "        nan        nan 0.77702175 0.77515291 0.77330955 0.77607883\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c87086b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7779306829765547 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.754 + or -0.112 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.754 + or -0.112 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.526 + or -0.014 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.751 + or -0.112 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.751 + or -0.112 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.712 + or -0.091 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.76 + or -0.096 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.761 + or -0.103 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.761 + or -0.103 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.745 + or -0.104 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.761 + or -0.097 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.76 + or -0.102 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.76 + or -0.102 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.76 + or -0.102 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.775 + or -0.084 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.769 + or -0.095 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.768 + or -0.095 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.768 + or -0.093 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.778 + or -0.086 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.77 + or -0.086 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.773 + or -0.082 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.768 + or -0.085 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.777 + or -0.089 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.775 + or -0.087 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.773 + or -0.088 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.776 + or -0.088 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461bc878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.778\n",
      "Logistic Regression  average log_loss is 0.497\n",
      "Logistic Regression  average brier score is 0.160\n",
      "Logistic Regression  average auc is 0.842\n",
      "Logistic Regression  average recall is 0.785\n",
      "Logistic Regression  average precision is 0.779\n",
      "Logistic Regression  average f1 is 0.780\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 100,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e914b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c036a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.004328761281083057}\n",
      "Best Score is : 0.7493034318722391 \n",
      "\n",
      "\n",
      "0.737 + or -0.115 for the {'var_smoothing': 1.0}\n",
      "0.737 + or -0.113 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.737 + or -0.113 for the {'var_smoothing': 0.657933224657568}\n",
      "0.735 + or -0.11 for the {'var_smoothing': 0.533669923120631}\n",
      "0.734 + or -0.111 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.73 + or -0.109 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.727 + or -0.11 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.729 + or -0.108 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.727 + or -0.105 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.73 + or -0.101 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.729 + or -0.1 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.731 + or -0.1 for the {'var_smoothing': 0.1}\n",
      "0.731 + or -0.1 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.733 + or -0.095 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.736 + or -0.096 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.737 + or -0.097 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.737 + or -0.1 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.737 + or -0.099 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.739 + or -0.097 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.743 + or -0.09 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.747 + or -0.087 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.747 + or -0.089 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.747 + or -0.089 for the {'var_smoothing': 0.01}\n",
      "0.746 + or -0.088 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.746 + or -0.09 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.747 + or -0.088 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.749 + or -0.086 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.745 + or -0.086 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.745 + or -0.087 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.741 + or -0.087 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.741 + or -0.083 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.739 + or -0.083 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.74 + or -0.085 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.741 + or -0.084 for the {'var_smoothing': 0.001}\n",
      "0.74 + or -0.087 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.739 + or -0.085 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.739 + or -0.086 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.746 + or -0.077 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.747 + or -0.079 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.746 + or -0.079 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.748 + or -0.076 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.747 + or -0.074 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.746 + or -0.073 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.746 + or -0.072 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.747 + or -0.07 for the {'var_smoothing': 0.0001}\n",
      "0.746 + or -0.071 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.741 + or -0.068 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.742 + or -0.066 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.743 + or -0.066 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.741 + or -0.065 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.735 + or -0.062 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.73 + or -0.064 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.73 + or -0.068 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.73 + or -0.068 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.729 + or -0.071 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.726 + or -0.068 for the {'var_smoothing': 1e-05}\n",
      "0.726 + or -0.066 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.722 + or -0.063 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.721 + or -0.062 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.72 + or -0.062 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.72 + or -0.062 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.719 + or -0.062 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.72 + or -0.063 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.72 + or -0.061 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 1e-06}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.719 + or -0.063 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1e-07}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1e-08}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.718 + or -0.061 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5783f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.749\n",
      "Naive Bayes  average log_loss is 0.581\n",
      "Naive Bayes  average brier score is 0.184\n",
      "Naive Bayes  average auc is 0.805\n",
      "Naive Bayes  average recall is 0.762\n",
      "Naive Bayes  average precision is 0.753\n",
      "Naive Bayes  average f1 is 0.755\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.004328761281083057)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f1e5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Logistic Regression Input\n",
    "X = X_balanced[[\"Abnormal_Lung_Signs\", \"Antihypertensive_drug\", \"CKD\", \"COPD\", \"Cancers\", \"Cardiovascular_Disease\", \n",
    "                \"Chestpain\", \"Current_Smoking\", \"Diabetes\", \"Drug_history\", \"Dyspnea\", \"Fever\", \"History_hookah\", \n",
    "                \"Hospitalization_14_days_ago\", \"Hypertension\", \"Immunosuppressant_Drugs\", \"Oxygen_Saturation_Percent\", \n",
    "                \"Pantoprazole\", \"Sex\", \"Sweating\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fa9b844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.66275059 0.66275059 0.62665647\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.67195889 0.67195889 0.67654604        nan        nan        nan\n",
      "        nan        nan 0.68760618 0.68481142 0.68481142 0.68942406\n",
      "        nan        nan        nan        nan        nan 0.72076113\n",
      " 0.7096755  0.7096755  0.70230207        nan        nan        nan\n",
      "        nan        nan 0.72076962 0.72170404 0.72170404 0.71985219\n",
      "        nan        nan        nan        nan        nan 0.72076962\n",
      " 0.72076962 0.72076962 0.72076962        nan        nan        nan\n",
      "        nan        nan 0.72076962 0.72076962 0.72076962 0.72076962\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6aad9ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.7217040434930343 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.663 + or -0.126 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.663 + or -0.126 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.627 + or -0.089 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.672 + or -0.116 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.672 + or -0.116 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.677 + or -0.104 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.688 + or -0.114 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.685 + or -0.102 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.685 + or -0.102 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.689 + or -0.102 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.107 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.71 + or -0.099 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.71 + or -0.099 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.702 + or -0.103 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.109 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.722 + or -0.105 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.722 + or -0.105 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.72 + or -0.105 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.108 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.721 + or -0.108 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.721 + or -0.108 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.108 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.108 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.721 + or -0.108 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.721 + or -0.108 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.108 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd677709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.722\n",
      "Logistic Regression  average log_loss is 0.586\n",
      "Logistic Regression  average brier score is 0.194\n",
      "Logistic Regression  average auc is 0.770\n",
      "Logistic Regression  average recall is 0.774\n",
      "Logistic Regression  average precision is 0.694\n",
      "Logistic Regression  average f1 is 0.730\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 10,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d00dfe95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7219a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.08111308307896872}\n",
      "Best Score is : 0.6755521576622494 \n",
      "\n",
      "\n",
      "0.624 + or -0.09 for the {'var_smoothing': 1.0}\n",
      "0.631 + or -0.09 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.635 + or -0.094 for the {'var_smoothing': 0.657933224657568}\n",
      "0.648 + or -0.091 for the {'var_smoothing': 0.533669923120631}\n",
      "0.655 + or -0.092 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.661 + or -0.092 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.668 + or -0.094 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.669 + or -0.096 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.672 + or -0.098 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.673 + or -0.097 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.675 + or -0.098 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.675 + or -0.097 for the {'var_smoothing': 0.1}\n",
      "0.676 + or -0.092 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.673 + or -0.094 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.675 + or -0.093 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.676 + or -0.091 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.674 + or -0.092 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.674 + or -0.09 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.674 + or -0.09 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.675 + or -0.088 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.675 + or -0.088 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.675 + or -0.088 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.676 + or -0.089 for the {'var_smoothing': 0.01}\n",
      "0.676 + or -0.089 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.676 + or -0.089 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.675 + or -0.089 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.676 + or -0.088 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.675 + or -0.088 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.674 + or -0.086 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.674 + or -0.086 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.674 + or -0.086 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.674 + or -0.086 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.671 + or -0.087 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.67 + or -0.088 for the {'var_smoothing': 0.001}\n",
      "0.67 + or -0.088 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.672 + or -0.085 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.672 + or -0.085 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.672 + or -0.085 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.671 + or -0.087 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.671 + or -0.087 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.671 + or -0.087 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.672 + or -0.085 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 0.0001}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1e-05}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 1e-06}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.673 + or -0.084 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1e-07}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1e-08}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.674 + or -0.082 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d334f57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.675\n",
      "Naive Bayes  average log_loss is 1.889\n",
      "Naive Bayes  average brier score is 0.303\n",
      "Naive Bayes  average auc is 0.756\n",
      "Naive Bayes  average recall is 0.905\n",
      "Naive Bayes  average precision is 0.619\n",
      "Naive Bayes  average f1 is 0.735\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.08111308307896872)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ee04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Logistic Regression Input + Post admission variables\n",
    "X = X_balanced[['Abnormal_Lung_Signs', 'Age', 'Antihypertensive_drug', 'BMI', 'CKD', 'COPD', \n",
    "                'Cancers', 'Cardiovascular_Disease', 'Chestpain', 'Current_Smoking', 'Diabetes', \n",
    "                'Drug_history', 'Dyspnea', 'Fever', 'History_hookah', 'Hospitalization_14_days_ago', \n",
    "                'Hypertension', 'ICU_admission', 'Immunosuppressant_Drugs', 'Intubation_Duration_Day', \n",
    "                'NIV_Duration_Day', 'Oxygen_Saturation_Percent', 'Pantoprazole', 'Sex', 'Sweating']]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f82edf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.77344546 0.77344546 0.54891267\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.77897554 0.77897554 0.75124873        nan        nan        nan\n",
      "        nan        nan 0.78996772 0.78637445 0.78637445 0.78539755\n",
      "        nan        nan        nan        nan        nan 0.80474006\n",
      " 0.79744309 0.79744309 0.80020387        nan        nan        nan\n",
      "        nan        nan 0.80841828 0.81213897 0.81213897 0.81028712\n",
      "        nan        nan        nan        nan        nan 0.81121305\n",
      " 0.81029562 0.81027863 0.80937819        nan        nan        nan\n",
      "        nan        nan 0.81029562 0.81120455 0.80199626 0.81120455\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "52f2a7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.8121389738362217 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.773 + or -0.121 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.773 + or -0.121 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.549 + or -0.023 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.779 + or -0.121 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.779 + or -0.121 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.751 + or -0.112 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.79 + or -0.104 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.786 + or -0.125 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.786 + or -0.125 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.785 + or -0.116 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.805 + or -0.107 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.797 + or -0.125 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.797 + or -0.125 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.8 + or -0.121 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.808 + or -0.108 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.812 + or -0.112 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.812 + or -0.112 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.81 + or -0.112 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.811 + or -0.11 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.81 + or -0.114 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.81 + or -0.112 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.809 + or -0.115 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.81 + or -0.112 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.811 + or -0.112 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.802 + or -0.108 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.811 + or -0.112 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80977b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.812\n",
      "Logistic Regression  average log_loss is 0.467\n",
      "Logistic Regression  average brier score is 0.147\n",
      "Logistic Regression  average auc is 0.863\n",
      "Logistic Regression  average recall is 0.820\n",
      "Logistic Regression  average precision is 0.810\n",
      "Logistic Regression  average f1 is 0.814\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 10,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f46c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(lr, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = lr.decision_function(xtest)\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'Logistic Regression Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'Logistic Regression Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74906ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression Cal  average accuracy is 0.804\n",
      "Logistic Regression Cal  average log_loss is 0.464\n",
      "Logistic Regression Cal  average brier score is 0.148\n",
      "Logistic Regression Cal  average auc is 0.863\n",
      "Logistic Regression Cal  average recall is 0.805\n",
      "Logistic Regression Cal  average precision is 0.807\n",
      "Logistic Regression Cal  average f1 is 0.805\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(lr, method='sigmoid', cv=10)\n",
    "showResults(calibrated, \"Logistic Regression Cal\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46b20612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63e48eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 2.848035868435799e-07}\n",
      "Best Score is : 0.716106014271152 \n",
      "\n",
      "\n",
      "0.702 + or -0.108 for the {'var_smoothing': 1.0}\n",
      "0.704 + or -0.116 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.704 + or -0.116 for the {'var_smoothing': 0.657933224657568}\n",
      "0.703 + or -0.111 for the {'var_smoothing': 0.533669923120631}\n",
      "0.705 + or -0.113 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.71 + or -0.113 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.703 + or -0.11 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.699 + or -0.11 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.694 + or -0.11 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.695 + or -0.105 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.691 + or -0.103 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.694 + or -0.103 for the {'var_smoothing': 0.1}\n",
      "0.693 + or -0.102 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.691 + or -0.099 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.689 + or -0.101 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.688 + or -0.101 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.688 + or -0.103 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.687 + or -0.103 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.688 + or -0.101 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.688 + or -0.1 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.685 + or -0.097 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.685 + or -0.097 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.685 + or -0.097 for the {'var_smoothing': 0.01}\n",
      "0.684 + or -0.096 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.684 + or -0.097 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.685 + or -0.097 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.687 + or -0.096 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.686 + or -0.093 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.686 + or -0.095 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.686 + or -0.095 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.001}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.684 + or -0.098 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.686 + or -0.095 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.688 + or -0.096 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.69 + or -0.096 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.691 + or -0.095 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.692 + or -0.095 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.693 + or -0.096 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.694 + or -0.097 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.697 + or -0.096 for the {'var_smoothing': 0.0001}\n",
      "0.698 + or -0.097 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.699 + or -0.097 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.698 + or -0.096 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.7 + or -0.096 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.701 + or -0.097 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.705 + or -0.097 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.709 + or -0.097 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.709 + or -0.097 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.709 + or -0.097 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.711 + or -0.098 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.711 + or -0.099 for the {'var_smoothing': 1e-05}\n",
      "0.712 + or -0.096 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.712 + or -0.095 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.712 + or -0.095 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.712 + or -0.096 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.712 + or -0.096 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.712 + or -0.097 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.712 + or -0.097 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.713 + or -0.098 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.712 + or -0.099 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.712 + or -0.099 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.712 + or -0.099 for the {'var_smoothing': 1e-06}\n",
      "0.714 + or -0.099 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.714 + or -0.099 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.714 + or -0.099 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.714 + or -0.099 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.714 + or -0.099 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 1e-07}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.716 + or -0.097 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.715 + or -0.099 for the {'var_smoothing': 1e-08}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.714 + or -0.1 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88259234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.716\n",
      "Naive Bayes  average log_loss is 1.661\n",
      "Naive Bayes  average brier score is 0.237\n",
      "Naive Bayes  average auc is 0.843\n",
      "Naive Bayes  average recall is 0.921\n",
      "Naive Bayes  average precision is 0.656\n",
      "Naive Bayes  average f1 is 0.766\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 2.848035868435799e-07)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb7f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Gradient Boosting Input\n",
    "X = X_balanced[[\"Age\", \"CKD\", \"Cancers\", \"DiastolicBP\", \"Oxygen_Saturation_Percent\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e599f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.54052837 0.54052837 0.66511213\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.54878525 0.54878525 0.54969419        nan        nan        nan\n",
      "        nan        nan 0.52122834 0.58846415 0.58846415 0.59952429\n",
      "        nan        nan        nan        nan        nan 0.67426945\n",
      " 0.66873938 0.66873938 0.66688753        nan        nan        nan\n",
      "        nan        nan 0.6724261  0.67150866 0.67150866 0.67335202\n",
      "        nan        nan        nan        nan        nan 0.67058274\n",
      " 0.67058274 0.67058274 0.67150866        nan        nan        nan\n",
      "        nan        nan 0.67058274 0.67058274 0.67058274 0.67058274\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79ebfe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.6742694529391777 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.541 + or -0.067 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.541 + or -0.067 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.665 + or -0.04 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.549 + or -0.053 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.549 + or -0.053 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.55 + or -0.055 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.521 + or -0.04 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.588 + or -0.061 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.588 + or -0.061 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.6 + or -0.058 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.674 + or -0.044 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.669 + or -0.04 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.669 + or -0.04 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.667 + or -0.04 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.672 + or -0.045 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.672 + or -0.048 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.672 + or -0.048 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.673 + or -0.048 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.671 + or -0.045 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.671 + or -0.045 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.671 + or -0.045 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.672 + or -0.043 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.671 + or -0.045 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.671 + or -0.045 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.671 + or -0.045 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.671 + or -0.045 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2569a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.674\n",
      "Logistic Regression  average log_loss is 0.628\n",
      "Logistic Regression  average brier score is 0.219\n",
      "Logistic Regression  average auc is 0.708\n",
      "Logistic Regression  average recall is 0.716\n",
      "Logistic Regression  average precision is 0.662\n",
      "Logistic Regression  average f1 is 0.687\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "102b40b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f986c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.001873817422860383}\n",
      "Best Score is : 0.6540180088345227 \n",
      "\n",
      "\n",
      "0.541 + or -0.053 for the {'var_smoothing': 1.0}\n",
      "0.541 + or -0.055 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.54 + or -0.055 for the {'var_smoothing': 0.657933224657568}\n",
      "0.54 + or -0.054 for the {'var_smoothing': 0.533669923120631}\n",
      "0.54 + or -0.057 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.54 + or -0.057 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.54 + or -0.054 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.537 + or -0.047 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.535 + or -0.046 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.535 + or -0.046 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.533 + or -0.046 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.533 + or -0.052 for the {'var_smoothing': 0.1}\n",
      "0.54 + or -0.056 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.554 + or -0.072 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.579 + or -0.07 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.593 + or -0.06 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.605 + or -0.059 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.609 + or -0.057 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.619 + or -0.052 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.623 + or -0.047 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.624 + or -0.042 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.63 + or -0.038 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.63 + or -0.036 for the {'var_smoothing': 0.01}\n",
      "0.636 + or -0.037 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.641 + or -0.035 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.644 + or -0.033 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.649 + or -0.027 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.648 + or -0.026 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.648 + or -0.026 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.651 + or -0.024 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.654 + or -0.024 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.654 + or -0.025 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.654 + or -0.026 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.653 + or -0.027 for the {'var_smoothing': 0.001}\n",
      "0.654 + or -0.027 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.654 + or -0.028 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.654 + or -0.028 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.654 + or -0.028 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.654 + or -0.028 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.653 + or -0.029 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.654 + or -0.029 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 0.0001}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1e-05}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1e-06}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1e-07}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1e-08}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.653 + or -0.03 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9646ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.654\n",
      "Naive Bayes  average log_loss is 0.698\n",
      "Naive Bayes  average brier score is 0.236\n",
      "Naive Bayes  average auc is 0.682\n",
      "Naive Bayes  average recall is 0.677\n",
      "Naive Bayes  average precision is 0.649\n",
      "Naive Bayes  average f1 is 0.660\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.001873817422860383)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "811b16d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Gradient Boosting Input + Post admission variables\n",
    "X = X_balanced[['Age', 'CKD', 'ICU_admission', 'Intubation_Duration_Day']]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6e90a18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.73916922 0.73916922 0.5\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.74009514 0.74009514 0.69199796        nan        nan        nan\n",
      "        nan        nan 0.74471628 0.73916922 0.73916922 0.73176181\n",
      "        nan        nan        nan        nan        nan 0.74749405\n",
      " 0.75026334 0.75026334 0.74932892        nan        nan        nan\n",
      "        nan        nan 0.74654264 0.7456422  0.7456422  0.74471628\n",
      "        nan        nan        nan        nan        nan 0.74746007\n",
      " 0.74379884 0.74379884 0.74379884        nan        nan        nan\n",
      "        nan        nan 0.74746007 0.74655114 0.74655114 0.74655114\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "95fc61b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.7502633367312267 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.739 + or -0.082 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.739 + or -0.082 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.74 + or -0.082 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.74 + or -0.082 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.692 + or -0.064 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.745 + or -0.088 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.739 + or -0.082 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.739 + or -0.082 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.732 + or -0.078 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.747 + or -0.091 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.75 + or -0.092 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.75 + or -0.092 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.749 + or -0.092 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.747 + or -0.088 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.746 + or -0.09 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.746 + or -0.09 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.745 + or -0.09 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.747 + or -0.088 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.744 + or -0.088 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.744 + or -0.088 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.744 + or -0.088 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.747 + or -0.088 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.747 + or -0.088 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.747 + or -0.088 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.747 + or -0.088 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71336a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.750\n",
      "Logistic Regression  average log_loss is 0.547\n",
      "Logistic Regression  average brier score is 0.181\n",
      "Logistic Regression  average auc is 0.828\n",
      "Logistic Regression  average recall is 0.712\n",
      "Logistic Regression  average precision is 0.787\n",
      "Logistic Regression  average f1 is 0.743\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1d8e7b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cd4dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.533669923120631}\n",
      "Best Score is : 0.7317703024125043 \n",
      "\n",
      "\n",
      "0.731 + or -0.079 for the {'var_smoothing': 1.0}\n",
      "0.731 + or -0.079 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.731 + or -0.079 for the {'var_smoothing': 0.657933224657568}\n",
      "0.732 + or -0.08 for the {'var_smoothing': 0.533669923120631}\n",
      "0.726 + or -0.079 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.722 + or -0.076 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.715 + or -0.074 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.716 + or -0.073 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.713 + or -0.078 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.713 + or -0.078 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.713 + or -0.078 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.713 + or -0.078 for the {'var_smoothing': 0.1}\n",
      "0.714 + or -0.078 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.717 + or -0.074 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.718 + or -0.074 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.717 + or -0.071 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.718 + or -0.072 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.718 + or -0.077 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.718 + or -0.077 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.719 + or -0.077 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.718 + or -0.078 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.719 + or -0.077 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.72 + or -0.078 for the {'var_smoothing': 0.01}\n",
      "0.721 + or -0.079 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.721 + or -0.078 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.72 + or -0.078 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.722 + or -0.08 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.724 + or -0.08 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.724 + or -0.08 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.725 + or -0.079 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.725 + or -0.08 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.725 + or -0.08 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.723 + or -0.079 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.722 + or -0.079 for the {'var_smoothing': 0.001}\n",
      "0.719 + or -0.077 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.719 + or -0.076 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.718 + or -0.076 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.718 + or -0.074 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.717 + or -0.073 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.716 + or -0.072 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.717 + or -0.07 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.716 + or -0.065 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.714 + or -0.063 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.711 + or -0.057 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.709 + or -0.058 for the {'var_smoothing': 0.0001}\n",
      "0.708 + or -0.057 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.705 + or -0.055 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.704 + or -0.053 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.7 + or -0.051 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.703 + or -0.051 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.706 + or -0.052 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.706 + or -0.052 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.704 + or -0.055 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.701 + or -0.053 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.701 + or -0.054 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.703 + or -0.054 for the {'var_smoothing': 1e-05}\n",
      "0.702 + or -0.054 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.7 + or -0.052 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.701 + or -0.052 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.702 + or -0.054 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.701 + or -0.055 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.699 + or -0.054 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.698 + or -0.053 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.697 + or -0.052 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.698 + or -0.051 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.697 + or -0.054 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.697 + or -0.054 for the {'var_smoothing': 1e-06}\n",
      "0.697 + or -0.054 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.697 + or -0.053 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.696 + or -0.053 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.696 + or -0.053 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 1e-07}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.695 + or -0.053 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.694 + or -0.052 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.694 + or -0.052 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.694 + or -0.052 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1e-08}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.695 + or -0.052 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d95e3ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.732\n",
      "Naive Bayes  average log_loss is 0.582\n",
      "Naive Bayes  average brier score is 0.196\n",
      "Naive Bayes  average auc is 0.830\n",
      "Naive Bayes  average recall is 0.671\n",
      "Naive Bayes  average precision is 0.784\n",
      "Naive Bayes  average f1 is 0.717\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.533669923120631)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c22512b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Random Forest Input\n",
    "X = X_balanced[[\"Abnormal_Lung_Signs\", \"Age\", \"Antihypertensive_drug\", \"Average_Daily_Use_Cigarettes\", \"BMI\", \n",
    "                \"CKD\", \"COPD\", \"Cancers\", \"Cardiovascular_Disease\", \"Chestpain\",\"Current_Smoking\", \n",
    "                \"Diabetes\", \"DiastolicBP\", \"Drug_history\", \"Dyspnea\", \"Fever\", \"History_hookah\", \n",
    "                \"Hospitalization_14_days_ago\", \"Hypertension\", \"Immunosuppressant_Drugs\", \n",
    "                \"Oxygen_Saturation_Percent\", \"Pantoprazole\", \"Respiratory_rate\", \"Sex\", \"Sweating\", \n",
    "                \"SystolicBP\", \"Total_Lung_Involvement_Percent\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "200a217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.66550289 0.66550289 0.63498131\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.67471118 0.67471118 0.68118417        nan        nan        nan\n",
      "        nan        nan 0.69960924 0.6912844  0.6912844  0.69771492\n",
      "        nan        nan        nan        nan        nan 0.73269623\n",
      " 0.72906048 0.72906048 0.72906048        nan        nan        nan\n",
      "        nan        nan 0.72530581 0.73361366 0.73361366 0.73269623\n",
      "        nan        nan        nan        nan        nan 0.72719164\n",
      " 0.73086137 0.72809208 0.73086137        nan        nan        nan\n",
      "        nan        nan 0.7290265  0.72719164 0.72716616 0.72810907\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83a0f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.7336136595310908 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.666 + or -0.121 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.666 + or -0.121 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.635 + or -0.092 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.675 + or -0.115 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.675 + or -0.115 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 + or -0.116 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.7 + or -0.118 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.691 + or -0.106 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.691 + or -0.106 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.698 + or -0.1 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.733 + or -0.084 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.729 + or -0.096 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.729 + or -0.096 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.729 + or -0.096 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.725 + or -0.082 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.734 + or -0.085 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.734 + or -0.085 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.733 + or -0.087 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.727 + or -0.089 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.731 + or -0.086 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.728 + or -0.086 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.731 + or -0.086 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.729 + or -0.086 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.727 + or -0.086 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.727 + or -0.086 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.728 + or -0.086 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79b7a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.734\n",
      "Logistic Regression  average log_loss is 0.557\n",
      "Logistic Regression  average brier score is 0.182\n",
      "Logistic Regression  average auc is 0.798\n",
      "Logistic Regression  average recall is 0.770\n",
      "Logistic Regression  average precision is 0.714\n",
      "Logistic Regression  average f1 is 0.739\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 10,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca6611f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(lr, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = lr.decision_function(xtest)\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'Logistic Regression Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'Logistic Regression Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f94c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression Cal  average accuracy is 0.740\n",
      "Logistic Regression Cal  average log_loss is 0.550\n",
      "Logistic Regression Cal  average brier score is 0.183\n",
      "Logistic Regression Cal  average auc is 0.798\n",
      "Logistic Regression Cal  average recall is 0.759\n",
      "Logistic Regression Cal  average precision is 0.727\n",
      "Logistic Regression Cal  average f1 is 0.741\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(lr, method='sigmoid', cv=10)\n",
    "showResults(calibrated, \"Logistic Regression Cal\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1dcba982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "559373de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.012328467394420659}\n",
      "Best Score is : 0.678304451240231 \n",
      "\n",
      "\n",
      "0.627 + or -0.09 for the {'var_smoothing': 1.0}\n",
      "0.633 + or -0.089 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.637 + or -0.096 for the {'var_smoothing': 0.657933224657568}\n",
      "0.649 + or -0.089 for the {'var_smoothing': 0.533669923120631}\n",
      "0.656 + or -0.088 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.663 + or -0.091 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.671 + or -0.094 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.67 + or -0.093 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.673 + or -0.097 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.675 + or -0.099 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.675 + or -0.096 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.676 + or -0.094 for the {'var_smoothing': 0.1}\n",
      "0.675 + or -0.095 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.676 + or -0.091 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.677 + or -0.089 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.677 + or -0.089 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.677 + or -0.089 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.677 + or -0.089 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.676 + or -0.089 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.677 + or -0.087 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.678 + or -0.087 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.678 + or -0.089 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.677 + or -0.088 for the {'var_smoothing': 0.01}\n",
      "0.678 + or -0.086 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.677 + or -0.086 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.677 + or -0.086 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.677 + or -0.086 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.678 + or -0.086 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.676 + or -0.086 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.676 + or -0.086 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.676 + or -0.086 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.676 + or -0.086 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.674 + or -0.088 for the {'var_smoothing': 0.001}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 0.0001}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 1e-05}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.677 + or -0.082 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.676 + or -0.083 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 1e-06}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.675 + or -0.086 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1e-07}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1e-08}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99ad3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.678\n",
      "Naive Bayes  average log_loss is 1.711\n",
      "Naive Bayes  average brier score is 0.294\n",
      "Naive Bayes  average auc is 0.769\n",
      "Naive Bayes  average recall is 0.907\n",
      "Naive Bayes  average precision is 0.622\n",
      "Naive Bayes  average f1 is 0.737\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.012328467394420659)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d942ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEJCAYAAACUk1DVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACDtElEQVR4nO2dd3RUVdeHn+nJpPcAgUACCb2DEHoRkN4EG2ADFRUrioCCL2JFEbCCfmKhIx3pCCi9JqGEAAmBBNJ7pmTK/f6IjEQIaTOZSbjPWlkrc8s5+9w7c/c9Zf+2RBAEARERERGR+x6pvQ0QEREREXEMRIcgIiIiIgKIDkFERERE5B9EhyAiIiIiAogOQURERETkH+T2NqAimM1mCgoKUCgUSCQSe5sjIiIiUi0QBAGDwYCLiwtS6Z39gWrpEAoKCoiNjbW3GSIiIiLVkrCwMNzc3O7YXi0dgkKhAIoapVQqy33+2bNnad68ubXNcmjENt8fiG2+P6homwsLC4mNjbU8Q/9LtXQIt4aJlEolKpWqQmVU9LzqjNjm+wOxzfcHlWlzSUPt4qSyiIiIiAggOgQRERERkX+olkNG98JsNpOYmEhBQUGJx8jlci5cuFCFVtkfsc32w8XFhaCgoLuu6hARcSRs6hDy8/N55JFH+O677wgKCiq278KFC8yYMYOCggLat2/P+++/j1xeeXPS09ORSCSEh4eX+AMsKCjAxcWl0nVVJ8Q22wez2UxSUhLp6en4+/vb1RYRkdKw2StLZGQkjz76KFevXr3r/qlTp/Lee++xY8cOBEFg9erVVqk3OzubgIAA8W1MxCGQSqUEBASQk5Njb1NERErFZk/N1atXM2vWrLu+FSUlJaHT6WjdujUAI0eOZPv27Vap12QylbikSkSkLOgMerK0OegMequUp1AoMBqNVilLRMSW2GzIaO7cuSXuS01Nxc/Pz/LZz8+PlJQUq9UtRi+LVBSdQc+NvGQEQIKE2m4BOCkqt6RR/D6KWAOzWWDboXjSsrW0qGWbOuwyqWw2m4v9SARBqNCP5uzZs3dsk8vl95xQvkVZjrEGbdu25dSpU3dsnzVrFu3atWPo0KHlLnPQoEEsWbKEEydOcPLkSd5///0ynXf16lW+/PJLLl68iEwmIyAggLfeeuuO+Z3bOXHiBN9//z1Llizhf//7H6NHj0aj0Vi2VZRJkyaxePHiMh9/ux3lobz3OceQx62MUQICudpcTIXqcpVxNwoLCzl58mSlyykLVVWPI1HT25yea2Dj0SyupxXSsJaKpgG+NmmzXRxCYGAgaWlpls8VnXBr3rz5HcEZFy5cKHUisaonG+9Wl1wuR6VSVcgOqVSKs7MzKpUKuVxepjLS09N57rnnePrpp5k/fz4SiYRNmzbx4osvsm3bthKH2ZycnJDJZLi4uPDJJ58AcPToUcu2inLixIlynX+7HWWlvPfZYDKg0xcW2+bu7F7pHgIUBVG2atWq0uWUxsmTJ2nXrp3N63EkanKbBUFg7d5LrNh5EZVCxquPtKF3+7qcOnWqQm3W6/V3fZG+hV0cQp06dVCpVJYbuXHjRrp3724PU6oMQRD4+OOP2bdvH/7+/phMJjp27AjAhg0b+PnnnzGbzTRr1oxZs2ahUqn47bff2LhxI1qtFoVCweeff05ISMgdZR8+fJgFCxawcuVKANatW0dkZGSxnsOOHTvw9vZm7Nixlm1Dhw5FqVRSWFiIXq9n+vTppKSkkJqaSufOne8Y9hs3bhwvvfQSAFlZWTzzzDOkpqbSsmVLZs2ahVKppFOnTjRv3py0tDTWrl3L+++/z6VLl0hPTyc8PJwvvviCefPmAfDwww+zZs0aDhw4wMKFCzEajQQFBTFnzhy8vLz4+++/+eijj1CpVDRo0MC6N+Q/mAUzyflpSCQS/F18ydJmYzSbUMnLL40iImItJBIJCTfz6Ng0kOdGtMDL3cmm9VWpQ5g4cSJTpkyhRYsWzJs3j5kzZ5Kfn0+zZs0YP368Tep855u/79jWsYkvI3o1Rldo5P0fjtyxv0/7evTtWI+cfD0f/3L8jv0DOzegW5s65bJjx44dnD9/ni1btpCXl2cZKrp06RKrV69m5cqVqFQqPv/8c3788UfGjx/P7t27+fXXX3FycmLBggUsW7aMd999946yO3XqxMyZM7l27Rr16tVjw4YNvPHGG8WOiYmJoVmzZnecO2DAAAC2bNlCkyZNWLhwIYWFhQwaNIhz586V2J7ExES++uorgoODee2111ixYgUTJkwgKyuLiRMn8sADD3D8+HEUCgWrVq3CbDYzYcIE9u/fz8yZM/n1119Zs2YNmZmZfP755/zyyy94eHiwcuVK5s2bx6xZs5g2bRo///wzoaGhzJgxo1zXuzwIgkB6QSaFJgO1XP1RK50BgZT8dHRGPc4K2/4IRURup9BgYuWui/RoE0RwLXdeeaQNCnnVrJq0uUPYu3ev5f/bx38bN27M2rVrbV29w3Ds2DH69euHQqHA29vb0iM6evQoCQkJjBkzBgCDwUDTpk1xdXXl888/Z+vWrVy9epW//vqLJk2a3LVsiUTCiBEj2LRpEyNHjiQjI+OO4QmpVHpPIcDBgwcTFRXF0qVLiYuLIzs7G41GU+Lx7du3p379+gAMGTKEdevWMWHCBABL3R06dMDT05Nly5YRFxfH1atX7ygzMjKSmzdvWl4IzGYzHh4eXLx4EX9/f0JDQwEYMWIECxYsKNGeypCnzyevsAAvJ49/nAGo5c5IkFBg0IgOQaTKOB+fwcJVZ0hKy0ftpCC4lnuVOQOogZHK/+WjyV3v2HZrotFJKb/r/lt4uKruub88SCQSBEGwfL4VhGcymXjooYeYOXOmxTaTycTNmzcZN24cTzzxBN27d8fX1/eeUbcjRozg2WefRalUMmzYsDv2N23alK1bt96xfcaMGTz55JMcOXKEHTt2MGbMGCIiIoiNjS1m73+5PYhQEIRin52cih6ge/bsYeHChYwfP56RI0eSlZV1R5kmk4m2bdvy3XffAUVjnAUFBdy4caPYsTKZrERbKoPeqCddk4WzwgkvZw/LdqlUirPCiYJCLT7OFVv0ICJSVjQ6A7/+cYGth+Lx83Tm/UmdaRte9YGMYvRWFdG5c2e2bdtGYWEhOTk5/PXXXwA88MAD7Nq1i4yMDARBYPbs2fz8889ER0cTHBzMk08+SYsWLdi9ezcmk6nE8uvUqUNgYCArV668q0Po27cvSUlJrFmzxrLt999/59ixYwQHB3Pw4EHGjh3L0KFD0ev1xMTEYDabS6zv5MmT3LhxA7PZzIYNG4iIiLjjmMOHD/PQQw8xatQo3N3dOXr0qKUNMpkMo9FIq1atOHPmDPHx8QB88803fPrpp4SHh5Oenk5MTAzAXZ1ZZTGZTSTnpyOTSglw8b3joe+iVGM0Gyk0Gaxet4jI7Ww9GM/WQ/EM7hrCV1N728UZwH3QQ3AU+vbtS3R0NIMHD8bX19cyFNK4cWNeeuklJkyYgNlspkmTJkyaNAmj0ciKFSsYOHAggiDQoUMHLl26dM86Bg4cyM6dOwkICLhjn5OTE0uXLuXDDz9k6dKlSCQSgoKC+L//+z+USiUTJkxg9uzZLF68GFdXV9q0aUNiYiL16tW7a10NGzZk+vTppKWl0alTJ0aPHn3HMQ8//DBvvvkmW7duRaFQ0LZtWxITEwHo06cPw4YNY926dXz44Ye8+uqrmM1mAgIC+Oyzz1AoFHzxxRdMnToVuVxO06ZNy3vJ74kgCKQWZGAym6jtFoBMemcPxEXhTBpQYNCIk8siVidPU0h6tpYGtT0Y1j2Ulg19CQ/2tqtNEuFe4wIOyq2lUyUtOy1prP0WjqBxY22MRiNvvfUWAwYMoF+/fnfsr4ltLo17tTlLm0OmNhtftRceTu4llpGUm4xZMFPXo3albCnL99Ia1OQlmCVRHdt8MOoG362LQq2S883bfZBJyzckWdE23+vZCeKQUY1AEAS6deuGRCKhb9++9jbH4dEatGRqs3FVqnFX3ZlG8HZclGoKTQYM4rCRiBXIzNXx4dJjfPzzcXw8nHh7fIdyOwNbIg4Z1QAkEgmHDx+2txnVAqPJSEp+OkqZAj+1T6mTxS4KNRlkUVCoxdNZ1MgSqTiJqXm8ufAvDAYTTw5qyvAeochkjvVOLjoEkfsGQRBIKUjHjEBtV98yKeIqZHJUMiUFBg2eziUPLYmIlITBaEIhl1Hb15UHO9ZjQOf61PFztbdZd8Wx3JOIiA3J0GahM+rxV/uglJV9klitdEZn1GM0l7zKS0Tkv5jMApv+usKkD3eTmatDKpXwzNDmDusMQOwhiNwn5BcWkKPLw0PlhquqfJPrLgo1WdocNIUa3J3uPecgIgJwPSWPhatOE5OQRbvG/veM6XEkRIcgUuMpNBlIK8jASa7CR+1V7vOVMgUKqZwCg1Z0CCL3RBAEVu+JZeXOWJxVMl5/rC092wZVm8BG0SGI1GjMgpmU/DQkFInWVeSHKZFIUCudydXlYzKbkYnZ+ERKQCKRkJiST6fmgTw3oiWebpVXyq1KxG+2DUlMTCQ8PJyDBw8W2967d29LgNbdSElJYeLEiZWuPzw8nGHDhjFs2DBGjRrFjBkz0OutkwWsrKxbt45p06YV23b06FHGjRtn1XpuXdM9e/ZYNI8GDRpE1KVzFJoM+Lv6opCV7/1n9erVbNmyBSgaNhIQ0Bq0ZbJD5P5BbzDx89bzXL2ZC8Arj7Th7fEdqp0zANEhWNAlXiTr4Dp0iRetWq5CoeDdd98lPz+/zOcEBARUKvnM7WzcuJGNGzeydu1acnJyarygYJ8+fXjllVeAogQ3GoMGL2dP1Arncpd16tQpCguL8iM4yVXIJDIKDCUL/oncf5y9ks6UeX+ydu8lTl4oyvood7ClpOWhRg8Z5UXtIy9y7x3bTSYTObeJpZn1GgpTr4IgkCWRoPSvj1R17yxZbq1649ayZ6k2+Pv7ExERwSeffMKcOXOK7TMajcyePfuOfAHp6emMHz+e33//ncGDB7Nv3z4UCgWxsbG8+eabbNq0qcQcCiVhNBrRarX4+voCEBsby5w5c9BoNGRmZjJp0iTGjh1L3759+fHHH2nQoAEajYaHHnqInTt3cvTo0bvmLPjkk084ePAgUqmUvn37WvIllJVp06bh6urKuXPnSElJ4cUXX2TUqFFkZ2czY8YM4uLiUCqVTJs2jc6dO5eaI2LdunUcO3aM2R+8j1kQWPl/y7l2JQGVSsX7779P48aNmTZtGtnZ2SQkJDB16lT0ej0//fQTOp2OwsJCPvzwQ3Q6HXv37uXIkSP4+fnRpEkT5syYTfLNZJwUKt544w0iIiLIzs5m6tSpJCcnExoaWuU9MBH7oNEZWLr1PNsOXSXAW80Hz0XQKsyv9BMdnOrryqyIWVcAt1YBCELRZysybdo0/v777zuGjk6fPm3JF7Br1y7y8vLYv3+/Zb+XlxctW7bk77+Lcjps3bqVoUOHFsuhsHHjRnx8fPjxxx/vWvetIaP+/fuTlpZG586dAVizZg2TJ0/m999/55dffuHTTz9FKpUyfPhwNm3aBMDOnTvp2bMnBQUFljwNGzZsoGvXrsybN4+kpCQOHDjApk2bWLFiBZcvX67QAzE5OZnly5fz7bff8umnnwKwYMEC6tWrx7Zt2/j000/58ssvyc/Pt+SI2LJlCz179mTZsmV3lCcIRbkMJEB4aBgbNmxg8uTJxYauPD092bZtGz179mTlypV89913bNq0iWeffZbFixcTERFB7969mTJlCt26dWPu3LmMGjmKhUu/5ouF83nvvffIz89n4cKFNG3alM2bN/P444+Tnp5e7vaLVD+2/B3PjsNXGd4jlK/e7FUjnAHU8B6CW8ued32L/6/GjS7xIjeXzUYwGZHI5PgPfxWnoHCr2eHq6sqcOXN49913LQ9bKFu+gKFDh7J161Z69erFtm3b+PXXX9m1a9ddcyjcjY0bNwKQl5fHggULeO211/jxxx+ZNm0af/31F99//z2xsbGWekeOHMlTTz3FK6+8wvr163n99ddLzFkQEBCASqXikUceoVevXrz55pt39FLuFvz13xzaXbp0QSKREBYWRnZ2NgDHjx+3ZFYLDw9n1apVAKXmiBAEAa1Rh8lsQiqRMnZMUYa4Hj16MHXqVHJzi8Z5W7ZsabHv66+/Zu/evcTHx3Ps2LG72nzo0CHi4uIoNBUilRQptV6/fp1jx47x+eefW+5n3bp173ofRKo/Ofl60rO1hAZ5MrxHKG3C/WhUt/yr1hyZGu0QyopTUDi1Hp+NNuEczsHNrOoMbtG1a1fL0NEtypIvoE+fPnz88cccP36cWrVqERAQUGIOhXshlUoZPXo0jz76KACvvvoq7u7u9OrVi4EDB1omT4OCgqhduzY7d+60JNrZvXv3XXMWyOVy1qxZw7Fjxzhw4ACPPPIIv/76a7F0l+7u7paH8C0yMzPx8Pg398AtJ3K7k5DL5cU+X7lyBScnJyZMmHDPHBEagxaT2WRZXnp7HoXb8zbcytlQUFDA6NGjGTp0KB06dCA8PPyuvQ6z2czPP/+MXm5Aa9TjrFfg6+t7R54LW+VtELEfgiDwd+QNvl8fhYuTgm/e7oNSIatxzgDEISMLTkHheHUZaRNncItbQ0epqanAvfMF3EKpVNKtWzc+/PBDS9rNknIolMbhw4ctPYmDBw8yZcoU+vbty4EDBwAsdY8aNYoPPvjAUl9JOQvOnz/PE088QYcOHXj77bcJDQ21HHOL1q1bExUVxbVr1wAoLCxk/fr1lqGrkmjfvr0lB8KVK1eYOHEiZ8+evWeOCJ1RR4FBi1wqx11VFA26efNmAHbt2kVoaChqdfG5oatXryKRSHj++ect1/X2nA23/u/UqRPLly/HRaEm/kocQ4YMQavV0rlzZ0sv7PZ2itQMMnK0zP3pGJ/+egI/LzXTJjiWGJ21EXsIVcitoaNnnnkGuHe+gNsZNmwYmzZton///kDJORTuxq1kOYIg4OHhwf/+9z8AXn75ZR577DFUKhWNGzemTp06JCYmEhwcTL9+/Xj33Xct5/r5+d01Z4GXlxetW7dm8ODBODs707ZtW0tq0Ft4e3szZ84cXn31VUwmE4WFhfTr14+xY8fe81pNmTKFmTNnMnToUORyOZ9++ilNmjRh5cqVd80RUZQXOQu5VIaTXGXpXVy9epVhw4bh4uLCxx9/fEc9jRs3pkmTJjz00ENIJBK6du3KyZMnAYiIiOCLL77Azc2NmTNn8t577/Ho6EcoNBby3gezcHV1ZcqUKUybNo1BgwYREhIiDhnVIK6n5DF14QEMRjNPD2nG0G4hDidGZ23EfAj3CWVtsyAIHDhwgBUrVliGiBwdQRC4kZdMoclIHfdAlLIiVVJb3eebeSkYTEbqetQuc6CbmA/Bdli7zbfE6MxmgaVbzzOgczC1fR1Lf8hW+RDEHoJIMT788EP+/PNPq8VBVAUZmix0xkICXH0tzsCWuCjUpBkyKTQZxExqNQiTWWDzX3Gs33eZL17tjo+HM08PaWZvs6oU0SGIFGPGjBnMmDHD3maUmTx9ATn6PDyc3HBVVk2vT610Bg0UGLSiQ6ghJNzMZdHqM1y8lkX7JnemoL1fEB2CSLWl0Fj4r2idc9Wt+JBL5TjJVWgKNXg7e5R+gojDIggCK3deZPWeWJxVCt54vB092tSpNmJ01kZ0CCLVErPZTEpBOlKJlADXionWVQYXhTMZ2mwMJmO5NZJEHAeJRMKNjAIiWtRm0ogWeLhWP/0hayJ+k0WqHYIgkKbJoNBkoLZbAHJp1X+N1Uo1GdpsNAYNHjIxk1p1QldoZMWOi/RsF0SD2h68MrZNtdYfsiaiQxCpduTq88gv1ODt7ImzwskuNihlCpQyBQWFWjycRIdQXYi+nM6i1We4mVGAh6uKBrU9RGdwG+KVsCGi/HURcXFxPP/88wwZMoQhQ4bwxhtvkJmZec9zbpfNnjhxIikpKaxbt46pb00lQ5OFWuGMZzkfxHl5ebz44ovlOudu8t23cFGoLTIZIo5NgdbAV2vOMP3bot/i3BciGNmroZ2tcjxEh2Bj7nf565SUFMaPH8+YMWPYvHkzmzZtolGjRuVSRV2yZAkBAQGYBTNaow65VI6/i0+55w1ycnLukLqoDC7KIkltTSk5EkTsz9aD8ew6msCIng1Z+GZPWjasGWJ01kZ0CP8Qmx7H+vPbiU2Ps2q5t8tf/xej0cjMmTMZO3Ysffr0YfLkyeh0OhITE+nduzdZWVl06dIFg8FQZGNsrEVOYsOGDYwYMYJhw4Yxffr0Ut/87yZ/PW7cOEaNGkWvXr1YsWIFZrOZ3r17W+QnNBoNPXr0QK/Xc+DAAUaPHs3w4cN56aWXyMrKAuCTTz5h6NChDB8+nK+++uqOelesWEGnTp3o3bs3UDSJN3HiRB577DGMRiMpKSk888wzjBkzhp49e1qS29xO7969uX79Orn6fJKuJ/H25DcZNnQY8+bNQxAEEhMTGTBgAI8++ihPPfUU+fn5TJkyhQkTJtCrVy+mT5+OIAh88MEHpKamWnoJJV3DDRs20L9/f0aNGsW+fftKvKZKmRK5VE5BoZgjwRHJyddzJTEbgOE9Qvn8lR48PaQZTkpxpLwkavSV2R9/hD/jD92x3WQyFRMh0xi0JGQnISAgQUKwZ51SE6r0ahBBjwadymTHtGnTGDJkCAcPHqRLly6W7bfLX5vNZiZMmMD+/ftp1qwoGOZ2+etevXrdVf5apVJZpKknT558R9235CeSk5MJCAi4Q/66c+fOXL9+naFDh/Loo49a5K9feeWVO+Svf/nlFzw8PFi5ciXz5s1j8uTJHDhwgK1bt6LVannnnXfQ6/XFIiAvXLhAp07Fr5NMJmPw4MEAbNmyhcGDBzNixAjy8vLo0aPHXbOp5erzinIjJ6eyaeMmXF1dmTBhAnv27KFx48bEx8fzww8/EBQUxJYtW2jSpAkfffQRCoWCQYMGce7cOWbOnMn48eP5+uuvS7yGo0aNYt68eWzYsAFPT0+ee+65O/SPbiGRSHBROJOrz8csmJFKxPcrR0AQBA6cTmLxhmhcnf8Vo2tY19Pepjk8NdohlBWNQYtAkYJHUZYtbYUybJXE/Sx/LZFIUCpLDt565plnOHLkCD/++COXLl3CYDCg1RYfgjELZnL0eTjJlfTp3Qdvb28AHnroIY4dO0bjxo3x8fEhKCgIgMGDBxMVFcWyZctITEwkOzsbjUaDp6enpcyjR4/e9RqePn2aNm3aWHpSQ4YM4ciRIyXa76JUk6PPQ2PQ4aq8d1IlEduTnq3lm98jOX4+hbB6nkwZ06ZGi9FZG5s6hM2bN/Ptt99iNBqZMGECjz/+eLH9586d47333sNgMFCrVi0+++wz3N2tt2KjR4NOd32L/6/GTWx6HP/b9yVGswm5VMaUTk8T5htyx3mV4X6Vv27evDlnz54tZovZbGbKlCnMnj2bH374gevXrzN48GD69u3LoUOHil0Dg8mIyWxGIVXgpnS1yFffKue/ctYAv/76Kzt27GDYsGH07NmT2NjYO65rSdfw8OHDxY69vb67UZRaU0pBoUZ0CHbmekoeby48gNEk8MzQ5gzpFiI6g3Jisz5uSkoK8+fPZ/ny5WzYsIFVq1Zx+fLlYsfMnTuXKVOmsGnTJho0aFBi1i9bE+Ybwns9X2Vs8yG81/NVqzuDW9yP8tdjx45l//79lkxwgiDwzTffkJGRga+vLwcPHuSZZ57hoYceIj4+npSUFMxms+XYlPw0APxcvJFIJOzfv5/c3Fz0ej1//PEHERERd7Tz4MGDjB07loEDB6LX64mJibE4D6PReM9r2K5dO86cOWOx448//rjnNZVIJKgVzkW9zOqnE1kjMJiKrnsdP1ce6lyfr97sxfAeoaIzqAA26yEcOnSITp06Wbrp/fv3Z/v27cVWl5jNZgoKitJVarXaYklTqpow3xCbOYJb3I/y135+fixZsoRPP/2UefPmYTKZaNq0KV9//TUAzz33HG+99RZOTk4EBgbSvHlzyzXQmwrRmwqRSaWW4LOQkBAmTZpEbm4ugwcPpmvXrndcswkTJjB79my+++473N3dadOmDYmJibRv357atWszbtw4fv3117teQ5VKxcyZM3nyySdxdnamYcPSlya6KNXkFRagNeqsOtQocm9MJjMbD8SxZvdNGoVr8fFw5snB95cYnbWxmfz1999/j0aj4bXXXgOKJjGjoqKKJZo/c+YMTz/9NGq1GmdnZ1avXo2XV+maNLckXO+GXC4v049Y5O4IgsDBgwdZu3YtX375pd3s0Jr05BjzcJE54yZ3bKlyAYFUfSbOMhXu8rvLJF++fNnSOxGpPCnZBjYeyeRGpoHwOk4M7uiFm7OYra6sVLn8tdlsLrZO/L95dHU6HTNmzGDp0qW0bNmSn376ibfffpvFixeXuY6S8iGUpoEv5kMomblz51rkr+11jfTGQnJzM3CWqwhw86uwTlFV3ud8sxa9SY9arb6rvUqlklatWtncjpqeD0EQBJbvuMiaPbG4qhW8Na49zsabtG/f3t6mVSmVzYdQEjabQwgMDCQtLc3yOS0tDX9/f8vn2NhYVCqVJdn52LFjOXbsmK3MESkjM2bMYPfu3cUmhqsSk9lMSn4aUqkUfzuI1lUUF6UzRrMJvanQ3qbUaCQSCalZGrq1qcM3b/WhW+v7V5nUFtjMIURERHD48GEyMzPRarXs3Lmz2PhycHAwycnJxMUVBYLt2bOHFi1a2MockWrALdE6g9lIgIuvXUTrKsqtuQMxSM366PRGftx0lvgbOQBMGdOaNx5rh7uLmIvC2tjsFxcQEMBrr73G+PHjMRgMjB49mpYtWzJx4kSmTJlCixYt+Oijj3j11VcRBAEfHx8+/PBDq9T93+EpkepBjj6PgkINPs5edhOtqygyqQxnhRMagxYfis+DiauPKk7kpTS+WnOG5AwN3u5ONKjtUePzGtsTm76C3RIzu53bNXp69OhBjx49rFqnk5MTGRkZ+PiUX+tGxH5oDToyNFm4KNV4OLnZ25wK4aJQk64pSq15K5WnIAhkZGQUi5MQKZ18rYGfNp9j59EEavu68OHkLrQI9bW3WTWe6tMnLyNBQUEkJiYWm7/4L4WFhfeMnq2JOHKbzYKZLG0OEokETycPsiTpVim3qttsMpvJ1GaRrcwotvzUycnJEkUtUjb+OBjP7mMJjOrVkEf7N0alEFcQVQU1ziEoFIpSJ0RPnjxZJSs+HAlHbbPJbOKD/Qu5lBHP3L5vEexpvQenPdr8zq6PkSDhwwffrtJ6awLZeXrSs7U0rOvJiJ6htGvsT2iQp73Nuq8QB+NE7MrK6E2cS41lYrvHrOoM7EXHOq25nHmVTE22vU2pNgiCwJ8nrzP50z189tsJTGYBhVwmOgM7IDoEEbtxIimSjTE76RvStczKsY5Oh6CiHsnxpEg7W1I9SM3S8P4PR/hi+Snq+Lky8+kHRMkJO1LjhoxEqgfJ+Wl8dfRnGnjV5cm2Y+xtjtUIcq9FbbcAjiWdoX8j6y6YqGlcT8njjQX7MQswcXhzBnURxejsjegQRKqcQmMhXxxcjEQi4Y2ISZYVOTWFDnVaseXibvILC3BV3l8R8WVBbzChUsgI8ndlUJcQBnSuT4C3qBTrCIhDRiJVzo+nVnE1O5GXH3gSf9eat5SwY1BrTIKZUzdKlgi4HzGZzPy+9xLPzt1FRo4WiUTChEFNRWfgQIgOQaRK2Rt3iD/jDzGy6QDa1q6Zkemh3sF4OXtwLOmMvU1xGOJv5PDGwgMs3XqexsFeSMUYIYdEHDISqTLis67z46mVtAgIZ0yzIaWfUE2RSqR0qN2K/VePUGgsRCl3zPiPqkAQBJbtiGHtnku4qZVMG9+BiJa1xKBRB0XsIYhUCQWFGr44uBg3pQtTOj2NVFqzv3odg1qjNxUSlXLB3qbYFYlEQlqWlh5tg/j6rd50aVVbdAYOTKm/yitXrrBmzRoEQeDVV1+lb9++98wxKyLyX8yCma+P/ky6JpPXIybi4WS9NKmOSlO/RqgVzhy7D5efavVGlmyILiZG99qjbUUxumpAqQ5h1qxZqFQq9u3bR0pKCnPnzmX+/PlVYZtIDWFTzC5O3IhiXOtRNs9K5yjIZXLa1m7ByaQoTOZ757uuSZy+mMpL8/5k899xRF4qkiARxeiqD6XeKb1ez9ChQ/n777956KGHeOCBBzAYDFVhm0gN4FxqLCuiN9K5bjseatTL3uZUKR3rtCKvsICY9Cv2NsXm5GsKWbDyNO8tPoxCJuWjyV0Z3iPU3maJlJNSHUJhYSHp6ens27ePiIgI0tPT0ev1VWGbSDUnU5vNl4d+oLZrAM93eOK+GztuHdgUhVTO8cQz9jbF5mw7fJW9J6/zcJ9GLHyjJ81CfOxtkkgFKNUhjB07ll69etGuXTsaNmzI6NGjmTBhQlXYJlKNMZpNfHnoB3RGPa93mVjt8htYAyeFEy0Dm3AsKbJG5kTIytVx6XoWAMN7hPLlaz0YP7ApSlGZtNpS6rLTxx57jEceecSyKmT9+vV4eXmVcpbI/c7yqA3EpF9hSqenqOtR297m2I0OdVpz8kY0V7MTaeBV197mWAVBENh74jo/bDyLu4uSb97ug0Iuo0FtD3ubJlJJSu0hFBQU8MEHHzBhwgSys7OZP38+BQUFVWGbSDXlyPVTbLm4m/4Ne9A1uKO9zbEr7Wu3QCKRcKyGDBulZmqYveQIX648Td0AN1GMroZRqkP44IMPcHNzIyMjA5VKRX5+Pu+9915V2CZSDbmRl8K3x36loXd9xrceZW9z7I67kxtNfBvWiKjl6yl5vDRvL+fjM3huRAs+frErdQOqZ3Y7kbtTqkO4cOECr732GnK5HGdnZ+bNm8eFC/d3sI3I3dEZ9Xx+cDFyqYzXIyaiqGGidRWlQ51WXM+5QXJeqr1NqRC6QiMAQf6uDO4awtdTezO4awhSsWdQ4yjVIfw3otRkMtX4KFOR8iMIAj+cWEFizk1e7vQ0vi7e9jbJYegQ1Bqg2gWpGU1m1uyJ5dm5u0jPLhKjGz+wKf5WEqPTxEeRdXAdusSLVilPpPKUOqncoUMHPvvsM3Q6HX/99RfLli3jgQceqArbRKoRu6/8zYGEozzcbBCtazW1tzkOhb+LDw0863I88QxDGz9ob3PKxJXEbBauOkPcjRy6tKyN3MrBZVmH1pP152+AhGy5glqPz8YpKNyqdYiUn1Lv8ptvvolarcbNzY358+cTHh7OW2+9VRW2iVQTrmQm8NPp1bQKbMqoZgPtbY5D0iGoFbEZ8WRrc+xtyj0RBIFf/jjP6wsOkJWn450JHZg2oQOebiqr1aG5cpqsfctv1YhgMqJNOGe18kUqTqk9hCNHjvDiiy/y4osvVoU9ItWMfH0BXxxcjIeTGy93egqpRBxOvBsd67Rm9dktnLgRRd/QbvY2p0QkEgmZuTr6tK/L00Oa4aq2rv6Q9mo0KWs/Re4ZgDE7BQQzEpkc5+BmVq1HpGKU+utdtGgRvXv35ptvviElJaUqbBKpJpgFM4uO/kSmLoc3IibhrnK1t0kOS12P2gS4+DpkrmWNzsD366OISyrqvbw8pg1TxraxujPQXY8hefVHyD39qfPkh/g+NAkAj07DxOEiB6FUh7B69WqWLFlCQUEBY8aM4bnnnmP37t1VYZuIg7P+/HZO3zzHk60fpqFPfXub49BIJBI6BLUmOuUiGoPW3uZYOBVTJEa39WA80Vf+EaOzweoh3Y3L3Fz5AXI3b2o9PhuZ2h231n2QuXphSE+0en0iFaNM/fvQ0FCmTp3KokWLyMrK4vXXX7e1XSIOTlTyBVaf3ULXeh3o17C7vc2pFnSs0xqj2cjpm/ZPrZmnKWT+ilPMWnIYlULGJy92Y1h324jR6VOukrxiDjJnN2o9Phu5a5HSgUQiRd2oPZq40whGUTDTESh1DiEjI4NNmzaxfv16TCYTo0eP5vvvv68K20QclHRNJguO/B9B7oFM6vD4fSdaV1HCfBrgoXLjeGIkXep1sKst2w5dZf+pRMb2DWNM3zCb6Q8Vpl3n5vL3kShU1HpiNnL34jm0XcI6kHd6F9qr0agbtrWJDSJlp1SH0K9fP/r168d7771H+/btq8ImEQfGaDIy/9APGEwG3ugyCSe59Vaf1HSkUint67Ti0LUTGEyGKg/cy8zVkZ6tJayeFyN6htKxWSD1a9kuWZEh82aRM5BIqfX4bBSeAXcc41S/BRKlEwWxx0WH4ACU6hD279+Pq6s4WShSxK+R67iUEc9rEc9S2z3Q3uZUOzrUacWeuL85m3qRNrWaV0mdgiCw+9g1ftx8Dk9XJV+/VSRGZ1NnkJ3KjWWzEcwmaj/xPkqfuwscSuVK1CFt0MQeQ3hoIhJxlZpdKdEhvPLKKyxYsIBHH330rvs3b95sM6NEHJND106w7dKfDAzrTee67extTrWkRUA4znInjiVGVolDSM4o4Os1kZy5lEazEB9eHtPa5mJ0xtwMbi6bjVCopdbj76P0q3fP49VhHSiIOYz+xmWc6oTZ1DaRe1OiQ5g4cSIA7777boUL37x5M99++y1Go5EJEybw+OOPF9sfFxfHrFmzyMnJwc/Pjy+++AIPD1FC1xFJzL3Jt8d/I9wnhCdajbS3OdUWhUxBm1rNOJEUycR2j9pUBuZaci6vLziAVCJh8qiW9O9U3+b6Q8b8bG4un41Jk0utx2ahCmxQ6jnqhm1BIkUTe1x0CP9Bl3iRs7EHiVcraNWwi81T0Jb4bWzevOjtZcOGDXTs2LHY32+//VZqwSkpKcyfP5/ly5ezYcMGVq1axeXLly37BUHghRdeYOLEiWzatIkmTZqwePFiKzRJxNroDDo+P7gYlUzBaxETkUvFBCiVoUNQK3L0ecRmxNukfJ2+SIyuboAbw3uE8vXU3jwU0cDmzsCkyeXm8vcx5mZQ65EZONVpVKbzZM5uONVrSkHsMZvaV93QJV7k79XvMy/1GGuvHuR/f84nNj3OpnWW2EOYNWsWKSkpnDx5kszMTMt2o9HI9evXSy340KFDdOrUCU9PTwD69+/P9u3beemllwA4d+4carWa7t2Lliw+//zz5ObmVqYtIjbgYtoVfji5gqTcZN7t+Qreak97m1TtaVOrOTKpjGNJZ2jsZ72lnkaTmQNnc5m/aRdfvtYTX09nnhjQxGrl3wuTroCbK+ZgzLxJ4NjpONUtX70uYR3I2PUThsybKLxr2cjK6oUm7gw7vJ0x/7OKz2g2ci411qa9hBIdwujRo7l06RIXL16kf//+lu0ymYzWrVuXWnBqaip+fn6Wz/7+/kRFRVk+X7t2DV9fX6ZPn86FCxcICQmp1PCUiPWJTY/j/X3zMZpNyCRSVDLrRq7er6gVzrTwD+d4UiTjWo20yrLdy9ezWbDqNFdv5tKtdR0U8qqbnDXrtSSv/IDC1GsEPvwWzg1alrsMdVhHMnb9REHscTw7DbWBldWPs8ZcEpyVSAUBAZDLFDTzt+2QWokOoUWLFrRo0YIuXboQEHDncrHSMJvNxb7ogiAU+2w0Gjl27Bi//fYbLVq04Msvv+Tjjz/m448/LnMdZ89WPMDn5MmTFT63ulLeNh/OPIPRbALALAjsPP0ned5ZtjDNZjjqfQ4weXMm/zw7Du/GT1VxqXBBENgdmcuhC3m4OEl5pLsPjYMkXL5YRcFvJgOuJ1Yiz06koPVILuQAFbzmbm7+pJzayxVFnXKf66j3uaLkGzX8lHqGWoVG+qnqk6B2JsirMXkJWZxMKGqrLdpc6iqjZ5999q77S1tlFBgYyIkTJyyf09LS8Pf3t3z28/MjODiYFi1aADB48GCmTJlSLuObN2+OSlX+dfAnT56kXbv7a5VMRdrskubBgb1F91Ahk9OvTS+bT2pZE0e+z6HahuzcdJB8j0IGNKucjQcvn+bBjt48NaQZF89HVVmbzcZCUlZ/jDYrEf/hr+DarHKifZn5l8g++DutGzdE5lL2xSWOfJ8rglkwM3f/QgyYeVIeSJuxM+44pqJt1uv193yRttkqo4iICBYtWkRmZibOzs7s3LmTOXPmWPa3adOGzMxMYmJiaNy4MXv37qVZM1Hx0JG4FXTWKagtg8P7VCtn4Oh4OnsQ5tOA44mRjG42qFznanQGft56nn4PBBMa5MlLVbCU9L8IJgOpv89DGx+J3+AXK+0MAFzCOpL99xo0l0/i1qq3FaysnmyK2UV0ykVGpuXSoH3/0k+wIqWuMurYsSO1atWiY8eOaDQajh8/TpMmpU8YBQQE8NprrzF+/HiGDx/O4MGDadmyJRMnTiQ6OhonJye+/vprZs6cyaBBgzh69CjTpk2zXstEKk1USlGq1CfbPCw6AxvQIag18dnXSS3IKPM5Jy6k8OKne9l++Crn44sWe1S5MzCbSN3wJZrLJ/EdMNFqD29lYANk7r739WqjSxnxrIreRHu3unTI1VVoPqYylBqp/N577wEwYcIEZs6cSbdu3Zg+fTqLFi0qtfAhQ4YwZMiQYtuWLFli+b9Vq1asXbu2vDaLVBHRKTEEudcSVxbZiI51WvFb5DqOJ55hUHifex6bk6/nh41n2XcqkXqBbkyb0IHw4KpPUyqYTaRt/oqCmCN4930S93YDrFa2RCLBpVF78iL3YjbokSruL1kUjUHLgsM/4u3syZhCJ1C7owyoX6U2lLoU4ezZs8yePZtdu3YxYsQIPvroI5KSkqrCNhE7UmgycD7tMi0DGtvblBpLoJs/dT1qlylHws6jCfx1JolH+4Xz5Ws97OMMBDPp2xaTf/YAXj0fw/OBIaWfVE7UYR0RjIVo46NKP7gGcSsneZomk5c6PYXk6jmc67eocimPUmsTBAGpVMrBgwfp1KkTADqdzuaGidiXi+lXMJgMtAismnXs9ysd67TmQvplcnV5d+zLyNFyMaFoWGh4j4YseKMnj/VvjEJe9YGBgiCQsfP/yDuzG88uo/HqMsom9TgHN0WiUqO5z4aNDlw9yt/XjvNws8GECgpMBdk4N2hV5XaU6hDq1avHxIkTSUxMpEOHDrzxxhs0biy+NdZ0opIvIJNIaepXtmhTkYrRoU4rBEHg5I1oyzZBENhxJIEXP93LF8tPYTILKORSggNtJ0Z3LwRBIHPvr+Se2IbHA0Pw6vGIzeqSyBSoG7al4NIJhH+WPNd0buSl8MOplTTxa8TIJgPQxBf1GNUhVe8QSp1D+Oijj9i1axft27dHqVTSvn17hg8fXgWmidiT6JQYwnxDcFY42duUGk0Dr7r4qr05lnSGXiERJGcUsGj1GaIup9M8tGrE6Eoj68Aqco5sxL3dALz7TLB5/guXsI4UnPsbfVJsuSOeqxtGk5GFh/8PhVTOlE5PIZVK0cZFofCpc0fuiKqgVIegVqupX78+69evx2Aw0KVLF5ydnavCNhE7kafPJz7rOg83L99ySJHyI5FI6FCnFbuv/MWlpDSmLTqKTCrhxdGt6PdAsM31h0oj+9A6sv9eg1ur3vj0f6ZKkiGpQ9uAVE5B7LEa7xBWRG8kLusab3Z5Dh+1F4LRgO7aOdxa97WLPaUOGW3YsIEpU6aQk5NDQUEBb775JqtXr64K20TsRHTKRQQEWgbU7B+jo9DSvzkGs5EM83VG9WrIN2/1ZkBn2yuTlkbOsS1k/rkM12bd8B34fJVNcEpVapzrN0MTexxBEKqkTntw5uZ5Nl/cTb/Q7nQMag2ALjEGwVhY5ctNb1FqD2Hp0qWsWbPGEmU8ceJEnnnmGcaMGWNz40TsQ3RKDGqFM6HewfY2pUZjMJpZuyeWTX/H49JGzbGkSKb0f8reZgGQe2onGbt+Qh3+AH5DX0ZSxQq36kYdydixBENGEkrfoCqtuyrI1uXy9dGl1HWvxfjW/07Qa+MjQSrDObhqkif9l1JdvtlsLiY5ERAQYFMNdxH7IggCUSkXaOYfhkyUubYZsdeyeG3+PpbvvEi78EBaBTTn1I1oi3aUPcmL+pP0bd+jbtiOgBGvVbkzgCL1U6BGrjYyC2a+PvozGqOOVzo/g1L+r2ikJi4KpzphSFX2GZYv9cnu6enJ7t27LZ93794tJrGpwaTkp5FWkEELMf7AJgiCwI+bzjJ14QHytQbefeYB3nyiHV3rt0Vj0HI+Ndau9uWfP0jalm9wbtAS/1FvIqnivM+3kLv7oAwMpSD2uF3qtyV/xO4lMvk8E1qPpp7nv0J+Jk0ehclxdhsugjIMGb377rtMnjzZokOkUCj4+uuvbW6YiH2ISokBoKUYf2ATJBIJBVoD/TrV58lBTXFxLnrgtgxogkqm5FjiGbtd+4KLx0jd8CVOQeEEjH4bqdy+cucu4R3J2r8CY14Wcjcvu9piLeIyE1gWtYEOdVrxYGhx/Sft1ShAsEv8wS1KdQiNGjVi+/btXL16FZPJREhICHJ5qaeJVFOiUi7gq/amlqt/6QeLlIkC7T9idJ2CaRjkyUsPt75jwlgpV9KqVlOO34jkaWEs0iqOUNVcOU3K+s9R1QolcOx0pEr7Lzd2CetA1v4VaC4dx71tP3ubU2m0Bh1fHv4RT5U7L3QYd8eKLW18FFKVGlXthnaysAwOoaCggK+//pq///4bmUxG7969ee6551AqxWQpNQ2z2cy5lIt0DGpTJcsL7weOnUvmm98jycrVUS/QjYZBniWuHupYpzXHEs9wJTOBRj6l5yK2Ftqr0aSs/RSlb10CH5mJVKWusrrvhcKvHnJPfwpia4ZD+L9Tq0gpSGdWz1dxVbkU2ycIAtr4SJyCm9tlzuYWpb6GzJw5k5SUFN555x2mTp3KlStX+OCDD6rCNpEqJi7rGgUGLS0DxfmDypKTr+ez304w5/+O4qZW8tmU7gzuem/F2La1myOTSDmWeKZqjAR012NIXv0Rcq8Aaj32HjJn1yqruzQkEgnqsI7orkZjLtTa25xK8XfCMfZfPcKopg/R9C5Zz4xZNzHmpNl1uAjK0EM4f/48O3bssHzu1KkTgwaJAUuOQEHscQpTE3Cu3wKnoPBKl3dL7rqFv+M6BM3lU+hT4nEObm6VNtuKnUcTOBR1g8f6N2Z070ZlSmnpqnQh2LMue+IOEuDqSz2P8mcOS9Kl4lbGROwFl06Qc2QDUjc3/B56iiuadNCkF5WTm0yWNofmAeF2lT53CetA7rEtaOLO4Nq4s93sqAwp+WksObGCcN9QRjUdeNdjNHFFYn7qEPtNKEMZHIK/vz+ZmZl4exepK2o0Gry8asYET3Um9/Qu0v/4DoDsg79T6/HZlX5ARiVfoL5nEO5ObtYw0erkRe8nbdNCALLlSqu02ZqkZ2tJz9HSONib4T0a0ql5LeoGlP1axqbHkZCdiEkwsfjE8oobkliOY2v/s2Lw0Hd37JIA6y4oeK/nq3ZzCk51myB1dkUTe7xaOgSj2cSCw/+HRCJhSqenSlzKrY2PRO7hj9yrVhVbWJxSHUJgYCCjRo1iwIAByGQy9uzZg6+vr2XYaObMmTY3UqQ4ZoOezH3LLJ8FYyEFF49U6uGoM+i4mBHHoDDHzFQlGA1k7vnl388mI9qEcw7hEMxmgR1HE/hp8zm83VV881YfFHJpuZwBwLnUWATBDIAECT3qP0BEvfblKuPSpUs0anRvQUKTroD0rd9iNtxSLZbg2rInbk27AHDo2gn2XT2CQNED7VxqrN0cgkQqQ92wPZp/xO7sOb5eEVaf3czlzKu8FvEsfi4+dz1GMJvQJpzFtUmE3efuSnUIwcHBBAf/G7EqDhfZn6z9KzBr8kAmB7MJBIHc07txadwZpzp3jk+WhQvplzGZTQ4rV5H11ypMBdkglRW1WSLBOdj+KVdvpOWzaM0Zzl7JoFUj37uuICorzfzDkMvkGM0m5FIZfUO7lftBbLqho3Wtkq+L2aDn5rLZeOVrAAmYTUhkcmqF98CpVpFzVSuc2X/1KAICcqmMZncZ865KXMI6kB+9D9218zjXb2FXW8pDdEoMGy/spE9IVzrXLTn/sf7GZQS9Bmc7qJv+l1IdwksvvVQVdoiUEe218+Qc3YJ72/64tuiBNuEccg8/svav4OZvs/AbOgXXJuXvWkclx6CQymnsG2oDqyuH7noM2Yc34taqD26t+5C29WuMuZko/erZ1a5rybm8Nn8/CrmUl8e05sGO9Sr1hhfmG8J7PV/lXGoszfzDrP5WLghm0jYtRJ90Cf9RbyB39UabcA7n4GbFelphviH0De3GrisHeKPLJLunT3UOaYVEpqAg9ni1cQi5ujy+OrKU2u4BPNnm4Xseq42LBCQ4B9u/bWJAQTXCXKgjbcvXyD398e4zDqnS2fJDVjdoSfKaT0hdNw9j73F4dBpWrodTVMoFGvuFFgujdwTMhVpSNy1E7u6Lz4NPIVU54zf4JW4sfYfc07vw7DS0ym3S6AyonRTUDXDj4b5hPNixHj4e1pEaCPMNsdkDOHPPr/+kvpxgGY8vacita3B7dl05gNkBxOWkSmecG7QsErt78Cm7D6uUhiAIfHPsF/IKC3in+0uoSvlNaeIjUdUKQaa2/9ydKEpUjcjc+yvGrGT8hryIVFn8ASRz8aDWE7NxadqFzL2/kv7HdwgmY5nKzdbmcD3nBi0ccLgoY/cvGLNT8Rv6skXfxalOGE71W5BzdBOC0VBlthiMJpZtj+HZubtIzdIgkUh45MFwqzkDW5JzYhs5Rzfh3v4hPDqWnvoy1CsYmUTKxfQrVWBd6ajDOmDMSaUwNcHeppTKtkt/curmWca1Gkl9r3sL85n1GvRJsXZfbnqLEh3Cl19+CcDJkyeryhaRe6CNjyL35HbcOwzCud7dx4ilciX+w1/FM2IkeWd2k7zqQ8y6glLLtshVOJhD0Fw+Sd7pnXh0GopzvabF9nlGjMCUn0Ve1J9VYktMQiavfLGflbsu0q5JAE7K6tO5Log9TsbO/0PdqD0+ZXzDVsqVNPCqx8UyLmG1NepG7QEJGgfXNrqadZ3fItfTtnYLBjTqWerx2oRzIJjtql90OyU6hC1btpCSksL7779PTk4O2dnZxf5Eqg6zXkPalq9ReNfCu9fj9zxWIpHi3etxfAdNRptwlqRfZmDISb3nOVEpF3BTupT6NlOVmDR5pG35BoVfvbumbHSu3xJVrYZkH9lo01SLgiDww8azvLXoL7Q6A7Oe7cQbj7XD3cWxhtZKQn/jMqkb5qMKbID/8PIpl4b5hnA586pDKLDKXb1Q1Wnk0GJ3OqOeBYf/DzelC5M7ji+T49XGRyJRqHAKcozYnxIdQpcuXejZsyeXLl3igQceoFOnTpa/zp2r33rg6kzG7p8x5mXiN+RlpApVmc5xb92HWo/MxJSbwY2f3kGWc+OuxwmCQHRKDM0DGle5fk5JCIJA+vbvMWnz8R865a4iaxKJBM+IkRizkim4cMhmtkgkErR6IwM61+frt3rTvkmAzeqyNobsVJJXf4RM7U7AmHfKrU/U2DcUg8nA1azrNrKwfLiEdaQw+QrG3HR7m3JXlp5ew428FF7u9CTuqrJFfGvjI3Gq2xSJ3D6qsv+lxCfA+++/z4ULF2jbti0xMTHF/i5cuFCVNt7XaC6fIu/Mbjw6DS33mnvnBi2pPeFDJHIlbkd/oyDm6B3H3IpIbelActcF5/6m4MJhvLqPRRVYsqaPOrwDCt8gsg+tt2pmrXytgUWrz3D5ejYAL45uxeRRrVA7OcaPtiyYdAUkr5qLYCwkcOwM5K7lDya9Nbkdm+Egw0b/5EhwxF7CoWsn2Rt3kGFN+tG8jL8lY246howbONs5Ovl2Sn0lXLZsGZGRkXz11VfMnz+f48cd72bUVEzafNK2fovCNwiv7mMrVIbSry61n/wIk5s/Kb9/RvbRTcUenha5CgeRuzbmZpC+YwmqoHA8Ow+757ESiRTPziMoTE1Ae/mUVeo/HH2TFz/dw+7j17iYkAlg91SW5UUwGUhZ+ymGzGQCRr+F0q9uhcrxdvbET+3tMPMISt8gFN61HW4eIbUgg8UnltHIuz5jmpc+YX8LTVwkAGoHmVCGMjiEjRs3Fsup/Prrr4s5lauIjF3/h6kgu8Rhk7Iid/Ukr+PjuDTuRObun8nYvsQy7h6VEkOgqx/+JURRViWCYCZty1cIJhP+Q8qWttG1WdeiOIxDv1eql5CVp+PjX47z4dJjeLiq+HxKdwaVIkbnkAgCaVu/RZdwFr/Bkyu9bj/MN4SL6VccJrexOqwD2oRzZVosURWYzCYWHf4/BARe6fwM8nLM0WjjI5G5eKKwczzN7ZTqEH766SfWrFnDjBkzmDlzJmvXruWXX34p7TSRSlJw8Rj50fvx7DISVS0rBIvJFPiPfB2PzsPJPbWD5FUfUajN43xqrMOsLso9uQNtfBQ+fSeg8C6bpotEJsfjgaHoEy+iu36+wnXvPnaNo2eTGfdQE754tQcN63pWuCx74nT5APnR+/Hq/ghuLXpUurxw31AytdlkaLKsYF3lcQnrCGYjmiun7W0KAGvP/cHFjDgmtnsMf1ffMp8nCGa0V6OLgu4cKK5CzKnsgJg0uaRv+w5lQAO8uo62WrkSiRSf3uPwHfg82vhIjqyYic6op4UDyF0XZiSRuecXnEPb4NbmwXKd69a6DzIXD7IPri/XeWlZWi7EFw0LDe/RkEVv9mRM3zDksur5/c6L3IvzlYO4teqNp5W+N+H/RK5fzHCMeARVnUZI1e4UOECu5XOpsaw7v42eDTrTNbhDuc4tTLmKWZPrMMtNbyHmVHZA0nf8gElbgN+Ql2yS09a9zYMEPjKTC8Z8JIJAI6FsK5dshWA2kbZpERKFEr9BL5b7jUmqUOHeYTDauNPob5Y+3m02C/xxKJ4XP9vDglWnMJsFFHIpQf72jxStKJr4SNL++A6DT318H3rOam+d9Txqo5KrHGYeQSKV4dKoPZorpxFMVReU+F/y9PksOvITgW5+PN1mTLnP18YXyV0713ec+QMog0N49913+eSTT+jRowc9e/bk448/FhVObUj+hUMUnD+IV7eHUQXUt1k96pBWXKvbgLpGyFnxgV1XbmQfXIf+xiV8B0yqcO5cj3b9kajUZB9ed8/jktLymf7tQb79PYrwYG/enxRR7SaN/0thagIpv89D6VuH/NYjkcisFzQnk8po5F2fWAdxCADqsI4Ieg3ahIoPEVYGQRD49vhv5OjzeKXTMzgpyp9uVBt3pigjnIPlihZzKjsQxvxs0rctRlWrIZ4RI2xal6ZQy5W8mwxt0gtl4UlS1nyCT7+n8OhQtWq2+ptXyPp7Da7NuuH6j/xyRZA6ueDRbgDZh9ZTmHEDpU/tO45J+EeMTqmQ8crYNvTpUNehxm8rgjEvk5sr5yJVOBE4dgYpl6wv7RDmG8KGCzvQGXQVevhZG+cGLZEoVGhij6G2g0LorisHOJEUyfjWownxLv+EsNmgR3c9Bvd2/W1gXeUo02CpTCYjNDSUsLCwcjmDzZs3M3DgQPr168eyZctKPG7fvn307u2YOvxVhSAIpG/7HqFQh9/Qsq2wqQxnUy9iFsy0rtuGWuPmoA7vSMbO/yN9xw82jfy9HbNBT+qmhchcPPDp/2yly/PoOBiJXEHO4eJzCQXaoqGFegFujH0wjG/e6k3fSiqTOgJmvbZInkRfQODY6cjdyz6pWR7CfUMwC2YuZzqGjpBUocK5QSsKYo9X+eqna9lJ/Hx6LW1qNWNgWK8KlaG7fgHBZHAY/aLbsdnsWUpKCvPnz2f58uVs2LCBVatWcfny5TuOS09P55NPPrGVGdWG/LMH0MQew6vnoyh9bS8hEZ0Sg0quIswnBKlCRcDIN/B4YCi5J7aRsuaTKslhm7VvOYb0RPwGv2SVXL4yFw/cWvchL/oAxtwMDCaBX/44zzNzd5GaWSRGN7ZvON7u9n/LrSyC2UTKus8pTE0gYMQb9wzgqyxhPo4VoAZFORJMeRkUJledTXpjIQsO/4haqWZyx/EVjuzXxkeCTI7Tf/S5HAGbOYRDhw7RqVMnPD09UavV9O/fn+3bt99x3MyZM+/7nAvG3Awydv6IKqgxHh0HV0mdUSkXaOrXCPk/480SqQyfvhPwHTAJzZXT3PjlXYy5GTarX3s1mpxjW3BvN8Cq3X6PTkMBgbidq/l+Wwpr9lzigWaBODvVnGHOImmPJWjjTuM7YCLqhm1tWp+LUk1d91oOM7EM/4jdSaRVutrolzNruZ57k5cemICHk3uFy9HGReEUFF5uKZGqoEy/ksjISP766y8MBgNdunShY8eOpZ6TmpqKn5+f5bO/vz9RUVHFjvnll19o2rQprVpV7IFw9uzZCp0HDqTiKgi4nlyNvFBPVoOeJJ8+Y7OqbrU515DPzbxUmqga3OU6+CJv+zCuZ9ZzdfEb5Lcbg8ndyvo9Bh3uB38AtTcJ3i1IsOK9EASBbEVD6sTsQ2F6mCd61qJhbYHYC9FWq8PeqOIOo479E22DzlwSfOA/188W321v3DmfEsuJEyccZqjN1bMO6ZEHoEuYzX/PsflX2ZX8Fx09W2BM0nIyqWL1SfT5eKZeRduoBzcrabMt2lyqQ9iwYQPz58+nX79+CILAG2+8wcsvv8yYMfdeamU2m4t9cQRBKPY5NjaWnTt3snTpUpKTkytkfPPmzVGpyr9k8uTJk7RrV3JKu6ok98xu0tOv4NPvGUI7lG/9fXm4vc174w5BAgxs9yD1POvc5eh26Nt0JHnVh3gcX0bAiNdRN7Le9UrdvIh8fT61J8ytcMrPe/FTTBYNEi7yUngCLYdYL47DEcg/9zepsX/i0rQLDYa/iuQ/wxa2+m7nxRcSeewigY3qEORh30Twt8g2JJG552ekmmzadOtjs3rSNZl8tWM5oV7BvNpnkqVXXRHyz/5FKhDadSBOtRtWuJyK3me9Xn/PF+lSh4yWLl1aoUjlwMBA0tLSLJ/T0tKKBbht376dtLQ0Ro0axaRJk0hNTeWxxx4rtdyahCEnlYxdS3EKbo57+wFVVm9UygU8ndyp63HnSpxbqALqU+epj1H41CZ5zcfknNhmlboLYo6SH7UPzy4jreYM8jWFLFx1mkvXi6Jpn3y8Ly7hD6BOPIVZb/u5kKpCe+08qZsX4VS3SVGMShWq094SunOUhDlQNI8AoEiNtVkdZrOZRUd+wmQ28UrnpyvlDKAoXkTq7GrTOZ/KYLNI5YiICA4fPkxmZiZarZadO3fSvXt3y/4pU6awY8cONm7cyOLFi/H392f58uUVbEb1QxDMpG/5BhDwG/xilf24zYKZ6JQYWgQ0LrXrL3fzpva4OagbtiNjxw+k7/qpUiuQjPnZpG37DmVgCF5d751ntqwcirrB5E/3sufEdS79o056SxpbatSRe2qHVeqxN4UZSaSs/QSFhz8Bo9+ulLZVRajl6o+bypWLDjSxrPCuhcKvrk0dwroL27iQdpln2z1KoJt/6SfcA0EQ0MZH4ly/hc1XEVYUm0UqBwQE8NprrzF+/HiGDx/O4MGDadmyJRMnTiQ6uuaM51aU3JM70V6NxqfPBBSelfuilYdr2Unk6fPLrF8kVToRMHoq7h0Hk3tsCylrP8NcqCt3vYIgkP7Htwh6Lf5Dp1Q6eCorV8dHPx/jo5+P4+XmxBevdGdgxL9vXU61G2LwqU/O0c2YjYWVqsvemApySF45FyRSAh+ZYZfcuxKJhHCfEIcKUANwadQBedZ1TNo8q5cdk3aFNee20i24I93rP1Dp8gwZSZjyMh1yuektSv1Vvvvuu0yePJk5c+YAoFAo+Oqrr8pU+JAhQxgypLgc7JIlS+44LigoiL1795apzJqAISuZzL2/4BzSuty6PZXlX7nrsusXSaQyfB98CoVnABm7fuLGr+8SOGZ6uaIs8yL3orl0Au++T1ZYjvl2dh+/xvHzKYwf2IQRPRveVX9IFxKB4vhy8qP24d62X6XrtAdmg57k1R9hys+i1hPvo/AKtJstYb4hnLgRRa4+v8wJYGyNOqwj2YfWobl8ErcWPa1Wbn5hAQuP/B/+Lr480+7OjH0VQRtfJHddrR2CGKlsXQTBTNrmr5BIZfgNmlzlKzaikmMIcq+Ft7Nnuc/16DAQhWcAKeu/IGnpNGqNnY7SP7jU8wzZKWTs+j+cgpvh0bHikdApmRoycrQ0beDDiJ4N6dKyNrX9Sn4wGb2DUdVuRPbh9bi17uOw3fSSEMwmUjcuQH/jMgGjptpkAr48hN9KmJMeR/s6jiHKpqodilnliib2uNUcgiAIfH98GVnabOb0mYpa4WyVcrVxkci9Aqt0RKC8lDhkdOtNfs6cOXz00UesWLGC1atX8/HHH/PBBx9UmYE1jZxjW9Fdv4BPv6eRu1dtDoJCk4EL6ZcrlR1N3agdtcd/AGYzST/PKFWGWDCbSNv8FUikFZ4INZsFNv8Vx0uf7WXhqjOYzQJymfSezgCAW2k2s1MpOG+7NJu2InPPL2guHsXnwSdxaVz5IYvKEuoVjEwqc6gANYlEisG/EZorZ6w2NLgn7iBHE0/zaMthNPSpb5UyBZMB7bVzDpUM526U+Ot0cysap/Ty8sLT0/OOP5HyU5iRRNa+5agbtcfVit3bsnIx/QoGk4GWlcyOpgpsULQCySuQ5FUfkntqZ4nH5hzbiu7aeXz7PY3Co/xvRtdT8pj29d8s3hBN0xAf/jepc7nE6NRh7VH4BpF1aB2CYC53/fYi5/gfRYF77QfiXsX6UiWhlCsJ8azrUAFqAIX+YQgGHbqrlZ+bTMy9ydLTq2kZ0ITB4X2tYF0RuqRYhEKdQw8XwT2GjB55pGjczNvb+47loIsXL7atVTUQi8SzXInvQ8/bJbgnKvkCMomUJn6NKl2W3N2H2uPmkLphPunbvseQdRPv3uOK9QAKU6+RuW8Z6rCOFXKAt8TonJQyXnu0Lb3aBZX7ukkkUjwjRpC2aRGaSyctSxUdmYKLx8jY+X+owzrg8+CTDhMIBhDmG8rOKwcwmk3lyg5mS4w+wUiUThRcPIa6YcVjMApNBhYc+hEnuYoXH5hQYWmKu6GNiwKJFKf6za1Wpi0o0SGsWLECnU7H0qVL0ev1lu0Gg4GVK1cyadKkKjGwppBzZCP6G5fwH/6q3SRvo1IuEOYbgrOVFCulKmcCHn6bjF0/kXNkE4asFPyHvYJUoUIwGYqE65xc8BtYPgeYrzXg6qygXoAbj/YLp2/Heni5Vdxm16Zdydq/iuxD61A3au9QD9j/ortxmdQN81HVCsV/+GsON+8R7hvC1tg9XM26brXhlEojlaMObYPm0gkEwVzhJdy/Ra4jISeJad1exMvZujlftPGRqGo3RObkYtVyrU2JV04ulxMbG4tOpyM2Ntbyd+3aNaZNm1aVNlZ7ClOvkXlgFS6NO+HStKtdbNCYdFzNSqSFldNlSqQyfPs/i0+/p9FcPMbNX9+j4NIJbi6fQ2FKPL4DX0DmUrYfl95g4uet53n2NjG6h/uEVcoZwD9pNjsNQ58US/of36JLvFip8myBLvEiGXt+JnnF/5C5eBIw5h2kCvsmLrobjhigBkWrjUwF2ehv3CmgWRqx6XF8dWQp2y/tY1BYH9rWtu5bvEmbj/7mFYfLjnY3SuwhPPzwwzz88MPs3r2bvn2tN5Z2vyGYjKRuWohUpcZ3wCS7vZ0maG4gIFRqQvleeHQYhNzDn5R1n5Oy+qOijRIpMnXZRMDOxWWwaPVpktIKeLBjPdRWFqNT+BZJdOSd2UNe9H68e49D6Vv55a/WoDD9Opl7fwWTEQCf/hORu3ra16gS8Hb2xM/Fh4sZcQzCdnIR5UUd2hYkUjSxx8q1Gis2PY73//wSg9mABAkdbLB6SpdwFgSzw88fQBmWnbZt25alS5dSUFCAIAiYzWYSEhL4/PPPq8K+ak/2wXUUpsQTMGpqmd+UbcFVbRJqhTOh3qUvE60oLmEdcG/dh9yT/6raahPO4RQUXuI5giCweH00Ww7G4++tZs5znWkdZv1lefqkS/9+MBnJ3PWT1euwChIJxpy00o+zI+E+IZxLi71Dn8yeyJxdcQpuRkHscbx7PVHm886lxmIwF+XLkAAX0+No6m/d5b2a+EgkSie7LxsuC6U6hFdffRUnJycuX75MREQEhw4dchhhOEdHfzOOrINrcW3WDZfGnexmhyAIXNUk0SwgDJmNx6Rdm3cnL3IvgsmIRCbHObjZPY+XSCSYzAJDu4XwxENNcFbZJsbFObgZ2XJlUR5eqRzffk+j9Ct/titbUJh2jfSd/wdmU5mumb0J8w3h72vHydBk4evibW9zLLiEdSBj5/9hyLyBwrtkna7bUf8znyYB5DI5zazsDKAof7JzcHOrpja1FaVaeOPGDXbv3s3s2bN55JFHePnll5k8eXJV2FatEYwGUjcvQqZ2x6f/M3a1JSU/jVxj2eUqKoNTUDi1Hp+NNuEczsHN7to7yC0o5MdNZxnUpQFh9bx4YVRLm79plsUue+FUtzFK/2CHtO1uhPuGAhCTfoWuDuQQ1P84hILY43h2Glbq8WbBzN74Q7ir3BjQsActA5tY5kishSE7BWNWcpWnpq0opToEX9+itHz169cnNjaWoUOHYjQabW5YdSfrr9UY0q4ROGY6Mueq1565nYrIVVQGp6Dwuz7UBEHgYNQNvl8XTZ6mkMbBXoTV86qyYYeS7HIEHNm2/1LPozYquYrY9Di6BjvOMl6Fhz/KgAYUXDxWJofw19VjxGddZ0qnp+gaXHqOl4qgjbslV+H4E8pQBofg4+PDDz/8QOvWrVm0aBGurq7odOUXN7uf0CXFkn14A64te1s1j0BFiUqJwV3uSi1X+4XMZ+bq+Pb3SI6cTaZhkAf/e64zDWrbb05FpOLIpDLCfOpzMcOxVhpBUS8h+681mApy7jlnpzPqWRG9kYbe9Ymo195m9mjjo5C5+aDwuVveEcej1AW7//vf/1AqlbRv357mzZuzcOFCpk6dWhW2VUvMBj1pmxchc/PG98En7W0OZrOZcykXqa+ubdcJwL0nrnMqJpWnBjdl3pTuojOo5oT5hJKQnYTO4Fgvh0WBhwIFl07c87gtF3eTqc1mfOvRVg1Aux3BbEJ7NRrnBq0cZvK9NEq9Ej4+PowfPx6AqVOnsmHDBpydrSP2VBPJ2r8CQ8YN/AZNRuoAQShXshIoMGgJdq76N5TkjALOxRXlZR7eI5SvpvZmZK9GyO6iTCpSvQj3DcEsmLmcedXephRDGdAAubsvmtjjJR6Tqclm44WddKrblsZ+oTazRZ8cj1mXjzqkegwXwT0cwtmzZ3nkkUd4/vnnyczMBIommF9++WVeeOGFKjOwOqG9dp6co1twa9vPqonjK0NUctH8QX112VZdWAOTWWDTgSu8NO9PFq3+V4yulq/9HaSIdWjkU5R7wtF0jSQSCeqwDmjjIzEb9Hc9ZmX0JkyCmcdbDrepLdq4MwA4168BDuH999+nX79+BAUF8e2337J7926GDh1KQUEBGzdurEobqwXmQh1pW75G7umHT5/x9jbHQnRKDA0866KWVU2v7lpyLtO++oslG8/SPMSHOc9FlEuMTqR64KJUU9e9lkMpn95CHdYBwVhomdC9nbjMa+y/eoSBYb0IcPWzqR3a+CiUAQ3sGn9UXkqcVM7Ly+Ppp5/GZDLRv39/tm3bxvvvv8+gQdVj+VRVk7n3V4xZydR64n9IlY4xpKYz6IoiSsN6QxUsDEu4mcur8/fjrJLzxmNt6dG2/GJ0ItWHcN9QDl8/iVkw22wcviI412uGVKWmIPY4LuH/rh4SBIFfI3/HVeXCiCa2zWFuLtSiS7xYqfwf9qBEh3BrnkAmk6HX61m8eDFNmzatMsOqE9r4KHJPbse9wyCHCio6n3YZk9lEy4AmGJI0NqsnX1OIq1pJvUA3nhjQmD4d6uHp5ng6PCLWJcw3hN1xf3MjN4Ugj1r2NseCRCZH3bAdmssnEMwmi0DgiRtRnEuN5Zm2j+CiVNvUBt2182A2Vgu5itsp0a0LgmD538vLS3QGJWDWa0jb8jUK71p493rc3uYUIzolBoVUTmNf20yc6Q0mlm45x7Nzd5HyjxjdqN6NRGdwn3B7gJqjoQ7rgFmTaxEyNJqM/HZmHXXcA+kbanuBSU18FBK5Eqe6VRP7Yy1KdAhms5mcnByys7MBLP/f+hMpImP3zxjzMvEb8rLDqVNGpVygsV9DlHKl1cuOvpLOy/P+5Pc/L9OlVR1cnBVWr0PEsQl09cNN5Uqsg00sA6hD24BUbllttPPKAW7mpzK+9Siby7dAkdy1U90mDvdMKI0Sh4xiY2Pp1KmTpafwwAP/pvCTSCRcuHDB9tY5OJrLp8g7sxuPzsMdLso0S5vD9ZwbdLNyBKbZLPDd+ii2HbpKoI+aD56PoFUj207OiTgmEomEcJ8QhwxQk6rUONdvTkHsMZRdR7Hm3FZaBTahdaDth3SNeZkY0q5bLcdzVVKiQ4iJialKO6odJm0+aVu/ReEbhFf3sfY25w6iU4run7X1i26tGBreI5THBzTGSen4gl0itiPcN5QTN6LI1efjriolx3UV4xLWgfTtS1hzajUag5ZxrUZVySIHbXwUQLWbP4AyBKaJ3J2MXf+HqSAb/6FTkNpgSKayRKVcwE3pQn2voEqXlZOv5/PlJ4m9lgXACyNb8szQ5qIzECH8HzE4hxw2atSBNIWMnddP0KdBF+p5Vk1wpjY+EqnaHWWA7aTmbYXoECpAwcVj5Efvx7PLSFS1bBfpWFEEQSA6OYbmAY0rtRxQEAQOnE5k8qd7+ftMEvE3cgDEpaQiFkK86iGTyhwugxoU5f3eUScAhSAwpsWQKqlTEIQiuesGLSucytOeiK945cSkySV923coAxrg1XW0vc25K0m5yWTpciqVHS0jR8u3v0dx9Fwyjep6MmVsG+rXKlv2M5H7B6VcSYhnXYcMUDubcpGzciP9M/JxNRjBOqnE74kh7RqmgmzU1XC4CMQeQrlJ3/EDJm0BfkNeQiJzzJU1t+SuWwZWfP7gz5OJnI5N4+khzfhsSnfRGYiUSJhvKJczEzCaHEcW32w288uZtfio3OmarUFTitidtdDE35K7Fh1CjSf/wiEKzh/Eq9vDqALq29ucEolKvkCgqx9+Lj7lOu9menExuq+n9mJEz4bIROkJkXsQ7huCwWTganaivU2xcCDhKFezE3m8zSicPQIoiD1WJfVq4yJR+NRB7l6+356jIDqEMmLMzyZ922JUtULxjBhhb3NKxGgyci7tUrlWF5nMAhv2X+aleX/y1Zp/xegCfUQxOpHSuZVlzFHmEXRGPSuiNtLIuz5d6nXAJawD2qvRmPVam9ZrNhaiu3a+2vYOQHQIZUIQBNK3fY9QqMNvyMuWUHhH5FJmPHqjvszDRQk3c3lr0QF+3HSOVo18RTE6kXLj7eyJn4uPwyifborZRZYuh/FtRv+jftoRTEY0/6iP2gp94kUEY2G1yY52N8RJ5TKQf/YAmthjePceh9Kvrr3NuSdRyTFIJJIyJQsvEqPbh9pJwdQn2tGtdR1xBZFIhQj3CeFcWiyCINj1O5SpyWZTzE4i6razSGs41W2M1NkVTewxXJt0tlnd2vhIkMpwDm5uszpsjU17CJs3b2bgwIH069ePZcuW3bF/9+7dDBs2jKFDhzJ58mRycnJsaU6FMOZmkLHzR1RB4Xg8UDVL1ypDVMoFGnoF31O8K7egEIB6gW6MH9iUb97qTfc2ojKpSMUJ8w0hS5tDuibTrnasiN6IIAg81urfYV2JVIa6UXs0l08h2HDiWxMXhVOdMKQqx1A7rgg2cwgpKSnMnz+f5cuXs2HDBlatWsXly5ct+/Pz85k9ezaLFy9m06ZNhIeHs2jRIluZUyEEQSDtj28RjAb8h7zk0ENFAJpCLZczr9KihOEiXaGRHzed5dm5u0jOKEAikTCiZ0M8XKuX3oqI43FLQNGew0ZxmQn/5Drojf9/FlS4NOqIWZeP7rptJHdMmjwKk+Oq9fwB2NAhHDp0iE6dOuHp6YlaraZ///5s377dst9gMDBr1iwCAgIACA8P5+bNm7Yyp0LkRe5Be+U03r2fQOFddRnHKsrZ1IsIgnDXCeX4FB0vz/uTDfuv0KNtEG5qx4uuFqm+1PWojZNcZbeJZUEQ+PnM77irXO+a68A5pBUSudJmq420V6MAAWcHyZRYUWzmEFJTU/Hz+1f0zN/fn5SUFMtnLy8vHnzwQQB0Oh2LFy+mb9++tjKn3BhyUsnYtRSn4Ga4t3/I3uaUiaiUC6jkKsL+SW8IRWJ0X6+N5Oc96UiQ8OELXXhxdCtRnVTEqsikMhr51LebhMXxpEgupF1iTPMhqO+SoEqqdMK5fgs0sceLSftbC218FFKV2iGVC8qDzSaVzWZzsTHpkiab8vLyePHFF2ncuDEjRpRvOefZs2crbN/JkydL3ikIuJ5YgdxkIiW4BzdPna5wPVXJiYRI6ij9iTxTPHVgRnoWEU1c6dnCncKcBE6eTLCThVXPPe9zDcVebXYrVHM2O5bDx4+glFbdC4dJMPHDsdX4KD3xynYusf1KVQAuOSeJ3LcNk3uA9QwQBNxjjmPyDOLU6TPWK7cUbHGfbeYQAgMDOXHi3+jAtLQ0/P39ix2TmprKM888Q6dOnZg+fXq562jevDkqVfnHv0+ePEm7du1K3J9zYjsZGVfxfeg5Qtv2KXf59iC9IJPMyzkMafYgDes0Z8mGswzp1oDwYG/athU4derUPdtcEyntPtdE7Nlm2U1nDh04jVs9T5pXQjalvHy3ZynZhlymd3+J1rVKlrc2hody7dw2guX5eLUbaLX6DZk3uL4jh4CeY3Cvomtf0fus1+vv+SJtsyGjiIgIDh8+TGZmJlqtlp07d9K9e3fLfpPJxPPPP89DDz3EjBkzHGaFiyErmcy9v+Ac0gq3Ng/a25wyc0uuQpfpxQuf7OVgVBJXb+YBohidSNXQyKc+EiRVOrGcp8/nYOZpWgU2vaczAJC7eqIKCqPgn6Q51kITV33lrv+LzXoIAQEBvPbaa4wfPx6DwcDo0aNp2bIlEydOZMqUKSQnJ3P+/HlMJhM7duwAit74586dayuTSkUQzKRt/gqkMvwGTa5WD9Lj188hNzuzdO01wut58/LY1gQHivpDIlWHi1JNkEetKp1YXnvuDwrNBsa1Glmm413COpK591eMuenI3X2tYoM2PhK5hz9yr0CrlGdPbBqYNmTIEIYMKb52f8mSJQC0aNHC4ZLw5Bzbiu76BfwGv2i1L0tVYBbMnE2JwZDtzbPDWjC4a4ioPyRiF8J9Qjh0/SRmwVwp6fWycCM3mZ2X99PKPbzMuQ7UYR3I3PsrBReP4dGh8sNGgtmENuEsrk0iqtULZEmI0hX/UJiRRNa+5agbtsO1ZS97m1MmbqTlE30lnYTsJPSClnHdujOse6joDETsRphvCBqDlqTcZJvX9VvkepQyJV29yz6WrvSpg8KnNppL1hk20t+4hKDXVPvlpre4b6UrYtPjOJcaSzP/MBp5B5O2aRESuRLfgS84vKc3mcxsPHCFZdtj8PdW039IUfRl19Dqq6EiUjO4PUCtroftYnfOpsRw4kYUj7UcjoumfJHB6rCO5BzdjElXgMypcgKO2rgoQIJzcItKleMo3JcOIUmbwso/l2I0G1FIFbzu2xqvG5fwH/4qcjcve5t3T+Jv5LBw9RkuX8/mgWaBvDCqJd+eXkJd91p4O3va2zyR+5wAVz/cVa7EpsfRN7SrTeowm838fOZ3/NTeDAzrTfSZqHKd7xLWgZzDG9BeOYVrs26VskUTH4mqVigytVulynEU7ssho2vam5jMJgAMZgO7rvyNS+NOuDS1zRfYWly9mctr8/eTnqXl7fHtmfFUR9xc5VxIv0yLKlzmJyJSEhKJhDDfUJtOLO+7eoSE7EQebzUCZQWSVKlqN0Lm4lHp1UZmvQZ9Umy1Vjf9L/dlD6Gecy0UMjlGkxFBEDjlpiKwXm2eMJuQyxzvkuTk6/FwVREc6MaTg5vSu3093F2KpCdi0i5jMBkqlR1NRMSahPuEcCIpklxdHu5O1n1z1hl0rIzeSCOfBnSuW7E1/0Vidx3IP38QwWhAIq9YEJ024RwI5hozfwD3aQ+hjnMA7/V8lcEKf55NyqSnSxB/xP3Ne3s/JzU/3d7mWdDpjSzZGM3ED3dbxOiG92hocQYA0SkxyCRSmvo1sqOlIiL/Ev5Pwhxb5FneGLOLbF0uE1qPrtRcnzqsA0KhFm1CxdUOtPGRSBQqnOqEV7gMR+O+dAgAQTk5RFyIJlRn5KFzZ3k5fBA38lJ4a+eHHLl+yt7mcSY2lRfn/cmmA3H0ahdUzAncTlTKBcJ8Q3BSVEEGcRGRMhDiHYxMKrN6gFq6JpPNF3cRUa+9JUtbRXGu3wKJQoWmEsNG2vhInOo1rXAPwxG5bx2C/uZloOgNQzAZaV5QyKf9plPLzZ8vDi3hx5MrKTQZqtwus1lg4arTvPv9YeRSCR9N7sILo1qhdrrzS5erz+dqViItypEuU0TE1ihlCkK86lm9h7AyalNRroOWwytdllShwjmkNQWXKiZ2Z8xNx5Bxo0ZEJ9/OfesQnOu3LPLsEikSmRzn4Gb4u/oyp/ebDA7rw47L+3l392fczEutUrukUgkqpYxRvRqy8M1eNA8tOUDubMpFBARaihPKIg5GuE8IlzMTMFopIc2VzAQOJBxlUHifO3IdVBSXsA6Y8jIpvFn+CXBNXJGApFp0CDUDp6Bwaj0+G68ej1Lr8dk4BRWNA8plcsa3Gc1bXV8gTZPJ2zs/5O8E62qf/JesPB2f/nqCmISibFOThrfgycHNUCnunZAnKuUCaoUzod7BNrVPRKS8hPmGYDAZiM++XumyBEHg59Nr8FC5MbxJfytYV4S6YTuQSCu02kgbH4nM1QuFg6fULS/3rUOAIqfg1WWkxRncTvs6Lfm0/3SCPYNYeOT/+O74b+iNhVatXxAE9p64zouf7uVw9E2uJ5ddjE4QBKKTL9DMPwyZg2dyE7n/CLdiBrWjiaeJSb/C2BZDUCusl55SpnbHqW5jNJfKlzRHEMxor0bj3KClwwexlpf72iGUhq/am9m9XmN4k/7sjTvI9N2fkJhjnaxuqVka3v/hCPNXnCLI342Fb/TkwQfK/qafkp9GmibzrtnRRETsjZezB/4uPpVOmGMwGVgWuZ66HrXp1SDCStb9izqsI4Wp1zBklV1qozDlKmZNbo2KP7iF6BBKQSaV8VjL4Uzv/jI5ulze2fUx++IPV7rcv88kcS4ug0nDW/Dxi12pG1C+9dq35K7F+AMRR+VWgFplMpRtv7SflIJ0xrceZZOesEtYB4ByDRtp/5k/cK5fs+YPQHQIZaZ1raZ81n8mDX3q882xX/jqyFJ0Bl25ykhKyyf6clGcw7DuoXz9Vm+GdAtBWgExuqjkGHzV3gS6+pV+sIiIHQj3CSFLl0OaJrNC5+fq8/n9/B+0qdWMVoFNrWxdEQqvQBR+9cq1/FQbH4nSv57Dy9xUBNEhlAMvZw/e7fEKY5oP5q9rx5i262MSshNLPc9kMrN27yVenvcn366LxGwWkMmk+HupK2SHyWzibOpFWgY0rnFjmCI1B0uAWgVlLNae3YrOqGdcq1HWNOsOXMI6oLt+AZMmr9RjzQY9uusxNW656S1Eh1BOpFIpo5sN4r2er6I16Ji+6xN2Xf6rxG5x/I0c3lh4gJ+3nqd9kwDmPt+lQj2C24nLuobGoBWHi0QcmroetXGSqyo0sZyUm8zOKwfoG9KVII9aNrDuX9RhHUEwo7lceo5i3fULCCaD6BBEitPMP4xP+0+nqX8YS04u58vDP6IxaIsdc0uMLiNHx7QJHZj+ZEe83CsfURyVXDR/0Ny/5oTMi9Q8ZFIZjXwaVGhi+dfIdajkSh5uPsgGlhVHVSsEmas3BbGlrzbSxkeCTI5TPdsMYdkb0SFUAg8nd97p/iKPtRzO0cTTvL3zI+IyE8jJ1wMQHOjG00Oa8c1bvenS0nra8FEpMTTwrGt14TAREWsT7hvC1ZxEtOWYb4tKvsCpG9GMbPIQHk62TwMrkUhRh7VHGxeJuZSl5dq4KJyCGiNVqGxulz0QHUIlkUqkDG/Sn9m9XsdgMvLOrk+ZuHgxN9PzkUgkDO0eipv67jpEFUFn0BGbEUcLcbhIpBoQ5hOKIAhczrxapuPNZjO/nvkdPxcfHgqrusyFLmEdEQw6dPHRJR5jzM+mMPVqjR0uAtEhWA1NphuFZztjzPKBOuf5+fyv5OsLrF7P+bTLmMwmUa5CpFrQyKc+EiRlnkf4M/4QCTlJPFHBXAcVxTm4ORKl8z2HjXRXi5yFugbGH9xCdAiVxGwWWLDyNLMWH0YpVfO/flMY33o0kSnneGvnh5UOzPkvUSkXUEjlllSFIiKOjItSTZBHrTKtNNIadKw8u5lwnxA6BbWtAuv+RSJXoA5tg+bSCQTBfNdjNPGRSJ1dUQY2qFLbqhLRIVQSqVSCs5Och/s0YuEbPWkW4svg8D7M6f0mUomEWXs/Z1PMTswlfMnKS3RKDI39GqKUW28YSkTEloT7hhKbEV/qb2BjzA5ydLmMb1O5XAcVxSWsI6aCbPRJl+7YJwgC2vjIItnsGiwVIzqECpCVq+PjX44Tc7Uo4GbisOaMH9gU5W1idA196vNJv+m0r9OK3yLX88lf35CrK32d8z3r1eZwPeeGKFchUq0I9wlBY9DeU/YlvSCTzRf30LVeBxr52OcN3LlhW5DK7jpsZMhIwpSXWaPnD0B0COVCEAR2H7vG5E/3cuxcMomp9xajc1GqeT1iIs+0fYTolItM3TmX86l3vn2UleiUGAAxf7JItaIsGdSWR28EsEqug4oic3LBuV7Tu0Yta+P/kasQHYIIQEqmhlmLD7Ng1WnqBRaJ0fXtWLoYnUQioX+jHnzY9y2cZCre3zef38/9gdlc/iGkqJQLuKlcqe8VVJEmiIjYhQBXP9xVriVOLF/OuMrfCccYHNYHXxfvKrauOOqwjhgykijMuFFsuzYuEoV3LRSe/nayrGoQHUIZORiZRExCJs+PbMlHk7sS5F++GID6XnX5uN87dKnbnlVnNzP3wEKytTllPr9I7jqGFv7hSCXibROpPkgkEsJ8Q++6wEIQBH4+s9bquQ4qyi2xO81tw0aCyYA24VyN7x2A6BDuyfWUPCIvpQH/iNFN7cOgLg0qLD3hrHDi5U5P8XyHJ7iYHsfUnR9aoo5LIzH3Jlm6HHG4SKRa0tg3hJv5qXfMox1NPM3F9CuMbTEUZwfICy738EMZ0KDYPIIuKRbBoKuRctf/RXQId8FoMrN6dyxTPt/H9+ujLWJ0fl6VT84hkUjoHdKFD/u+jZvShbn7F7EyehMms+me591yHKJ+kUh1JMznn4Q5t80jFJoM/Ba5jnoedehtg1wHFcUlrCP6xFiM+dlAUXQyEinOwc3ta1gVIDqE/3A5MZvXv9zPr9su0Kl5IHNfiKi0GN3dqOdZhw8ffJseDTqx7vw2/rdvAZma7BKPj06JoZarP35WyicrIlKVhHjXQyaVFZtH2H7pT1ILMhjfehRSqeM8itRhHQABzeUTQNGEsqp2I6ROLvY1rApwnLvgAMTfyOGNBQfIztMz/cmOvD2+A15utuvGOslVTO44npceeJK4rGtM3fEBp26cveM4o8nIubRL4nCRSLVFKVMQ4lXPEqCWq8vj9/PbaFurucP1epUB9ZF7+KGJPY5Jm4/+5pX7YrgIRIcAFCW5B6hfy51nhzbnm7d607mFbSV3b6d7/Qf45MFpeDt78vFfX/Nb5DqMtw0hxWbEozfqHe6HIyJSHsJ9Q7mSmYDRZGT1uS3ojYU80Xqkvc26A4lEgrpRB7TxUUWS2IIZdUjNn1AGGzuEzZs3M3DgQPr168eyZcvu2H/hwgVGjhxJ//79mTFjBkaj0Zbm3IFGZ+C7dVFM+nA3N9MLkEgkDOkWgqsVxejKSm33QOb2fYt+od3ZFLOLWXs/J60gAygaLpJIJDTzD6tyu0RErEW4bwgGs5G/Eo6x+8rfPBjajSD3qnvxKg8u4R0RjIVk7V+JROmMqnYje5tUJdjMIaSkpDB//nyWL1/Ohg0bWLVqFZcvXy52zNSpU3nvvffYsWMHgiCwevVqW5lzBycupPDiZ3/yx6F4+nUKxsvN/nK2SrmSZ9s/yqudnyUx9yZv7ZjLscQzHE08jbeTB0m5ZU8ELiLiaIT5FAWofX9iGQqpnIeb2T7XQUVxqtsEidIJY04qSv9gJDK5vU2qEmzmEA4dOkSnTp3w9PRErVbTv39/tm/fbtmflJSETqejdevWAIwcObLYflthNgusP5zJ+z8cwVkl49OXujFxWAucVI5zwyPqteOTftMJcPVj3sHvScy9SYY2m//t+9LqYnkiIlXFrR6vWTBjNJtIzk+zs0Ulo795BcFQlBtBf+MSusSLdraoarDZUzA1NRU/v38TwPv7+xMVFVXifj8/P1JSUspVx9mzd07AlgVnpZTuzdzo3tydgox4TmbEV6gcWzPCuw8rNX+QpC+6LgaTkZ2n/yTPO6tC5Z08WXqKwJqG2GbH4XDmGcv/ZsFcqe/yf7F2m52uHMJJMCMBBLOZK4d2ogvNt2odlcUW99lmDsFsNhfT+BEEodjn0vaXhebNm6NSVWSo5yTt2rWrwHlVj1d9X/6370uMZhNyqYx+bXoR9o82THk4ebL6tNlaiG12LNzSvTiyLxKjyYRcVvHv8n+xRZt1Aa7cjD+EYDIilckJjeiHU5DjpKytaJv1ev09X6Rt5hACAwM5ceKE5XNaWhr+/v7F9qel/dtlTE9PL7ZfpIgw3xDe6/kq51JjaeYfZpUfkIiIPahO32WnoHBqPT67SLIiuJlDOQNbYjOHEBERwaJFi8jMzMTZ2ZmdO3cyZ84cy/46deqgUqksnm7jxo10797dVuZUa8J8Qxz6xyMiUlaq03fZKSj8vnEEt7DZpHJAQACvvfYa48ePZ/jw4QwePJiWLVsyceJEoqOLUtHNmzePjz76iAEDBqDRaBg/frytzBERERERKQWbLq0ZMmQIQ4YMKbZtyZIllv8bN27M2rVrbWmCiIiIiEgZESOVRUREREQA0SGIiIiIiPyD6BBERERERAAbzyHYCkEQACgsLKxwGXq93lrmVBvENt8fiG2+P6hIm289M289Q/+LRChpjwOTl5dHbGysvc0QERERqZaEhYXh5nZnGuBq6RDMZjMFBQUoFIpyRzeLiIiI3K8IgoDBYMDFxeWuSYmqpUMQEREREbE+4qSyiIiIiAggOgQRERERkX8QHYKIiIiICCA6BBERERGRfxAdgoiIiIgIIDoEEREREZF/EB2CiIiIiAhQwx3C5s2bGThwIP369WPZsmV37L9w4QIjR46kf//+zJgxA6PRaAcrrUtpbd69ezfDhg1j6NChTJ48mZycHDtYaV1Ka/Mt9u3bR+/evavQMttRWpvj4uIYN24cQ4cO5Zlnnrkv7vO5c+cYNWoUQ4cO5bnnniM3N9cOVlqX/Px8Bg8eTGJi4h37bPL8EmooycnJQq9evYSsrCyhoKBAGDJkiHDp0qVixwwaNEg4ffq0IAiC8M477wjLli2zg6XWo7Q25+XlCV26dBGSk5MFQRCEL7/8UpgzZ469zLUKZbnPgiAIaWlpwoABA4RevXrZwUrrUlqbzWaz0K9fP2H//v2CIAjCZ599Jnz66af2MtcqlOU+P/roo8K+ffsEQRCEjz76SPjiiy/sYarVOHPmjDB48GChWbNmwvXr1+/Yb4vnV43tIRw6dIhOnTrh6emJWq2mf//+bN++3bI/KSkJnU5H69atARg5cmSx/dWR0tpsMBiYNWsWAQEBAISHh3Pz5k17mWsVSmvzLWbOnMlLL71kBwutT2ltPnfuHGq12pKS9vnnn+fxxx+3l7lWoSz3+ZakDYBWq8XJyckeplqN1atXM2vWrLvmmrfV86vGOoTU1FT8/Pwsn/39/UlJSSlxv5+fX7H91ZHS2uzl5cWDDz4IgE6nY/HixfTt27fK7bQmpbUZ4JdffqFp06a0atWqqs2zCaW1+dq1a/j6+jJ9+nRGjBjBrFmzUKvV9jDVapTlPk+bNo2ZM2fStWtXDh06xCOPPFLVZlqVuXPn0r59+7vus9Xzq8Y6BLPZXEz4ThCEYp9L218dKWub8vLymDRpEo0bN2bEiBFVaaLVKa3NsbGx7Ny5k8mTJ9vDPJtQWpuNRiPHjh3j0UcfZf369dStW5ePP/7YHqZajdLarNPpmDFjBkuXLuXvv//mscce4+2337aHqVWCrZ5fNdYhBAYGkpaWZvmclpZWrOv13/3p6el37ZpVJ0prMxS9WTz22GOEh4czd+7cqjbR6pTW5u3bt5OWlsaoUaOYNGmSpf3VmdLa7OfnR3BwMC1atABg8ODBREVFVbmd1qS0NsfGxqJSqWjZsiUAY8eO5dixY1VuZ1Vhq+dXjXUIERERHD58mMzMTLRaLTt37rSMqQLUqVMHlUrFyZMnAdi4cWOx/dWR0tpsMpl4/vnneeihh5gxY0a17xFB6W2eMmUKO3bsYOPGjSxevBh/f3+WL19uR4srT2ltbtOmDZmZmcTExACwd+9emjVrZi9zrUJpbQ4ODiY5OZm4uDgA9uzZY3GINRGbPb8qPS3twGzatEkYNGiQ0K9fP2Hx4sWCIAjCs88+K0RFRQmCIAgXLlwQRo0aJfTv3194/fXXBb1eb09zrcK92rxz504hPDxcGDp0qOVv+vTpdra48pR2n29x/fr1GrHKSBBKb/OZM2eEUaNGCQMHDhSefvppIT093Z7mWoXS2rxv3z5hyJAhwuDBg4UJEyYI165ds6e5VqNXr16WVUa2fn6J+RBERERERIAaPGQkIiIiIlI+RIcgIiIiIgKIDkFERERE5B9EhyAiIiIiAogOQURERETkH0SHUI0wGAx07dqVZ5991t6mlJmjR4/SsmVLhg0bxvDhwxk2bBgjR45k7969lS578ODBHD16lJSUlFJlCq5fv87LL79c7jp+/PFHpk2bdsd2a7ard+/eREdHl+ucadOm8eOPP95137Bhw8jNzWXdunU899xzAMyYMYNDhw4BRbpOZ8+eLXNde/bs4YMPPiiXfdbk9nZU9Ljb2y9SMnJ7GyBSdnbt2kXjxo05e/YsV65cITQ01N4mlYl69eqxceNGy+eYmBgeffRR9uzZg7e3d6XLDwgIYOXKlfc85saNG8THx1e6rtuxdbsqyu023eL2qPRDhw4xduzYMpfXp08f+vTpYxXb7EVNiMqvCkSHUI1YsWIFAwcOpF69evz888/MmjWL3r178/XXX9O8eXMAXn31VTp27Mhjjz3Gt99+y86dOzGbzdSpU8eidDpu3Dg8PDyIi4vj0UcfpUWLFnz22WcUFhaSlpZGREQEH374IVD01rV48WKcnJzo1KkTv/zyC+fPnwcosfzSaNy4MU5OTiQlJbFs2TLOnDlDamoq4eHhzJs3r8RyL1++zPTp09FqtYSEhKDRaABITExkyJAhnD59GqPRyGeffca+ffuQyWS0adOGWbNmMXPmTFJSUnjmmWf48ccfOXXqFPPmzUOr1SKVSnnppZfo1asXBoOBDz74gEOHDuHj44OPjw9ubm5luj/3atdHH33Exx9/zOHDh5HJZLRs2ZJ33nkHV1dXAJYvX05MTAyFhYU89dRTjB49GrPZzIcffkhkZCQFBQUIgsAHH3xAu3btADh58iQ7duwgPz+fLl268PbbbyOXywkPD+fw4cPFbBs3bhyPP/44Fy5cIDU1lTfffJM5c+bw/PPPs3//ftzc3BAEgQEDBrBgwQIaN25sOXfdunXs2LGD77//nnHjxtG6dWtOnTrFzZs36dy5M3PmzEEqLT7YkJeXx9y5c4mNjcVgMNC5c2feeust5HI5a9euZdWqVRgMBnJycpg4caJFTuT7779n/fr1yOVygoODLRpMaWlpTJo0iZs3byKTyfj888/v+kKUlpbGM888Q2pqKnXq1GHOnDn4+flZ2t+8eXOefPJJevToQWRkJLm5uUydOtUi+njfU+nQNpEq4dKlS0KzZs2EzMxMITIyUmjZsqWQmZkpLFiwQHj//fcFQRCE7OxsoWPHjkJubq6wfv164dVXXxUMBoMgCIKwcuVK4dlnnxUEQRCeeOIJ4Z133rGU/dprrwlHjhwRBEEQ8vPzhQceeECIjo4WLl26JHTu3Fm4efOmIAiCsGjRIiEsLEwQBOGe5d/OkSNHhEGDBhXbtmPHDiEiIkLQaDTCwoULhf79+1vKuVe5w4YNE1avXi0IgiCcOHFCCA8PF44cOSJcv35daN26tSAIgvDzzz8Ljz/+uKDVagWTySS88sorwvr164vZkZ2dLfTr188S/ZmcnCx0795dSEpKEpYuXSqMHz9e0Ov1QkFBgTBixAjh7bffrnS7FixYILz00ktCYWGhYDKZhGnTpgnvvvuuIAhFkaizZs2y2NK5c2chNjZWOHXqlPDyyy8LJpNJEARB+P7774XnnntOEARBePvtt4URI0YIBQUFgl6vF5544gmLHn5YWJiQkZEh/P7778KkSZMs93zbtm2W+m5Fu77wwgvCb7/9JgiCIBw6dEgYM2bMHW39bzlTpkwRTCaTkJeXJ3Tt2lU4fPjwHedMmzZN+OWXXwRBEASj0Si8+eabwuLFi4X8/HxhzJgxQmZmpiAIgnD69GnLvdu9e7fQr18/ITs7WxAEQfjwww+Fb775Rvj999+F9u3bC1evXhUEQRDmzJlT7Pt7u52tW7e2HPf5558Lr7zySrH2X79+XQgLCxP27t0rCIIgbN++XejZs+cdZd2viD2EasKKFSvo1asXXl5eeHl5ERQUxOrVqxk1ahSjR49m2rRpbNmyhd69e+Pm5saff/5JdHQ0o0aNAorUEbVaraW822V1P/74Yw4cOMB3331HXFwcer0ejUbDiRMn6NKlC4GBgQA88cQTLFq0CKDU8m/n2rVrDBs2DChS4gwMDOSbb77B2dkZgNatWyOXy+9ZblZWFhcvXmT48OEAtGvXjkaNGt1R16FDhxg2bJhFC//LL78Eisb8b3HmzBnS0tJ48cUXLdskEgkXL17k8OHDDB48GKVSiVKpZMiQIVy8eLHS7Tpw4ACvvfYaCoUCKHpjv73+W3MgAQEBdOnShcOHDzN+/Hg8PDxYuXIl169f5+jRo7i4uFjOGTZsmEXWeujQoezfv7/cwn2PP/44n332GY8//jirVq3i0UcfLfWcXr16IZVKcXV1JTg4+K7Z2Pbt20d0dDRr164FitRIAVxcXPjuu+/Yv38/V69eJSYmxtLTO3z4MAMGDMDDwwOAd955ByjqobRs2ZLg4GAAmjRpwq5du+5qW0REhOW40aNHM3r06DuOUSgU9OjRA4CmTZuSnZ1dapvvF0SHUA3QaDRs3LgRpVJpSQGZn5/Pb7/9xtNPP03Tpk3Zt28f69atY/r06UDRg/TZZ5+1PCAKCwuL/XBv18d/4oknCA8Pp1u3bjz00ENERkYiCAIymQzhNmUTmUxm+b+08m/nv2Pt/+V2W0or93Z7bj1sb+e/29LT0zGbzcW2mUwmQkNDWbNmjWVbSkoK3t7erFq1qtixt7e5su36r/y6wWCwfL59yMVsNiOXy9m3bx9z587lqaeeok+fPoSEhLBp06a72iYIwl2vR2lERESg1Wo5fPgwJ06c4JNPPin1nNsTz0gkkmL35PY2LFiwwDKsk5ubi0QiITk5mbFjxzJmzBjatWvHgAED+PPPPy3tuf0a5ebmWtJg3t62kuq8VcbtNtztmigUCsv1rgkCj9ZEXGVUDdi8eTOenp789ddf7N27l71797J79240Gg3bt29nzJgxLFmyBK1Waxlf7tq1K2vXriU/Px+ABQsW8NZbb91Rdm5uLtHR0bz55pv069eP5ORkrl27htlspmvXrhw+fNiSeOP2B2hZyy8vJZXr5eVFs2bNLDacO3eO2NjYO87v3LkzW7ZsobCwELPZzOzZs9m6dSsymczyAG7dujUJCQkcP34cKMpN279/f1JSUujWrRsbNmxAr9ej1+v5448/Kt0mgG7durFixQoMBgNms5lly5bRpUsXy/7169cDRZPfhw8fpnPnzhw8eJBevXrx2GOP0bx5c3bv3o3JZLKcs3XrVgoLC9Hr9axfv77MapcymcySf1cikfDYY48xY8YMBg8ejEqlskp7u3btytKlSxEEgcLCQl544QV+++03zp49i7e3N5MnT6Zr164WZ2AymYiIiGDXrl2We79o0SKWLl1arnqPHj3KjRs3AFi5cmW1VzCuasQeQjVgxYoVPPXUU8Xeftzd3Rk3bhxLly5l5cqVvP/++0ycONGy/+GHHyYlJYUxY8YgkUioVavWXZOkuLu7M2nSJEaMGIFarSYgIIC2bduSkJBA586deeedd3jmmWdQKpU0adLEMhxS1vLLy73K/eKLL3jnnXdYuXIl9erVIyQk5I7zH3nkEZKSkhg5ciSCINCxY0fGjRtHfn4+KpWK0aNHs2bNGhYuXMinn36KXq9HEAQ+/fRTgoKCeOSRR7h27RqDBw/G09PTMvxQWV544QU++eQThg8fjtFopGXLlrz77ruW/Xq9nhEjRmAwGJg5cyYNGjTgkUce4Y033mDIkCEYjUa6dOlimWwHCAoK4rHHHqOgoIAHH3ywzMmOHnzwQaZOncrs2bPp2rUrI0aM4JNPPinXyqPSmDFjBnPnzmXIkCEYDAYiIiJ49tlnMRqNrF27lgEDBiCRSOjYsSPe3t4kJCTQo0cPLl++bBm2atiwIXPmzGHnzp1lrjcsLIzp06eTnp5OSEgI//vf/6zWpvsBUe1UpESuX7/Oxo0bmTx5MlKplJ07d7JkyZJiPQWR6s/WrVtZv349P/zwg71NEbEzYg9BpEQCAwNJTU1lyJAhyGQy3NzcLMtRRWoG48aNIzMzk2+++cbepog4AGIPQUREREQEECeVRURERET+QXQIIiIiIiKA6BBERERERP5BdAgiIiIiIoDoEERERERE/kF0CCIiIiIiAPw/jb8rT7jTWsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = nb.predict_proba(xtest)[:,1]\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'Naive Bayes Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'Naive Bayes Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ac0b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes Cal  average accuracy is 0.683\n",
      "Naive Bayes Cal  average log_loss is 0.598\n",
      "Naive Bayes Cal  average brier score is 0.205\n",
      "Naive Bayes Cal  average auc is 0.769\n",
      "Naive Bayes Cal  average recall is 0.879\n",
      "Naive Bayes Cal  average precision is 0.631\n",
      "Naive Bayes Cal  average f1 is 0.734\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "showResults(calibrated, \"Naive Bayes Cal\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da246b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFECV with Random Forest Input + Post admission variables\n",
    "X = X_balanced[['Abnormal_Lung_Signs', 'Age', 'Average_Daily_Use_Cigarettes', 'BMI', 'CKD', 'Cancers',\n",
    "                'DiastolicBP', 'Drug_history', 'Dyspnea', 'Fever', 'Hospitalization_14_days_ago',\n",
    "                'Hypertension', 'ICU_admission', 'Intubation_Duration_Day', 'Oxygen_Saturation_Percent',\n",
    "                'Pantoprazole', 'Respiratory_rate', 'SystolicBP']]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59d9ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.75220863 0.75220863 0.52770982\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.75956507 0.75956507 0.71428814        nan        nan        nan\n",
      "        nan        nan 0.75584438 0.76320931 0.76320931 0.7456422\n",
      "        nan        nan        nan        nan        nan 0.76040605\n",
      " 0.76229188 0.76229188 0.76227489        nan        nan        nan\n",
      "        nan        nan 0.77794767 0.76137445 0.76137445 0.76044852\n",
      "        nan        nan        nan        nan        nan 0.78070846\n",
      " 0.77150017 0.77149168 0.77150017        nan        nan        nan\n",
      "        nan        nan 0.7788651  0.77795617 0.77240061 0.77795617\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "077ac84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7807084607543323 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.752 + or -0.111 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.752 + or -0.111 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.528 + or -0.014 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.76 + or -0.108 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.76 + or -0.108 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.714 + or -0.089 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.756 + or -0.1 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.763 + or -0.097 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.763 + or -0.097 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.746 + or -0.084 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.76 + or -0.087 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.762 + or -0.1 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.762 + or -0.1 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.762 + or -0.097 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.778 + or -0.087 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.761 + or -0.1 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.761 + or -0.1 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.76 + or -0.099 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.781 + or -0.085 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.772 + or -0.092 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.771 + or -0.091 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.772 + or -0.092 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.779 + or -0.084 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.778 + or -0.084 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.772 + or -0.085 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.778 + or -0.084 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0603b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.781\n",
      "Logistic Regression  average log_loss is 0.502\n",
      "Logistic Regression  average brier score is 0.162\n",
      "Logistic Regression  average auc is 0.838\n",
      "Logistic Regression  average recall is 0.794\n",
      "Logistic Regression  average precision is 0.778\n",
      "Logistic Regression  average f1 is 0.785\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 100,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e3b67957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4dac7207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.003511191734215131}\n",
      "Best Score is : 0.7464746856948692 \n",
      "\n",
      "\n",
      "0.744 + or -0.094 for the {'var_smoothing': 1.0}\n",
      "0.743 + or -0.092 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.744 + or -0.09 for the {'var_smoothing': 0.657933224657568}\n",
      "0.741 + or -0.091 for the {'var_smoothing': 0.533669923120631}\n",
      "0.737 + or -0.088 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.735 + or -0.086 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.733 + or -0.085 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.731 + or -0.084 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.729 + or -0.086 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.73 + or -0.085 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.736 + or -0.087 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.738 + or -0.087 for the {'var_smoothing': 0.1}\n",
      "0.736 + or -0.086 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.737 + or -0.086 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.741 + or -0.09 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.739 + or -0.092 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.735 + or -0.09 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.739 + or -0.091 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.738 + or -0.091 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.742 + or -0.096 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.739 + or -0.094 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.742 + or -0.091 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.745 + or -0.089 for the {'var_smoothing': 0.01}\n",
      "0.744 + or -0.084 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.745 + or -0.081 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.743 + or -0.08 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.746 + or -0.078 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.746 + or -0.078 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.746 + or -0.079 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.745 + or -0.079 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.746 + or -0.079 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.743 + or -0.079 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.743 + or -0.08 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.744 + or -0.081 for the {'var_smoothing': 0.001}\n",
      "0.744 + or -0.081 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.744 + or -0.08 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.746 + or -0.082 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.746 + or -0.083 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.746 + or -0.081 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.746 + or -0.084 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.746 + or -0.086 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.745 + or -0.083 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.741 + or -0.081 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.743 + or -0.08 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.742 + or -0.079 for the {'var_smoothing': 0.0001}\n",
      "0.74 + or -0.079 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.738 + or -0.073 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.739 + or -0.075 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.741 + or -0.073 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.741 + or -0.072 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.743 + or -0.069 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.739 + or -0.068 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.733 + or -0.068 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.732 + or -0.065 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.73 + or -0.065 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.729 + or -0.066 for the {'var_smoothing': 1e-05}\n",
      "0.728 + or -0.064 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.723 + or -0.064 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.721 + or -0.062 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.721 + or -0.062 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.72 + or -0.062 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.717 + or -0.061 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.717 + or -0.061 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.717 + or -0.061 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.717 + or -0.061 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.716 + or -0.061 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.716 + or -0.061 for the {'var_smoothing': 1e-06}\n",
      "0.716 + or -0.061 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.715 + or -0.062 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.714 + or -0.061 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.713 + or -0.06 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1e-07}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1e-08}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.712 + or -0.061 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2bcd80ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.746\n",
      "Naive Bayes  average log_loss is 0.597\n",
      "Naive Bayes  average brier score is 0.188\n",
      "Naive Bayes  average auc is 0.802\n",
      "Naive Bayes  average recall is 0.769\n",
      "Naive Bayes  average precision is 0.744\n",
      "Naive Bayes  average f1 is 0.754\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.003511191734215131)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1475f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance with Random Forest Input\n",
    "X = X_balanced[[\"Age\", \"CKD\", \"Oxygen_Saturation_Percent\" , \"DiastolicBP\" , \"BMI\", \n",
    "                \"Hypertension\", \"Cancers\", \"Cardiovascular_Disease\", \"Hospitalization_14_days_ago\" ,\n",
    "                \"Abnormal_Lung_Signs\", \"Average_Daily_Use_Cigarettes\" , \"Pantoprazole\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5d56078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.54617737 0.54617737 0.55722052\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.56643731 0.56643731 0.56459395        nan        nan        nan\n",
      "        nan        nan 0.53513422 0.59051138 0.59051138 0.58865953\n",
      "        nan        nan        nan        nan        nan 0.67069317\n",
      " 0.65965002 0.65965002 0.65965002        nan        nan        nan\n",
      "        nan        nan 0.66794937 0.67164458 0.67164458 0.67164458\n",
      "        nan        nan        nan        nan        nan 0.66703194\n",
      " 0.66979273 0.66979273 0.66979273        nan        nan        nan\n",
      "        nan        nan 0.6688753  0.6688753  0.6688753  0.6688753\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;background-color: white;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "78bd3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.6716445803601767 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.546 + or -0.071 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.546 + or -0.071 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.557 + or -0.069 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.566 + or -0.069 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.566 + or -0.069 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.565 + or -0.07 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.535 + or -0.078 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.591 + or -0.058 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.591 + or -0.058 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.589 + or -0.056 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.671 + or -0.032 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.66 + or -0.032 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.66 + or -0.032 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.66 + or -0.032 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.668 + or -0.037 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.672 + or -0.037 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.672 + or -0.037 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.672 + or -0.037 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.667 + or -0.037 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.67 + or -0.034 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.67 + or -0.034 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.67 + or -0.034 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.669 + or -0.037 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.669 + or -0.037 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.669 + or -0.037 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.669 + or -0.037 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc859ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.672\n",
      "Logistic Regression  average log_loss is 0.619\n",
      "Logistic Regression  average brier score is 0.214\n",
      "Logistic Regression  average auc is 0.721\n",
      "Logistic Regression  average recall is 0.687\n",
      "Logistic Regression  average precision is 0.668\n",
      "Logistic Regression  average f1 is 0.676\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 10,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a562f00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;background-color: white;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ee276602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.001}\n",
      "Best Score is : 0.6355079850492695 \n",
      "\n",
      "\n",
      "0.569 + or -0.055 for the {'var_smoothing': 1.0}\n",
      "0.572 + or -0.053 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.572 + or -0.055 for the {'var_smoothing': 0.657933224657568}\n",
      "0.577 + or -0.055 for the {'var_smoothing': 0.533669923120631}\n",
      "0.579 + or -0.058 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.582 + or -0.058 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.584 + or -0.057 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.581 + or -0.055 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.58 + or -0.055 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.581 + or -0.051 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.58 + or -0.053 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.583 + or -0.052 for the {'var_smoothing': 0.1}\n",
      "0.584 + or -0.055 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.58 + or -0.054 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.587 + or -0.056 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.592 + or -0.063 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.595 + or -0.059 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.603 + or -0.058 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.611 + or -0.057 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.614 + or -0.054 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.618 + or -0.059 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.618 + or -0.062 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.615 + or -0.058 for the {'var_smoothing': 0.01}\n",
      "0.617 + or -0.055 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.621 + or -0.055 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.617 + or -0.056 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.622 + or -0.052 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.623 + or -0.05 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.624 + or -0.048 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.629 + or -0.049 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.628 + or -0.052 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.631 + or -0.054 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.636 + or -0.053 for the {'var_smoothing': 0.001}\n",
      "0.635 + or -0.053 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.635 + or -0.054 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.633 + or -0.06 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.634 + or -0.059 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.634 + or -0.056 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.631 + or -0.055 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.631 + or -0.055 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.63 + or -0.055 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.63 + or -0.055 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.63 + or -0.055 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.63 + or -0.055 for the {'var_smoothing': 0.0001}\n",
      "0.631 + or -0.054 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.631 + or -0.054 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.631 + or -0.054 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.631 + or -0.054 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.63 + or -0.054 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1e-05}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1e-06}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1e-07}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1e-08}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.63 + or -0.052 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e664fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.636\n",
      "Naive Bayes  average log_loss is 0.716\n",
      "Naive Bayes  average brier score is 0.241\n",
      "Naive Bayes  average auc is 0.673\n",
      "Naive Bayes  average recall is 0.625\n",
      "Naive Bayes  average precision is 0.638\n",
      "Naive Bayes  average f1 is 0.631\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.001)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c03be29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance with Random Forest Input + Post admission variables\n",
    "X = X_balanced[[\"Intubation_Duration_Day\", \"Cancers\", \"CKD\", \"ICU_admission\", \"DiastolicBP\",\n",
    "               \"SystolicBP\", \"Oxygen_Saturation_Percent\", \"Hospitalization_14_days_ago\", \"Chestpain\",\n",
    "               \"Antihypertensive_drug\", \"Sweating\", \"BMI\", \"Cardiovascular_Disease\", \"Pantoprazole\", \n",
    "               \"Current_Smoking\", \"Average_Daily_Use_Cigarettes\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "228a2a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.74934591 0.74934591 0.51106864\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.74843697 0.74843697 0.69479273        nan        nan        nan\n",
      "        nan        nan 0.75947163 0.75857119 0.75857119 0.74102956\n",
      "        nan        nan        nan        nan        nan 0.76779647\n",
      " 0.76777948 0.76777948 0.76410975        nan        nan        nan\n",
      "        nan        nan 0.76777098 0.76777098 0.76869691 0.76224941\n",
      "        nan        nan        nan        nan        nan 0.77054027\n",
      " 0.76869691 0.76685355 0.76502718        nan        nan        nan\n",
      "        nan        nan 0.77053177 0.77054027 0.7714577  0.77054027\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;background-color: white;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8776530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Best Score is : 0.7714576962283385 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.749 + or -0.087 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.749 + or -0.087 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.511 + or -0.009 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.748 + or -0.088 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.748 + or -0.088 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.695 + or -0.065 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.759 + or -0.083 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.759 + or -0.091 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.759 + or -0.091 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.741 + or -0.086 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.768 + or -0.089 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768 + or -0.085 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.768 + or -0.085 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.764 + or -0.09 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.768 + or -0.087 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.768 + or -0.088 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.769 + or -0.088 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.762 + or -0.091 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.771 + or -0.081 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.769 + or -0.089 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.767 + or -0.088 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.765 + or -0.092 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.771 + or -0.081 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.771 + or -0.084 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.771 + or -0.083 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.771 + or -0.082 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f82bfd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.771\n",
      "Logistic Regression  average log_loss is 0.495\n",
      "Logistic Regression  average brier score is 0.160\n",
      "Logistic Regression  average auc is 0.850\n",
      "Logistic Regression  average recall is 0.768\n",
      "Logistic Regression  average precision is 0.779\n",
      "Logistic Regression  average f1 is 0.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1000,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'lbfgs')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "229ab5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3ad9b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.8111308307896871}\n",
      "Best Score is : 0.7613914373088686 \n",
      "\n",
      "\n",
      "0.757 + or -0.106 for the {'var_smoothing': 1.0}\n",
      "0.761 + or -0.108 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.756 + or -0.098 for the {'var_smoothing': 0.657933224657568}\n",
      "0.756 + or -0.098 for the {'var_smoothing': 0.533669923120631}\n",
      "0.755 + or -0.098 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.752 + or -0.096 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.75 + or -0.096 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.751 + or -0.09 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.736 + or -0.092 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.724 + or -0.102 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.723 + or -0.103 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.72 + or -0.106 for the {'var_smoothing': 0.1}\n",
      "0.719 + or -0.107 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.712 + or -0.103 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.7 + or -0.098 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.679 + or -0.089 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.671 + or -0.084 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.663 + or -0.079 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.656 + or -0.078 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.652 + or -0.074 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.651 + or -0.072 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.65 + or -0.071 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.649 + or -0.072 for the {'var_smoothing': 0.01}\n",
      "0.645 + or -0.071 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.639 + or -0.07 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.64 + or -0.071 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.639 + or -0.069 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.639 + or -0.069 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.642 + or -0.071 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.644 + or -0.076 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.646 + or -0.077 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.647 + or -0.079 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.65 + or -0.08 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.652 + or -0.081 for the {'var_smoothing': 0.001}\n",
      "0.657 + or -0.082 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.664 + or -0.084 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.668 + or -0.081 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.671 + or -0.079 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.676 + or -0.085 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.682 + or -0.087 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.688 + or -0.087 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.695 + or -0.091 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.701 + or -0.096 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.704 + or -0.096 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.707 + or -0.097 for the {'var_smoothing': 0.0001}\n",
      "0.718 + or -0.098 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.72 + or -0.097 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.724 + or -0.093 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.728 + or -0.092 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.738 + or -0.088 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.744 + or -0.089 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.742 + or -0.092 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.743 + or -0.093 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.744 + or -0.096 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.745 + or -0.097 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.748 + or -0.097 for the {'var_smoothing': 1e-05}\n",
      "0.747 + or -0.097 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.75 + or -0.093 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.751 + or -0.095 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.75 + or -0.094 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.751 + or -0.092 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.753 + or -0.091 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.754 + or -0.09 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.752 + or -0.089 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.753 + or -0.089 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.754 + or -0.089 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.754 + or -0.089 for the {'var_smoothing': 1e-06}\n",
      "0.754 + or -0.089 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.754 + or -0.089 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.755 + or -0.089 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.755 + or -0.089 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.755 + or -0.089 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1e-07}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1e-08}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.756 + or -0.09 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9058636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.761\n",
      "Naive Bayes  average log_loss is 0.560\n",
      "Naive Bayes  average brier score is 0.187\n",
      "Naive Bayes  average auc is 0.829\n",
      "Naive Bayes  average recall is 0.818\n",
      "Naive Bayes  average precision is 0.744\n",
      "Naive Bayes  average f1 is 0.778\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.8111308307896871)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed8cb619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\calibration.py:964: FutureWarning: The normalize argument is deprecated in v1.1 and will be removed in v1.3. Explicitly normalizing y_prob will reproduce this behavior, but it is recommended that a proper probability is used (i.e. a classifier's `predict_proba` positive class or `decision_function` output calibrated with `CalibratedClassifierCV`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X,Y, test_size=0.2, random_state=5)\n",
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "calibrated.fit(xtrain, ytrain)\n",
    "probs = calibrated.predict_proba(xtest)[:, 1]\n",
    "uncalibrated = nb.predict_proba(xtest)[:,1]\n",
    "fop_uncalibrated, mpv_uncalibrated = calibration_curve(ytest, uncalibrated, n_bins=10, normalize=True)\n",
    "fop_calibrated, mpv_calibrated = calibration_curve(ytest, probs, n_bins=10, normalize=True)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label = 'Ideally Calibrated')\n",
    "plt.plot(mpv_uncalibrated, fop_uncalibrated, marker='.', label = 'Naive Bayes Uncalibrated')\n",
    "plt.plot(mpv_calibrated, fop_calibrated, marker='.', label = 'Naive Bayes Calibrated')\n",
    "leg = plt.legend(loc = 'upper left')\n",
    "plt.xlabel('Average Predicted Probability in each bin')\n",
    "plt.ylabel('Ratio of positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fefff986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes Cal  average accuracy is 0.761\n",
      "Naive Bayes Cal  average log_loss is 0.530\n",
      "Naive Bayes Cal  average brier score is 0.174\n",
      "Naive Bayes Cal  average auc is 0.828\n",
      "Naive Bayes Cal  average recall is 0.746\n",
      "Naive Bayes Cal  average precision is 0.778\n",
      "Naive Bayes Cal  average f1 is 0.760\n"
     ]
    }
   ],
   "source": [
    "calibrated = CalibratedClassifierCV(nb, method='sigmoid', cv=10)\n",
    "showResults(calibrated, \"Naive Bayes Cal\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "904ae557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Gradient Boosting\n",
    "X = X_balanced[[\"Age\" , \"Oxygen_Saturation_Percent\", \"CKD\",\"Respiratory_rate\", \"DiastolicBP\", \n",
    "                \"SystolicBP\",\"BMI\", \"Average_Daily_Use_Cigarettes\" , \"Pantoprazole\", \"Cancers\",\n",
    "                \"Hypertension\", \"Abnormal_Lung_Signs\", \"Drug_history\", \"Sex\", \n",
    "                \"Total_Lung_Involvement_Percent\", \"Hospitalization_14_days_ago\",\n",
    "                \"Current_Smoking\", \"Cardiovascular_Disease\", \"COPD\", \"Diabetes\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f45ffbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.59058784 0.59058784 0.58874448\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.59981312 0.59981312 0.59706082        nan        nan        nan\n",
      "        nan        nan 0.63671424 0.64039246 0.64039246 0.64132688\n",
      "        nan        nan        nan        nan        nan 0.69111451\n",
      " 0.68004587 0.68004587 0.6809718         nan        nan        nan\n",
      "        nan        nan 0.69111451 0.68835372 0.68835372 0.68835372\n",
      "        nan        nan        nan        nan        nan 0.68648488\n",
      " 0.68648488 0.68833673 0.68924567        nan        nan        nan\n",
      "        nan        nan 0.68555046 0.68555895 0.69109752 0.68740231\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;background-color: white;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4b138e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.6911145090044173 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.591 + or -0.071 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.591 + or -0.071 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.589 + or -0.063 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.6 + or -0.058 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.6 + or -0.058 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.597 + or -0.057 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.637 + or -0.055 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.64 + or -0.054 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.64 + or -0.054 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.641 + or -0.058 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.691 + or -0.044 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.68 + or -0.057 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.68 + or -0.057 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.681 + or -0.058 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.691 + or -0.051 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.688 + or -0.049 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.688 + or -0.049 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.688 + or -0.049 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.686 + or -0.048 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.686 + or -0.046 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.688 + or -0.047 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.689 + or -0.044 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.686 + or -0.048 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.686 + or -0.049 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.691 + or -0.047 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.687 + or -0.047 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3908403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.691\n",
      "Logistic Regression  average log_loss is 0.594\n",
      "Logistic Regression  average brier score is 0.203\n",
      "Logistic Regression  average auc is 0.750\n",
      "Logistic Regression  average recall is 0.716\n",
      "Logistic Regression  average precision is 0.682\n",
      "Logistic Regression  average f1 is 0.695\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "86d90367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;background-color: white;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-87\" type=\"checkbox\" ><label for=\"sk-estimator-id-87\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0d0e5117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.0004328761281083057}\n",
      "Best Score is : 0.6541454298335032 \n",
      "\n",
      "\n",
      "0.618 + or -0.07 for the {'var_smoothing': 1.0}\n",
      "0.616 + or -0.071 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.619 + or -0.072 for the {'var_smoothing': 0.657933224657568}\n",
      "0.622 + or -0.075 for the {'var_smoothing': 0.533669923120631}\n",
      "0.622 + or -0.076 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.624 + or -0.081 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.625 + or -0.083 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.628 + or -0.086 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.627 + or -0.088 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.623 + or -0.089 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.624 + or -0.084 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.626 + or -0.082 for the {'var_smoothing': 0.1}\n",
      "0.632 + or -0.084 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.633 + or -0.084 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.634 + or -0.085 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.637 + or -0.086 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.642 + or -0.086 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.643 + or -0.085 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.645 + or -0.079 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.65 + or -0.075 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.653 + or -0.075 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.647 + or -0.072 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.648 + or -0.074 for the {'var_smoothing': 0.01}\n",
      "0.647 + or -0.072 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.645 + or -0.07 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.648 + or -0.067 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.646 + or -0.07 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.647 + or -0.066 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.647 + or -0.066 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.645 + or -0.064 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.644 + or -0.064 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.645 + or -0.064 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.646 + or -0.06 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.649 + or -0.059 for the {'var_smoothing': 0.001}\n",
      "0.651 + or -0.06 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.651 + or -0.06 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.653 + or -0.058 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.654 + or -0.058 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.653 + or -0.059 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.653 + or -0.059 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.652 + or -0.06 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.651 + or -0.061 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.651 + or -0.061 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.652 + or -0.06 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.653 + or -0.06 for the {'var_smoothing': 0.0001}\n",
      "0.653 + or -0.06 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.654 + or -0.061 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.654 + or -0.061 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.654 + or -0.061 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.654 + or -0.061 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.654 + or -0.061 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1e-05}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1e-06}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1e-07}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1e-08}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.652 + or -0.062 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "309aecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.654\n",
      "Naive Bayes  average log_loss is 0.889\n",
      "Naive Bayes  average brier score is 0.255\n",
      "Naive Bayes  average auc is 0.691\n",
      "Naive Bayes  average recall is 0.740\n",
      "Naive Bayes  average precision is 0.636\n",
      "Naive Bayes  average f1 is 0.682\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.0004328761281083057)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "910cc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Gradient Boosting + Post admission variables\n",
    "X = X_balanced[[\"ICU_admission\", \"Age\", \"Intubation_Duration_Day\", \"Oxygen_Saturation_Percent\", \"CKD\", \n",
    "               \"Cancers\", \"Respiratory_rate\", \"SystolicBP\", \"DiastolicBP\", \"BMI\", \"Average_Daily_Use_Cigarettes\",\n",
    "               \"Drug_history\", \"Abnormal_Lung_Signs\", \"COPD\", \"Sweating\", \"Total_Lung_Involvement_Percent\", \n",
    "                \"Chestpain\", \"Cardiovascular_Disease\", \"Sex\", \"Hospitalization_14_days_ago\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9edcac5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.75030581 0.75030581 0.56279307\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.75124873 0.75124873 0.73635746        nan        nan        nan\n",
      "        nan        nan 0.76963982 0.76227489 0.76227489 0.76224091\n",
      "        nan        nan        nan        nan        nan 0.79085117\n",
      " 0.78256881 0.78256881 0.77794767        nan        nan        nan\n",
      "        nan        nan 0.78714747 0.78713048 0.78621305 0.78622154\n",
      "        nan        nan        nan        nan        nan 0.78713048\n",
      " 0.78344376 0.78713897 0.78713048        nan        nan        nan\n",
      "        nan        nan 0.78989976 0.78342678 0.78437819 0.7843527\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "048747d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7908511722731907 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.75 + or -0.103 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.75 + or -0.103 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.563 + or -0.043 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.751 + or -0.107 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.751 + or -0.107 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.736 + or -0.088 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.77 + or -0.094 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.762 + or -0.099 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.762 + or -0.099 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.762 + or -0.088 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791 + or -0.098 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.783 + or -0.093 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.783 + or -0.093 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.778 + or -0.09 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.787 + or -0.096 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.787 + or -0.094 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.786 + or -0.093 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.786 + or -0.096 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.787 + or -0.091 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.783 + or -0.094 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.787 + or -0.098 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.787 + or -0.092 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.79 + or -0.093 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.783 + or -0.093 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.784 + or -0.1 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.784 + or -0.092 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86fc7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.791\n",
      "Logistic Regression  average log_loss is 0.485\n",
      "Logistic Regression  average brier score is 0.156\n",
      "Logistic Regression  average auc is 0.855\n",
      "Logistic Regression  average recall is 0.783\n",
      "Logistic Regression  average precision is 0.803\n",
      "Logistic Regression  average f1 is 0.791\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0f6d9c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;background-color: white;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "188d523b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 8.111308307896872e-07}\n",
      "Best Score is : 0.7178389398572886 \n",
      "\n",
      "\n",
      "0.716 + or -0.116 for the {'var_smoothing': 1.0}\n",
      "0.715 + or -0.117 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.709 + or -0.11 for the {'var_smoothing': 0.657933224657568}\n",
      "0.704 + or -0.107 for the {'var_smoothing': 0.533669923120631}\n",
      "0.702 + or -0.099 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.701 + or -0.097 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.694 + or -0.096 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.689 + or -0.102 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.685 + or -0.101 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.685 + or -0.098 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.682 + or -0.1 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.677 + or -0.102 for the {'var_smoothing': 0.1}\n",
      "0.676 + or -0.102 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.674 + or -0.099 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.675 + or -0.098 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.675 + or -0.096 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.674 + or -0.096 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.673 + or -0.094 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.675 + or -0.096 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.676 + or -0.097 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.676 + or -0.1 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.678 + or -0.1 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.681 + or -0.097 for the {'var_smoothing': 0.01}\n",
      "0.68 + or -0.097 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.681 + or -0.097 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.682 + or -0.097 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.685 + or -0.096 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.686 + or -0.095 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.685 + or -0.094 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.686 + or -0.094 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.687 + or -0.093 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.687 + or -0.093 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.688 + or -0.093 for the {'var_smoothing': 0.001}\n",
      "0.687 + or -0.094 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.687 + or -0.094 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.688 + or -0.093 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.689 + or -0.096 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.688 + or -0.093 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.695 + or -0.095 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.697 + or -0.094 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.695 + or -0.094 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.696 + or -0.094 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.698 + or -0.095 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.697 + or -0.092 for the {'var_smoothing': 0.0001}\n",
      "0.698 + or -0.093 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.699 + or -0.094 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.7 + or -0.093 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.703 + or -0.091 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.704 + or -0.087 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.708 + or -0.088 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.706 + or -0.09 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.71 + or -0.089 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.711 + or -0.09 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.71 + or -0.086 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.71 + or -0.085 for the {'var_smoothing': 1e-05}\n",
      "0.712 + or -0.083 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.712 + or -0.083 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.712 + or -0.083 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.714 + or -0.083 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.713 + or -0.082 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.716 + or -0.084 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.717 + or -0.084 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.717 + or -0.084 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.717 + or -0.084 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.717 + or -0.084 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.717 + or -0.084 for the {'var_smoothing': 1e-06}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1e-07}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1e-08}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.718 + or -0.084 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2b1203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.718\n",
      "Naive Bayes  average log_loss is 1.156\n",
      "Naive Bayes  average brier score is 0.212\n",
      "Naive Bayes  average auc is 0.821\n",
      "Naive Bayes  average recall is 0.832\n",
      "Naive Bayes  average precision is 0.684\n",
      "Naive Bayes  average f1 is 0.749\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 8.111308307896872e-07)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf70da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physician Opinion Input \n",
    "X = X_balanced[[\"Age\", \"BMI\", \"SystolicBP\", \"DiastolicBP\", \"Respiratory_rate\",\n",
    "            \"Oxygen_Saturation_Percent\", \"Total_Lung_Involvement_Percent\", \n",
    "            \"Sex\", \"Current_Smoking\", \"History_hookah\", \"Drug_history\", \"Fever\", \"Dyspnea\", \"Chestpain\", \n",
    "            \"Diabetes\", \"Hypertension\", \"Cancers\", \"Cardiovascular_Disease\", \"CKD\", \"COPD\", \"Immunosuppressant_Drugs\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5f5ec7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.66549439 0.66549439 0.62755691\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.67655454 0.67655454 0.68206762        nan        nan        nan\n",
      "        nan        nan 0.67654604 0.70232756 0.70232756 0.7041879\n",
      "        nan        nan        nan        nan        nan 0.73362215\n",
      " 0.71980972 0.71980972 0.72165308        nan        nan        nan\n",
      "        nan        nan 0.72071016 0.72438838 0.72346245 0.72346245\n",
      "        nan        nan        nan        nan        nan 0.71791539\n",
      " 0.71977574 0.71609752 0.71794088        nan        nan        nan\n",
      "        nan        nan 0.71698947 0.71791539 0.71426266 0.71884132\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-32 {color: black;background-color: white;}#sk-container-id-32 pre{padding: 0;}#sk-container-id-32 div.sk-toggleable {background-color: white;}#sk-container-id-32 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-32 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-32 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-32 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-32 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-32 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-32 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-32 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-32 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-32 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-32 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-32 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-32 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-32 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-32 div.sk-item {position: relative;z-index: 1;}#sk-container-id-32 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-32 div.sk-item::before, #sk-container-id-32 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-32 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-32 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-32 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-32 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-32 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-32 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-32 div.sk-label-container {text-align: center;}#sk-container-id-32 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-32 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-32\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3b37ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score is : 0.7336221542643561 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.665 + or -0.119 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.665 + or -0.119 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.628 + or -0.091 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.677 + or -0.12 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.677 + or -0.12 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.682 + or -0.119 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.677 + or -0.113 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.702 + or -0.112 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.702 + or -0.112 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.704 + or -0.113 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.734 + or -0.103 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.72 + or -0.105 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.72 + or -0.105 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.722 + or -0.104 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.721 + or -0.099 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.724 + or -0.101 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.723 + or -0.101 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.723 + or -0.101 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.718 + or -0.1 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.72 + or -0.1 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.716 + or -0.101 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.718 + or -0.099 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.717 + or -0.101 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.718 + or -0.101 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.714 + or -0.099 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.719 + or -0.1 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ff09ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.734\n",
      "Logistic Regression  average log_loss is 0.555\n",
      "Logistic Regression  average brier score is 0.185\n",
      "Logistic Regression  average auc is 0.792\n",
      "Logistic Regression  average recall is 0.765\n",
      "Logistic Regression  average precision is 0.715\n",
      "Logistic Regression  average f1 is 0.738\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 1,\n",
    "                        penalty = 'l1', \n",
    "                        solver = 'liblinear')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a3dda90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-33 {color: black;background-color: white;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9616a490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 0.12328467394420659}\n",
      "Best Score is : 0.6718059802922187 \n",
      "\n",
      "\n",
      "0.632 + or -0.094 for the {'var_smoothing': 1.0}\n",
      "0.635 + or -0.091 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.647 + or -0.09 for the {'var_smoothing': 0.657933224657568}\n",
      "0.652 + or -0.091 for the {'var_smoothing': 0.533669923120631}\n",
      "0.653 + or -0.089 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.661 + or -0.094 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.664 + or -0.099 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.665 + or -0.094 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.667 + or -0.091 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.671 + or -0.093 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.672 + or -0.093 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.666 + or -0.091 for the {'var_smoothing': 0.1}\n",
      "0.664 + or -0.091 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.663 + or -0.092 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.659 + or -0.086 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.659 + or -0.088 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.66 + or -0.089 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.661 + or -0.088 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.661 + or -0.088 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.662 + or -0.089 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.661 + or -0.089 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.663 + or -0.09 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.663 + or -0.09 for the {'var_smoothing': 0.01}\n",
      "0.663 + or -0.088 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.665 + or -0.089 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.665 + or -0.089 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.665 + or -0.089 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.665 + or -0.087 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.665 + or -0.088 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.663 + or -0.087 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.664 + or -0.086 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.663 + or -0.087 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.664 + or -0.086 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.663 + or -0.086 for the {'var_smoothing': 0.001}\n",
      "0.663 + or -0.086 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.664 + or -0.084 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.664 + or -0.082 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.663 + or -0.083 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.663 + or -0.085 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.664 + or -0.086 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.664 + or -0.086 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.664 + or -0.086 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.663 + or -0.085 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.663 + or -0.085 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.663 + or -0.085 for the {'var_smoothing': 0.0001}\n",
      "0.663 + or -0.085 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.664 + or -0.083 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.664 + or -0.083 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.665 + or -0.082 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.665 + or -0.082 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.665 + or -0.082 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.664 + or -0.082 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1e-05}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1e-06}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 1e-07}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.666 + or -0.079 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1e-08}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.665 + or -0.08 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe03240b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.672\n",
      "Naive Bayes  average log_loss is 0.864\n",
      "Naive Bayes  average brier score is 0.251\n",
      "Naive Bayes  average auc is 0.758\n",
      "Naive Bayes  average recall is 0.892\n",
      "Naive Bayes  average precision is 0.618\n",
      "Naive Bayes  average f1 is 0.729\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 0.12328467394420659)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54b3f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physician Opinion Input + Post admission variables\n",
    "X = X_balanced[[\"Age\", \"BMI\", \"SystolicBP\", \"DiastolicBP\", \"Respiratory_rate\",\n",
    "            \"Oxygen_Saturation_Percent\", \"Total_Lung_Involvement_Percent\", \n",
    "            \"Sex\", \"Current_Smoking\", \"History_hookah\", \"Drug_history\", \"Fever\", \"Dyspnea\", \"Chestpain\", \n",
    "            \"Diabetes\", \"Hypertension\", \"Cancers\", \"Cardiovascular_Disease\", \"CKD\", \"COPD\", \"Immunosuppressant_Drugs\",\n",
    "            'Intubation_Duration_Day','NIV_Duration_Day',\"ICU_admission\"]]\n",
    "Y = Y_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "733f2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 63 candidates, totalling 630 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "350 fits failed out of a total of 630.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\alish\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5        0.78449711 0.78449711 0.52493204\n",
      "        nan        nan        nan        nan        nan 0.5\n",
      " 0.78357119 0.78357119 0.76876487        nan        nan        nan\n",
      "        nan        nan 0.78814135 0.79189602 0.79189602 0.7845141\n",
      "        nan        nan        nan        nan        nan 0.79185355\n",
      " 0.78268773 0.78268773 0.78637445        nan        nan        nan\n",
      "        nan        nan 0.79091064 0.79372239 0.79279647 0.79187903\n",
      "        nan        nan        nan        nan        nan 0.79090214\n",
      " 0.79001019 0.79183656 0.78631498        nan        nan        nan\n",
      "        nan        nan 0.79090214 0.78814985 0.79091064 0.78814985\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;background-color: white;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={&#x27;C&#x27;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=5),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5)\n",
    "\n",
    "cv = GridSearchCV(lr,params_logistic,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "64bf1f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Score is : 0.7937223921168876 \n",
      "\n",
      "\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.784 + or -0.122 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.784 + or -0.122 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.525 + or -0.017 for the {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.001, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.5 + or -0.003 for the {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.784 + or -0.115 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.784 + or -0.115 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.769 + or -0.102 for the {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.788 + or -0.108 for the {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.792 + or -0.119 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.792 + or -0.119 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.785 + or -0.121 for the {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.792 + or -0.112 for the {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.783 + or -0.123 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.783 + or -0.123 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.786 + or -0.122 for the {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791 + or -0.109 for the {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.794 + or -0.113 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.793 + or -0.113 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.792 + or -0.115 for the {'C': 10.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 10.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791 + or -0.114 for the {'C': 100.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.79 + or -0.112 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.792 + or -0.11 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.786 + or -0.111 for the {'C': 100.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 100.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'lbfgs'}\n",
      "0.791 + or -0.114 for the {'C': 1000.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.788 + or -0.117 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "0.791 + or -0.113 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "0.788 + or -0.117 for the {'C': 1000.0, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'}\n",
      "nan + or -nan for the {'C': 1000.0, 'penalty': 'elasticnet', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aeb4028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Logistic Regression  average accuracy is 0.794\n",
      "Logistic Regression  average log_loss is 0.471\n",
      "Logistic Regression  average brier score is 0.150\n",
      "Logistic Regression  average auc is 0.860\n",
      "Logistic Regression  average recall is 0.801\n",
      "Logistic Regression  average precision is 0.795\n",
      "Logistic Regression  average f1 is 0.797\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=5, \n",
    "                        C = 10,\n",
    "                        penalty = 'l2', \n",
    "                        solver = 'newton-cg')\n",
    "lr.fit(X,Y)\n",
    "\n",
    "showResults(lr, \"Logistic Regression\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "53b7226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-35 {color: black;background-color: white;}#sk-container-id-35 pre{padding: 0;}#sk-container-id-35 div.sk-toggleable {background-color: white;}#sk-container-id-35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-35 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-35 div.sk-item {position: relative;z-index: 1;}#sk-container-id-35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-35 div.sk-item::before, #sk-container-id-35 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-35 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-35 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-35 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-35 div.sk-label-container {text-align: center;}#sk-container-id-35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GaussianNB(),\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02, 6.57933225e-02, 5.33669923e-02, 4.32876128e-02,\n",
       "       3.51119173e-02, 2.84803587e-02, 2.3...\n",
       "       1.23284674e-07, 1.00000000e-07, 8.11130831e-08, 6.57933225e-08,\n",
       "       5.33669923e-08, 4.32876128e-08, 3.51119173e-08, 2.84803587e-08,\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "cv = GridSearchCV(nb,params_bayes,cv=10, verbose=1)\n",
    "cv.fit(X,Y.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f5285fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'var_smoothing': 2.310129700083158e-08}\n",
      "Best Score is : 0.7326622494053686 \n",
      "\n",
      "\n",
      "0.73 + or -0.115 for the {'var_smoothing': 1.0}\n",
      "0.728 + or -0.114 for the {'var_smoothing': 0.8111308307896871}\n",
      "0.727 + or -0.115 for the {'var_smoothing': 0.657933224657568}\n",
      "0.727 + or -0.114 for the {'var_smoothing': 0.533669923120631}\n",
      "0.729 + or -0.113 for the {'var_smoothing': 0.43287612810830584}\n",
      "0.724 + or -0.112 for the {'var_smoothing': 0.3511191734215131}\n",
      "0.726 + or -0.117 for the {'var_smoothing': 0.2848035868435802}\n",
      "0.72 + or -0.114 for the {'var_smoothing': 0.23101297000831597}\n",
      "0.719 + or -0.11 for the {'var_smoothing': 0.1873817422860384}\n",
      "0.714 + or -0.106 for the {'var_smoothing': 0.15199110829529336}\n",
      "0.707 + or -0.107 for the {'var_smoothing': 0.12328467394420659}\n",
      "0.707 + or -0.106 for the {'var_smoothing': 0.1}\n",
      "0.701 + or -0.11 for the {'var_smoothing': 0.08111308307896872}\n",
      "0.699 + or -0.106 for the {'var_smoothing': 0.0657933224657568}\n",
      "0.694 + or -0.106 for the {'var_smoothing': 0.0533669923120631}\n",
      "0.691 + or -0.105 for the {'var_smoothing': 0.04328761281083057}\n",
      "0.688 + or -0.104 for the {'var_smoothing': 0.03511191734215131}\n",
      "0.688 + or -0.103 for the {'var_smoothing': 0.02848035868435802}\n",
      "0.687 + or -0.101 for the {'var_smoothing': 0.02310129700083159}\n",
      "0.684 + or -0.1 for the {'var_smoothing': 0.01873817422860384}\n",
      "0.686 + or -0.102 for the {'var_smoothing': 0.01519911082952933}\n",
      "0.688 + or -0.1 for the {'var_smoothing': 0.012328467394420659}\n",
      "0.687 + or -0.097 for the {'var_smoothing': 0.01}\n",
      "0.687 + or -0.097 for the {'var_smoothing': 0.008111308307896872}\n",
      "0.683 + or -0.099 for the {'var_smoothing': 0.006579332246575682}\n",
      "0.686 + or -0.099 for the {'var_smoothing': 0.005336699231206307}\n",
      "0.687 + or -0.099 for the {'var_smoothing': 0.004328761281083057}\n",
      "0.687 + or -0.099 for the {'var_smoothing': 0.003511191734215131}\n",
      "0.685 + or -0.098 for the {'var_smoothing': 0.002848035868435802}\n",
      "0.685 + or -0.098 for the {'var_smoothing': 0.0023101297000831605}\n",
      "0.686 + or -0.098 for the {'var_smoothing': 0.001873817422860383}\n",
      "0.687 + or -0.096 for the {'var_smoothing': 0.0015199110829529332}\n",
      "0.689 + or -0.097 for the {'var_smoothing': 0.0012328467394420659}\n",
      "0.69 + or -0.095 for the {'var_smoothing': 0.001}\n",
      "0.69 + or -0.095 for the {'var_smoothing': 0.0008111308307896872}\n",
      "0.691 + or -0.095 for the {'var_smoothing': 0.0006579332246575676}\n",
      "0.694 + or -0.096 for the {'var_smoothing': 0.0005336699231206307}\n",
      "0.693 + or -0.096 for the {'var_smoothing': 0.0004328761281083057}\n",
      "0.695 + or -0.098 for the {'var_smoothing': 0.0003511191734215131}\n",
      "0.696 + or -0.098 for the {'var_smoothing': 0.0002848035868435802}\n",
      "0.699 + or -0.099 for the {'var_smoothing': 0.0002310129700083158}\n",
      "0.698 + or -0.098 for the {'var_smoothing': 0.0001873817422860383}\n",
      "0.7 + or -0.099 for the {'var_smoothing': 0.0001519911082952933}\n",
      "0.702 + or -0.1 for the {'var_smoothing': 0.0001232846739442066}\n",
      "0.708 + or -0.102 for the {'var_smoothing': 0.0001}\n",
      "0.706 + or -0.101 for the {'var_smoothing': 8.111308307896872e-05}\n",
      "0.709 + or -0.106 for the {'var_smoothing': 6.579332246575683e-05}\n",
      "0.71 + or -0.106 for the {'var_smoothing': 5.3366992312063123e-05}\n",
      "0.71 + or -0.105 for the {'var_smoothing': 4.328761281083062e-05}\n",
      "0.716 + or -0.104 for the {'var_smoothing': 3.511191734215127e-05}\n",
      "0.719 + or -0.104 for the {'var_smoothing': 2.848035868435799e-05}\n",
      "0.721 + or -0.105 for the {'var_smoothing': 2.310129700083158e-05}\n",
      "0.72 + or -0.105 for the {'var_smoothing': 1.873817422860383e-05}\n",
      "0.721 + or -0.105 for the {'var_smoothing': 1.5199110829529332e-05}\n",
      "0.719 + or -0.106 for the {'var_smoothing': 1.2328467394420658e-05}\n",
      "0.719 + or -0.106 for the {'var_smoothing': 1e-05}\n",
      "0.718 + or -0.105 for the {'var_smoothing': 8.111308307896873e-06}\n",
      "0.721 + or -0.105 for the {'var_smoothing': 6.579332246575683e-06}\n",
      "0.723 + or -0.106 for the {'var_smoothing': 5.336699231206313e-06}\n",
      "0.725 + or -0.106 for the {'var_smoothing': 4.328761281083053e-06}\n",
      "0.725 + or -0.106 for the {'var_smoothing': 3.5111917342151275e-06}\n",
      "0.727 + or -0.106 for the {'var_smoothing': 2.848035868435799e-06}\n",
      "0.728 + or -0.104 for the {'var_smoothing': 2.310129700083158e-06}\n",
      "0.729 + or -0.105 for the {'var_smoothing': 1.873817422860383e-06}\n",
      "0.728 + or -0.105 for the {'var_smoothing': 1.519911082952933e-06}\n",
      "0.728 + or -0.105 for the {'var_smoothing': 1.232846739442066e-06}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 1e-06}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 8.111308307896872e-07}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 6.579332246575682e-07}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 5.336699231206313e-07}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 4.3287612810830526e-07}\n",
      "0.729 + or -0.104 for the {'var_smoothing': 3.5111917342151277e-07}\n",
      "0.73 + or -0.104 for the {'var_smoothing': 2.848035868435799e-07}\n",
      "0.73 + or -0.104 for the {'var_smoothing': 2.310129700083158e-07}\n",
      "0.73 + or -0.104 for the {'var_smoothing': 1.873817422860383e-07}\n",
      "0.731 + or -0.103 for the {'var_smoothing': 1.519911082952933e-07}\n",
      "0.731 + or -0.103 for the {'var_smoothing': 1.232846739442066e-07}\n",
      "0.731 + or -0.103 for the {'var_smoothing': 1e-07}\n",
      "0.731 + or -0.103 for the {'var_smoothing': 8.111308307896873e-08}\n",
      "0.731 + or -0.103 for the {'var_smoothing': 6.579332246575682e-08}\n",
      "0.732 + or -0.104 for the {'var_smoothing': 5.336699231206302e-08}\n",
      "0.732 + or -0.104 for the {'var_smoothing': 4.3287612810830526e-08}\n",
      "0.732 + or -0.104 for the {'var_smoothing': 3.5111917342151277e-08}\n",
      "0.732 + or -0.104 for the {'var_smoothing': 2.848035868435799e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 2.310129700083158e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 1.873817422860383e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 1.519911082952933e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 1.232846739442066e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 1e-08}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 8.111308307896856e-09}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 6.579332246575682e-09}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 5.336699231206302e-09}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 4.328761281083061e-09}\n",
      "0.733 + or -0.102 for the {'var_smoothing': 3.5111917342151273e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 2.848035868435805e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 2.310129700083158e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 1.873817422860387e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 1.519911082952933e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 1.2328467394420635e-09}\n",
      "0.731 + or -0.105 for the {'var_smoothing': 1e-09}\n"
     ]
    }
   ],
   "source": [
    "display_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d155587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold cross-validation results:\n",
      "Naive Bayes  average accuracy is 0.733\n",
      "Naive Bayes  average log_loss is 1.503\n",
      "Naive Bayes  average brier score is 0.219\n",
      "Naive Bayes  average auc is 0.832\n",
      "Naive Bayes  average recall is 0.877\n",
      "Naive Bayes  average precision is 0.687\n",
      "Naive Bayes  average f1 is 0.769\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB(var_smoothing= 2.310129700083158e-08)\n",
    "nb.fit(X,Y)\n",
    "\n",
    "showResults(nb, \"Naive Bayes\", X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b672c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
